%%% This is an example thesis that you can use with luthesis.
%%%
%%% There are some choices as to how you format your thesis.
%%% Please read the comments in this file for information.
%%%
%%% Please also read the comments in luthesis.cls as they provide
%%% more details.
%%%
\documentclass[iwp,first]{luthesis}
\usepackage[pdftitle={Information on Using luthesis},pdfauthor={Matthew Tylee Atkinson},pdfsubject={}]{hyperref}
\usepackage[draft,inline,nomargin]{fixme}
\usepackage{booktabs}
\usepackage{wrapfig}
\usepackage{latexsym}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
\usepackage{url}


%%%
%%% Header information
%%%
\title{\textsf{Discrete Logarithm Problem in Finite Fields and Applications to Cryptography:}
\\ \large{Protocols, Algorithms and Source Codes in C++}} % Make sure this is the same as you have above!

\author{Divyesh Bhagwanji Chudasama} % ditto
% We specify the date the thesis was printed and signed
% (these may be merged in future releases).
\thesisDateDay{14th}
\thesisDateMonth{9}  % If you put the name instead of the number, you will get the error ``Missing number, treated as zero.''
\thesisDateYear{2012}
\thesisSignedDay{14th}
\thesisSignedMonth{9}
\thesisSignedYear{2012}

%%%
%%% The Document Body
%%%
\begin{document}
\maketitle % generates our title page and appropriate forms

\frontmatter
\chapter{Preface}
The word \textit{cryptography} originates from the Greek language from the words \textit{kryptos} meaning ``hidden" and \textit{graphein} meaning ``to write" and is the study of techniques for safe communication between two parties in the presence of adversaries. \textit{Cryptography} is a field intersecting the disciplines of mathematics, computer science and electrical engineering and deals with issues related to information security, such as: data confidentiality, data integrity and data authentication. More generally, it ensures and overcomes the influence of third parties upon this information, so that they do not understand what information is being transmitted over a public channel, verifies that the information sent is received from the rightful sender and makes sure that during transit, the information has not been tampered with by any unauthorised party. Prior to the current times, cryptography was  commendably identical to \textit{encryption}; converting information from a comprehensible form into incomprehensible form and back again at the other end, making it unreadable by adversaries without possessing secret knowledge. History recalls that such techniques were solely used by spies, military leaders, and diplomats, however the earliest forms of cryptography can be seen through the``shift cipher" of Julius Caesar. In the early 20$^{\textrm{th}}$ century, many mechanical encryption/decryption devices were invented amongst which the most famous is the ``Enigma" machine that was used by the German government and military from the late 20's and World War II.

The application of cryptology methods have become gradually extensive since World War I and the introduction of the computer. Modern cryptography deeply relies on mathematical theory and computer science practice; designing cryptographic algorithms based on computational hardness assumptions, so that such algorithms are hard to break in practice by any third party, making them computationally secure. Today cryptography is applied to help protect a variety of everyday tasks, some of which are: transferring money via ATMs, internet banking, transmitting voice, photo and video data over mobile networks, online shopping or electroinc commerce and the use of email, instant messaging and communication techniques via computer for both business and personal discussions.

It wasn't until 1976 that cryptography underwent a revolutionary change with the discovery of \textit{public-key cryptography} by Whitfield Diffie and Martin Hellman, providing a method of public-key agreement \cite{NDCrypt}. This key exchange technique uses exponentiation in a \textit{finite field} which then was named as Diffie-Hellman key exchange. This method was the first of it's kind, allowing establishment of a shared secret-key via a legitimate communications channel without the need of a prior shared secret. Prior to this discovery, all methods of cryptographic communications required both parties to approve on a secret key beforehand in privacy and to make sure this key stayed hidden from any third parties or else the information would become vulnerable to tampering; this caused huge obstacles when wanting to communicate securely over long distances or when there was no need for preceding understanding. However, public-key cryptography eliminated this need, and let secure communication take place without the need to secretly exchange keys amongst the two parties involved. Thanks to this remarkable discovery, a  comprehensive use of application of cryptography is possible today.

Nevertheless, every public-key cryptography case faces a computational problem in relation to it's security, that is, that security is guaranteed until solving this problem is infeasible. Putting aside individual problems, in the general case, in this modern age there are only two key problems behind the security of all widely used public-key cryptography, one belonging to the branch of number theory and the second belonging to the branch of group theory, both from the field of pure mathematics. The first problem is the \textit{integer factorisation problem} and the second is the \textit{discrete logarithm problem} respectively. The focus of this thesis is on public-key systems based on the \textit{discrete logarithm problem}.

In particular, this text will take into account, the current understanding on the discrete logarithm problem over \textit{finite fields}, with knowledge relating also to the more general problem and cryptography as a whole. It is to be noted that the subject will not be presented under full scope due to the limitation on time, but the most imperative examples of discrete logarithms used within public-key cryptography, especially considering the extensive use and prominence of applications, are central to the subject of this text. Further, also presented in this thesis are the problems faced for efficient computation in finite fields, as a result of which effectual implementations of public-key cryptography will be reviewed. Lastly, what follows are the various algorithms for computing discrete logarithms, alongside related issues in finite fields that could hold as potential attack mechanisms towards the cryptosystems that will be discussed.

This thesis is organised into a chapter by chapter structure, the details of which are outlined below:

Chapter 1 is based on an overview of the relevant topics that form the foundation of the subject of this thesis, to aid readers in understanding the arguments that will later be discussed in this text. It explains the concept and fundamentals of group theory and finite fields and outlines their vital importance and basis for the discrete logarithm problem, however, prior acquaintance with the theory of finite fields and related algebraic concepts including groups, rings, polynomials and basic number theory would be of benefit. Further,  If undergraduate level knowledge is possessed in the discipline of pure mathematics then one should not face any perplexity in understanding the material discussed in this text.

Chapter 2 is a literature review on the discrete logarithm problem and presents a historical outline of cryptography, its developments, public-key distribution and how the discrete logarithm came about. 

The third chapter brings forward the concept of the public key paradigm and explains what discrete logarithms are and the discrete logarithm problem. The chapter also presents: the Diffie-Hellman key exchange protocol and the Elgamal cryptosystem. These two are``cryptographic primitives" that are based on the difficulty of computing discrete logarithms for their security.

Chapter 4 covers information on efficient computation in finite fields. It discusses techniques for expressing finite fields of both prime and prime power order, which will appear in the chapters to follow. Further, the chapter studies a few non-trivial algorithms for carrying out straight forward computational tasks with multiplication and exponentiation. This chapter also looks into the issue of creating irreducible polynomials over finite fields but only briefly as the problem is wholly related to one of the given field representations. The information reviewed in this chapter links to the material from its previous chapter on the implementation of both the cryptographic primitives and the following chapter analyses the different attacks on these primitives.

Chapter 5 reviews and justifies various discrete logarithm algorithms that relate to subjective finite cycle groups and can be used to attack the primitives outlined in Chapter 3 of this text. The chapter is split into three sections; the first section presents the various different procedures used by the algorithms discussed, the second is based on ``generic discrete logarithm algorithms" whilst the final section explores ``index-calculus" algorithms, also known as non-generic discrete logarithm algorithms.

Chapter 6 explores the implementation of algorithms discussed in Chapter 5. It discusses the programming language used, the sources of the pseudocode used, explains the functionality of the code, looks into the robustness and efficiency of the implementations and discusses the experimental outcomes.

The final chapter summarises the text into a conclusion, and reviews improvements and additional work that could be a possible scope of future work, were the project to be done again. 

\chapter{Declaration of Authorship}

I hereby declare that I wrote this Master Thesis solely by myself and used no resources other than those cited.
\\
\\
Friday 14$^{th}$ September 2012
\begin{flushright}{\textbf{Divyesh B. Chudasama}}
\end{flushright}

\chapter{Acknowledgements}

To begin with, I would like to sincerely and whole-heartedly thank Loughborough University for accepting me onto their Masters Programme, for which reason this thesis exists today.
\\
\\
I would secondly like to express my greatest gratitude to Dr. Ana.M.Salagean, my project supervisor whose repeated advise, guidance, patience and exceeding insights are the purpose for this thesis being possible. 
\\
\\
Next, a huge appreciation to my friends, Nasreen Jabbar, Abhishek Sunil, Abbas Camp and Samuel Simpson for their ever grateful support throughout this thesis. Nasreen proofread a draft copy of this thesis for mathematical, spelling and grammatical errors for which I am obliged to her. Abhishek confirmed many of the mathematical calculations presented, offered beneficial propositions for improvement and assisted in the testing stage of the algorithms by verifying the different outputs obtained. I thank Samuel and Abbas for providing ever helpful advise and tips on program design and efficiency without which my implementations would have lacked their robustness. Their feedback and assitance was greatly helpful and is highly valued. 
\\
\\
Last but not least, I am forever indebted to my parents, without who's unconditional love, care, upbringing and support I would not today be where I am. They inspired me with the passion to learn. It is to them and my lovely sister Bhavini that I dedicate this thesis.

\chapter{Abstract}

Discrete Logarithms in finite fields have proven to provide grave importance and significance within the cryptographic field. It is such that given a primitive element $\alpha$ of a finite field $\mathbb{F}_n$, the discrete logarithm of a nonzero element $\beta\in\mathbb{F}_n$ is the integer \textit{x}, for which \textit{1 $\leq$ x $\leq$ n-1}, where $\beta=\alpha^x$. Had an efficient discrete logarithm been discovered, then many of today's cryptographic systems would have been insecure for making this problem central to the scope of research over recent years. This text critically surveys the known algorithms within this area, as well as reviewing past works, cryptographical developments and related knowledge to the \textit{discrete logarithm problem}. It has been discovered from past reasearch that discrete logarithms in the fields $\mathbb{F}_p$ (where $p$ is a prime) carry a much easier implementation level than that of $\mathbb{F}_{2^n}$. Therefore it can be said that the fields $\mathbb{F}_{2^n}$ are to be avoided in all cryptographic applications as fields $\mathbb{F}_{p}$ appear to provide a higher and increased level of security. Nevertheless, the focus of this thesis will be on the fields $\mathbb{F}_{2^n}$.

\chapter{Notation}

\begin{table}[ht]
\begin{tabular}{|p{2.5cm}|p{10cm}|}
\hline\hline
Symbol & Interpretation\\ [1ex]
\hline
$\mathbb{N}$& Set of \textit{natural numbers}, \{1,2,3,...\}.\\\hline 
$\mathbb{Z}$& Set of \textit{integers}, \{0, $\pm1, \pm2, \pm3,...$\}. \\\hline
$\mathbb{Z}_n$& Ring of \textit{integers} modulo \textit{n}, \{0,1,2,...,\textit{n}-1\}. \\\hline
$\mathbb{Z}^{*}_{p}/\mathbb{F}^{*}_{p}$& Multiplicative group of integers of units modulo \textit{p}. \\\hline
\textit{R$^*$}& The multiplicative group of the ring \textit{R}. \\\hline
\textit{R}[\textit{x}]& The ring of polynomials over the ring \textit{R}, in the indeterminate \textit{x}. \\\hline
gcd(\textit{f}(\textit{x}),\textit{g}(\textit{x}))& Unique monic polynomial of greatest degree dividing \textit{f}(\textit{x}) and \textit{g}(\textit{x}). \\\hline
$\langle \alpha \rangle$& Ideal generated by the ring element $\alpha$. \\\hline
$\square$& End of proof. \\\hline	
\end{tabular}
\label{table:nonlin}
\end{table}






\chapter{Pseudocode}

Throughout this text, various algorithms will be presented in a ficticious programming manner, meaning that the operations of the algorithms are clearly evident and does not include the detailed and complicated syntax that would otherwise be seen in a real programming language.  Nevertheless, we would like to mention here, that the pseudocode will be provided for those algorithms which will be both researched and implemented as one of the key tasks of this project requires the implementation of either one algorithm in great depth or program a set quantity of the discrete logarithm algorithms. 

An attempt has been made herewith, such that even an individual not possessing any knowledge or familiar with programming languages should be able to understand the pseudocode presented without any difficulty. Before proceeding further, we would like to note the following; for the pseudocode:

\begin{itemize}

\item The Algorithm arguments are presented as \textbf{Require}, clearly seperated by commas.

\item $\leftarrow$ is used to assign variables.

\item Bold font is used to outline control statements and these act equivalent to as they do in a real programming language. Some of the control statements seen will be: \textbf{Do, For, If, Return, Unconditionally} and \textbf{While}.

\end{itemize}

\tableofcontents

\mainmatter
\chapter{Overview of Relevant Topics}

As of the discrete nature of the problem presented in this thesis, nearly all the work will be restrained to the mathematics of group theory. For this reason, it is required that readers of this paper possess knowledge and are common to the concepts of group theory and the fundamentals on which it is built. Though it would be of benefit, it is not required that one is also well versed with an understanding of field theory in order to follow the arguments presented in this text.

\section{Groups}

This section outlines an overview of the basic algebraic objects and their properties that are required to be known for full understanding of this text.

\subsection{Definition} 
A \textit{group} is an ordered pair \textit{(G, $\ast$)} such that \textit{G} is a set, $\ast$ is an associative binary operation on \textit{G} and \textit{$\exists$e$\in$G} such that:

\begin{enumerate} 

\item if a$\in$G, then a$\ast$e=a.

\item if a$\in$G, then $\exists$a$^-$$^1$$\in$G such that a$\ast$a$^-$$^1$=e.

\end{enumerate}

If not misunderstood, then it is sufficient to denote the group \textit{(G, $\ast$)} by \textit{G} and the element \textit{a$\ast$b} by \textit{ab}. At times the operation $\ast$ is denoted by + and called addition.\cite{GRT}
\\
\\
This thesis will not look closely into the properties with depth as the text is not a study of group theory, however the information provided in the chapter will suffice for readers to follow and understand the remaining arguments of this text.
\\
\\
\textbf{Note 1:} The element e is known as the identity of $G$, and the element $a^{-1}$ is called the inverse of $a$.

\section{Finite Fields}

Finite fields are determined from the fundamental theorem of Galois Theory and are also known by the name Galois Fields. Galois Theory is amongst one of the most central and vital subjects in mathematics. 

A brief summary; there are two types of finite fields, $\mathbb{F}_{p}$ and $\mathbb{F}_{p^n}$, the former dealing with integer values with operation modulo $p$ whilst the latter deals with irreducible (primitive) polynomials of degree $n$, our focus being on the latter type. We begin by stating basic properties and facts about finite fields.

\subsection{Basic Properties}

\newtheorem{name}{Printed output}
\newtheorem{mydef}{Definition}
\begin{mydef}
A \textit{finite field} is a field $\mathbb{F}$ which contains a finite number of elements. The $order$ of $\mathbb{F}$ is the number of elements in $\mathbb{F}$.
\end{mydef}

\textbf{Fact 1} (\textit{uniqueness and existence of finite fields})
\begin{enumerate}

\item Consider $\mathbb{F}$ to be a finite field, then $\mathbb{F}$ contains $p^n$ elements for some prime $p$ and integer $n \geq 1$.

\item Every prime power order $p^m$, has a unique (up to isomorphism) finite field of order $p^n$. This field is denoted as $\mathbb{F}_{p^n}$.

\end{enumerate}

Speaking informally, $isomorphic$ means two finite fields are the same in structure, however their field elements may be represented differently. We here note that if $p$ is a prime then $\mathbb{F}_{p}$ is a field, and therefore every field of order $p$ is isomorphic to $\mathbb{F}_p$. Only if otherwise stated, the finite field $\mathbb{F}_p$ will be identified with $\mathbb{Z}_p$.
\\
\\
\textbf{Fact 2} If $\mathbb{F}_q$ is a finite field of order $q$ where $q = p^n$, $p$ a prime, then the characteristic of $\mathbb{F}_{q}$ is $p$. Further, $\mathbb{F}_p$ contains a copy of $\mathbb{Z}_p$ as a subfield. Therefore, $\mathbb{F}_q$ can be seen as an extension field of $\mathbb{Z}_p$ of degree $n$. 
\\
\\
\textbf{Fact 3} (\textit{subfields of a finite field}) Let $\mathbb{F}_q$ be a finite field of order $q = p^n$. Then every subfield of $\mathbb{F}_q$  has order $p^m$, for some $m$ which has a positive divisor $n$. Equally , if $m$ is a positive divisor of $n$, then only one subfield of $\mathbb{F}_q$ of order $p^m$; an element $a\in \mathbb{F}_q$ belongs to the subfield $\mathbb{F}_{p^m}$ iff ${a^p}^{m} = a$.

\begin{mydef}
All non-zero elements of $\mathbb{F}_q$  form a group called the multiplicative group of $\mathbb{F}_q$, denoted $\mathbb{Z}_{q}^{*}$, in which the only operation is multiplication.
\end{mydef}

\textbf{Fact 4} $\mathbb{Z}_{q}^{*}$ is a cyclic group of order $q$ -1. Hence $a^q = a$ for all $a\in \mathbb{F}_q$.

\begin{mydef}
A generator of the cyclic group $\mathbb{Z}_{q}^{*}$ is also known as a primitive element or generator of $\mathbb{F}_{q}$
\end{mydef}

\textbf{Fact 5} If $a, b\in \mathbb{F}_q$, a finite field of characteristic $p$, then

\begin{center}

$(a + b)^{p^t} = a^{p^t} + b^{p^t}$ for all $t \geq 0$.

\end{center}

\section{Construction of $\mathbb{F}_{p^n}$}

\begin{mydef}
The field $\mathbb{F}_{p^n}$ is constructed as $\mathbb{Z}_p$[x]/\textless f \textgreater, where f is an irreducible (primitive) polynomial of degree n in $\mathbb{Z}_p$[x].
\end{mydef}

Alternatively $\mathbb{F}_{p^n}$ is the field $\mathbb{Z}_p$[$\alpha$], where $\alpha$ is a root of an irreducible (primitive) polynomial of degree $n$.

\newtheorem{theorem}{Theorem}
\begin{theorem}
If f is primitive then $\alpha$ generates the cyclic group $\mathbb{F}_{q}^{*}$.
\end{theorem}

We can reperesent the elements of $\mathbb{F}_{p^n}$ in two ways:

\begin{enumerate}

\item \{\textit{a}$_0$ + \textit{a}$_{1}\alpha$ + ... + \textit{a}$_{n-1}\alpha$ \textbar a$_i\in \mathbb{Z}_p$\}

\item \{0, 1, $\alpha$, $\alpha^2$, .. , $\alpha^{{p^n}-2}$\}

\end{enumerate}

The Discrete Logarithm Problem converts from the representation shown in number 1 to the representation shown in number 2.




\chapter{Literature Review}

\section{Cryptographic Development}

Cryptography has passed through a revolution over the past three decades. It wasn't until the mid 1970's that cryptography faced the need to develop cryptographic systems, which reduced the need of secure key distribution channels and provide an alternative for a written signature due to the development in hardware technology. Juxtaposition, growth in information theory and computer science lead to probabilistic aspirations of secure cryptosystems that transformed this art into a science.

Following this transformation, telecommunications soon overtook most mail with the expansion of computer controlled communication networks, bridging the communication gap across countries. This however, posed many such applications to become vulnerable to eavesdropping and injection of illegitimate messages, opening up the need for a security solution within the cryptographic field.

Nevertheless, since it's ancient roots, until recently, the most well known problem in cryptography was that of privacy: stopping the retrieval of information from an unauthorised entity over an insecure channel. For cryptographic security, it was required however, a key be shared amongst both communication parties inclusively, without any third party sharing knowledge of it. This used to be achieved by exchange of the key over the means of a secure channel like a private courier or registered mail, in the case of two individual entities such as Alice and Bob involved in one-to-one interaction. For business however, it was common practice to communicate without prior acquaintance as holding back business contact till the physical transfer of the key was simply impractical, unprofessional and unrealistic. The key distribution problem posed a great barrier in the transfer of business communications to large teleprocessing networks due to the cost and delay it imposed. 

\section{Public-Key Distribution}

It wasn't until later, with the proposition of public key distribution systems that the requirement for a secure key distribution channel overcome. This proposition asks of a system and two users wishing to communicate. The system works as such that the users interact back and forth till they both reach a common key; eavesdropping by a third party would make computing the key computationally infeasible for the subject. Not only key distribution, but business communications also raises a question on authentication, the validation of which was given via signatures on a written agreement as proof of the acceptance of the contract. A \textit{public-key distribution} works in the same manner, however the use of signatures for such a system involves the transfer and storage of written contracts. For a digital replacement for the paper system, every user had to produce a message the authenticity of which can be verified by any other person, however not produced by anyone else, not even the recipient. As the messages can only be originated by one person but likewise received by many, it is classified as a broadcast cipher. 

Juxtaposed the increase in new cryptographic problems through the development in communications and computation, it's child divisions, information theory and theory of computation began to provide tools for the answer to the crucial classical crypto graphical problem. 

Since the ancient times, one of the oldest themes of cryptographic research has been one of unbreakable codes. This wasn't until recently, as all such proposed systems have been broken, but earlier this century, back in the nineteen twenties, the ``one time pad" scheme was invented and shown and still is mathematically unbreakable. Even having considered the current and future computation powers, there is no way to break it, purely because it is mathematically impossible. We note that one-time pads are not of central interest to this text, but if the reader wishes to gain insight knowledge upon this subject then please refer to \cite{NDCrypt}.

As opposed to crypto graphical developments, the security of the majority of current cryptographic systems is based on the level of computational difficulty a cryptanalyst faces of being able to find the plaintext without any knowledge of the key. This particular challenge remained within the domains of computational complexity and algorithmic analysis; two such disciplines that explore the difficulty levels of solving computational problems.

\section{Computing Logarithms}

In light of what has been discussed so far in this chapter, Diffie and Hellman introduced a technique that uses the concept of the difficulty of computing logarithms over a finite field $\mathbb{F}_p$ \cite{GAT} and is known as Galios' Field. Despite their proposal involving the finite field $\mathbb{F}_p$, it has since been adapted and used for the finite field $\mathbb{F}_{2^n}$ because of its ease of implementation. We take interest in the finite filed $\mathbb{F}_{2^n}$ for this text and subsequent arguments will follow, but first let us here explain the logarithmic technique presented by Diffie and Hellman in their invited paper in 1976 \cite{NDCrypt}. 

The computation works as such; for the finite field $\mathbb{F}_p$ with a prime number \textit{p} of elements, allow

\begin{center}
\textit{Y = $\alpha^X$} mod \textit{p}, for 1 $\leq$ \textit{X} $\leq$ \textit{p}-1
\end{center}

in which $\alpha$ is a primitive element of $\mathbb{F}_p$ that is fixed, \textit{X} is known to be the logarithm of \textit{Y} to the base $\alpha$ mod \textit{p}, mathematically denoted:

\begin{center}
\textit{X} = log$_\alpha$\textit{Y}mod\textit{p}, for 1 $\leq$ \textit{Y} $\leq$ \textit{p}-1
\end{center}

It is easy and straightforward to calculate Y from X, considering 2$\times$log$_2$\textit{p} multiplications to be the calculation. To state and example, like \textit{X} = 18,

\begin{center}
Y = $\alpha^{18}$ = ((($\alpha^2)^2)^2)^2 \times \alpha^2$
\end{center}

Though this is straightforward, doing the opposite operation of finding \textit{X} from \textit{Y} is of higher difficulty, especially for certain values of \textit{p}, for which case the most appropriate algorithm is to be determined.

Yet as difficult a method this may prove to be it's security very heavily depends on the hardness of computing logarithms mod $p$. Were an algortihm with growth log$_2$q to be found then this system would be broken. The Diffie-Hellman key exchange method is discussed later in Chapter 3 of this thesis for now we are to continue reviewing related literature. The best $p$ chosen is $p^{1/2}$ being the best measure of the difficulty of the problem and a good common algorithm for using logs and mod$p$, alongside being quite near optimal. A number is chosen uniformly, which users have produced from integers \{1,2, ...\}, keeps $X_i$ secret, but places

\begin{center}
$Y_i = \alpha^{X_i}$mod $p$
\end{center}

To cite an example of breaking such a system with a known log mod $q$, consider a public file holding names and addresses of individuals from one particular neighbourhood, when private communication is then used by $i$ users, the following therefore becomes their key,

\begin{center}
$K_{ij} = \alpha^{X_{i}X_{j}}$mod $p$
\end{center}

$K_{ij}$ is acquired by user $i$ and this is done by acquiring $Y_j$ as of the public file. Let 

\begin{center}
$K_{ij} = Y_{j}^{X_{i}}$mod $p$
\\
= $(\alpha^{X_j})^{X_i}$mod $p$
\\
= $\alpha^{X_{j}X_{i}}$
\\
= $\alpha^{X_{j}X_{i}}$mod $p$
\end{center}

User $j$ obtains $K_{ij}$ in the similar fashion

\begin{center}
$K_{ij} = Y_{i}^{X_j}$mod $p$
\end{center}

Another user must compute $K_{ij}$ from $Y_{i}$ and $Y_{j}$, for example, by computing

\begin{center}
$K_{ij} = Y_{i}^{(log_{\alpha}Y_{j})}$mod $p$
\end{center}

Hence, It is evident that the system can break without difficulty if the log mod $p$ is known. Although, there is no evidence that the system is secure if logs mod $p$ are not easy to compute, and $X_i$ or $X_j$ always have to be computed before $K_{ij}$ can be computed from $Y_i$ and $Y_j$. 

If 2$^b$ is a little more than $p$ (which is a prime), thereafter all quantities are seen as $b$ bit numbers.  Exponentiation then takes at most 2$b$ multiplications mod $p$, while by hypothesis, taking logs requires $p^{1/2} = 2^1/2$ operations. As a result, the crypt analytical effort exponentially grows with rightful efforts; to obtain $X_i$ to $Y_i$, or $Y_i$ and $X_j$ to $K_{ij}$ when $b$=200, then a maximum of 400 multiplications are needed, as well as logs mod$p$, which need 2$^{100}$ or roughly 10$^{30}$ operations. 

Continuing with computation we now consider our field of interest $\mathbb{F}_{2^n}$ in which computations are understood under the following context:

\begin{itemize}

\item A specific irreducible polynomial is $f(x)$ is chosen which is of order \textit{n} over the field $\mathbb{F}_2$. \textit{C$\in\mathbb{F}_2$} is polynomial C(x) over $\mathbb{F}_2$, understood as mod $p(x)$, and the field contains a maximum of 2$^n$ elements.

\item Addition and multiplication are understood as polynomial addition and multiplication over $\mathbb{F}_2$mod ($p(x)$).

\end{itemize}

It is required however, that the polynomial $f(x)$ is \textit{primitive}; as \textit{m} lies in the integer range of 0,1,2,...,2$^n$ - 2, the elements A(x)$\equiv$ x$^m$mod\textit{f(x)} of the field take each nonzero element of $\mathbb{F}$ once and only once. Further, the nonzero, element A(x) and integer m are related so that \textit{m} is referred to as the \textit{logarithm} of \textit{A(x)}. As \textit{x}$^{2^{n} -1}\equiv$1mod \textit{p(x)}, this logarithm can therefore be defined as 2$^{n}$ - 1 meaning the logarithm \textit{m} is considered to be in the scope of integers mod 2$^n$ - 1, (also called the ring \textit{Z}/(2$^n$ - 1)). It was this calculation of \textit{m} that gave birth to the subject of this text as we know it today, and was named the \textit{discrete logarithm problem}. It is advised, that if one so desires to gain a deeper insight into logarithms in fields of characteristic two then please refer to \cite{Char2}.

\subsection{Computational Complexity Issues}

The main question of security, `What is a possible computation?' derives from the consideration of security of cryptosystems against computational attacks. In mathematics, this is called computational complexity theory and this section consists of the complexity issues along with the discrete logarithm problem. 

Though chapter 5 of this thesis explores the problem in detail we here consider the discrete logarithm problem under the context of the \textit{Compiutational Complexity Issues}. The discrete logarithm problem for the group $G$ may be stated as:

\begin{center}

``Given $\alpha \in G$ and $\beta \in g$, find an integer $x$ such that $\alpha^x =\beta$.”

\end{center}

The statement of the problem above is the primary aspect that needs to be considered, yet, firstly, there is logic to discuss the discrete logarithm problem in an arbitrary semigroup; however, in many cases the curiosity is in precise examples of finite cyclic groups; the above statement has precisely eliminated that $\beta$ may not possibly be within the cyclic group generated by $\alpha$. There is another way to state the problem:

\begin{center}

``Given that $\beta, \alpha \in G$, determine if there exists an integer $x$ such that $\alpha^x=\beta$, and if so, find such an $x$.”

\end{center}

Nevertheless, more difficulty could be faced in solving this version of the problem, so, in order to resolve the discrete logarithm problem, analysing an algorithm could be utilised and as to go ahead with the analysis, we should be aware that $\beta \in g$. From now on, the assumption will be made that the group $G$ is cyclic, with $G = g$, so the initial statement of the problem can be used. 

The statement ``given the group $G$” should be defined in an unambiguous way. There could be many abstract ways that groups could occur; the following gives a few examples: 

\begin{itemize}

\item The imaginary quadratic field’s class group, which is received by the discriminant
\item An elliptic curve over a finite field or rational numbers, where a group of points occur, received by the equation of the curve and the specification of the field
\item Galois group of a polynomial
\item Finite Albelian group which is received by invarian factors or generators and relations. 

\end{itemize}

The following assumptions need to be made for the group $G$:

\begin{itemize}

\item Efficient algorithms for testing equality of group elements are known
\item An efficient algorithm for multipling any two elements of the group is known
\item The group is finite, generated by $\alpha$, with known order $n$.

\end{itemize}

The classification of computational problems is the aim of the field of computational complexity whilst corresponding the level of difficulty. An example of the discrete logarithm algorithm is a random polynomial time reduction between two computational issues, which could be used to determine the order of the base for the logarithm. This type of reduction can be seen as a partial ordering which is induced from the computational issues depending on the complexity dealt with, and valuable data could be given on the intrinsic complexity of the issue.  In this particular situation, it could be hard to determine the discrete logarithms because it is initially used to determine the order of that base in the group. We will not consider the analysis and evaluation of the various discrete logarithm algorithms and their applicable fields in the literature review as Chapter 5 of this text is dedicated to this very topic.

\subsection{Reduction}

Firstly we have to consider a few simple methods, which will decrease a discrete logarithm problem in a cyclic group $G$ to discrete logarithm problems in different subgroups. In order to start, it is essential to mention all the rules involved, yet, it is not too difficult to multiply and take inverses in $G$, which is required in this case. There could be a problem in some cases where there lies a possibility that two elements could be equal, for example, suppose the group is viewed as a structure with proportions, or there maybe a group of binary quadratic forms. However, the following two assumptions should always be made while carrying out a group operation; the cost of deciding if the two elements of $G$ are equal is of the identical magnitude and the group elements could have allocated symbols so that they could be kept. 

\subsubsection{The first reduction}

Suppose the cyclic group $G$ has the order $n$ and $n$ is factored significantly as $n=u \times v$, where $u$ and $v$ are coprime, and thus gcd ($u,v$) =1. So now the issue of solving a discrete logarithm in $G$ is decreased into solving for order $u$ and $v$ of the discrete logarithm in the subgroup of $G$. If we consider the case where $G$ = g, then $g^u$ generates the subgroup of $u^{th}$ powers in $G$, of order $v$, and in the same way $g^v$ generates the subgroup of $v^{th}$ powers, with order $u$. Solving the discrete logarithm $l_u$, $l_v$, where 

\begin{center}

($g^u)^{l_u}$ = $t^u$
\\
($g^v)^{l_v}$ = $t^v$

\end{center}

By performing repeated squaring one can solve the powers $g^u, g^u, t^u, t^v$. (Buhler and Wagon 2008)

Adopting the extended Euclidean algorithm may discover the integers $a, b$, by doing $a \times u + b \times v =1$. So:

\begin{center}

$t = t^{a_{u}+b_{v}} = (t^u)^{a}(t^v)^{b} = g^{ul_{u}a}g^{vl_{v}b} = g^{aul_{u}+bvl_{v}}$

\end{center}

and we come to the conclusion that the discrete logarithm of $t$ is $aul_{u} + bvl_{v}$.

\subsubsection{The next reduction}

This reduction assumes that the order is a prime power of $G$, so for example, $p^a$, where $a > 1$. The discrete logarithm issue of order $p$ in the cyclic subgroup of $G$ could have been reduced to $a$ from the discrete logarithm in the group. Suppose we need to discover the $l$ from $g^l=t$, in the base $p$, if we add in the $l$, where $l$ is satisfied for a smallest positive value, then 

\begin{center}

$l = b_{0} + b_{1}p + ... + b_{a-1}p^{a-1}$,

\end{center}

For each $b_j$ being an integer in [0, $p$-1], $b_0, b_1, b_{p-1}$ should be discovered in order. Consider the following:

\begin{center}

$t^{p^{a-1}} = (g^l)^{p^{a-1}} = g^{lp^{a-1}} = g^{b_{0}p^{a-1}} = (g^{p^{a-1}})^{b_0},$

\end{center}

The $p^{a-1}$ powers which are generated by $g^{p^{a-1}}$ in the cyclic subgroup, $b_0$ is the resolution of the discrete logarithm problem. Assume the calculation for $b_{0}…b_{j-1}$, has already been done. Note that:

 \begin{center}

$t_j = tg^{-b_{0}-b_{1}p-...-b_{j-1}p^{j-1}}$.

\end{center}

It can be observed that $t^j$ is a power of $p^j$, and therefore $t_j^{p^{a-j-1}}$ is in the group with powers of $p^{a-1}$. The discrete logarithm issue for $b_j$ needs to be solved. 

\begin{center}

$t_j^{p^{a-j-1}} = (g^{p^{a-1}})^b_j$

\end{center}

we now need to look for the base $p$ digit of $l$.

To demonstrate such reduction, we need a help of an example. Consider an example where $g$ = 11, $t$ = 17 in ($\mathbb{Z}$/101$\mathbb{Z}$)*.  It is sufficient to solve two discrete logarithm issues for every groups of order 2 and 5 as 100 is the order of the group. So 17$^{25} \equiv$ -1(mod 101), order 4 in the subgroup, the element 17$^{25}$ should have 2 as their discrete logarithm i.e. l$_{25}$ = 2. The two problems have now been solved for the order 2, the former being 0 and the latter therefore being l$_{25}$ = 0 + 1.2 = 2). 

We should now find l$_4$ for 11$^{l_4}$ = 17$^4$ = 95(mod 101), the order of 25 is being solved for the discrete logarithm in a cyclic group. The discrete logarithm calculation had been decreased to two in a group of order 5. Firstly we have to calculate 

\begin{center}
17$^20$ = 95$^5$ = 1(mod 101), 
\end{center}

this concludes that l$_4$ is a multiple of 5. In addition, 11$^{20}$ = 87(mod 101) and for the 95 modulo 101, we need to look for a power which corresponds to 87, so the solution is 0,1,2,3 or 4. It is obviously not 0 or 1 hence experiment with the number 2 yields the correct answer. So

\begin{center}
l$_4$ = 0 + 2 $\times$ 5 = 10. 
\end{center}

Next we consider 

\begin{center}
(-6) $\times$ 4 + 1 $\times$ 25 = 25, 
\end{center}

therefore 

\begin{center}
(-6) $\times$ 4 $\times$ 10 + 1 $\times$ 25 $\times$ 2 = -190, 
\end{center}

this is the smallest positive discrete logarithm for 17 $\times$ 10.
\\
\\
We can now control the group order, however, this may not be the situation most of the time, so we should decrease the problem to a smaller situation as illustrated just now in the above example. This could be done by running a factorisation algorithm on the order because some discrete algorithms are in general difficult in practice than factoring. Smaller situations ease the level of calculation, unless in some cases where one has to work on subgroups equally as hard as  working within the full group.

\section{Historical Perspective}

In the past the growth of cryptography has not indicated public key systems and a one-way authentication system, but it can be seen as a natural growth of development in cryptography going back to hundreds of years.

As already mentioned, an important aspect of cryptography is privacy; an aspect that was uncertain during the first stages of cryptography. An example of this could include the Caesar Cipher; when a letter is substituted by the third place, for example, A is carried to D and B is carried to E and so on, the Caesar cipher cryptosystem relies on the security by ensuring the whole process of encryption is kept secret. 

The general system had to negotiate when the telegraph was generated, this happened because of the difference between the general system and a precise key. An example of this is theft of crypto graphical devices, with no negotiation of upcoming encrypted messages in new keys. Kerchoffs codified this theory, where in 1881 it was stated that any correspondents should hesitate with the negotiation of a cryptography system. Around 1960 however, keeping messages a secret was out of place as cryptosystems came across and therefore it was quite strong to tolerate a common plaintext cryptanalytic attack. Such enlargement reduced the part of the system that had to be kept secret from the public, by removing dreary convenients rephrasing diplomatic dispatches. In order to decrease secrecy, public key systems are sustained and there were restrictions to computations in cryptography systems before this century. These computations were done by either hand or normal slide rule like devices. 

The actual revolutionary commenced just after World War 1 in which extraordinary machines were built for encrypting. Cryptography was restricted to operations that could be done with easy electromechanical systems, till there was expansion of normal purpose digital hardware and the expansion of digital computers has untied it from the restrictions of computing with gears and the search is authorized for better types of encryption to only cryptographic principle.





\chapter{Discrete Logarithms and Cryptosystems}

This chapter will begin by discussing discrete logarithms in finite fields, stating associated properties and specifying mathematical characteristics. The chapter then follows by the introduction of public-key cryptography and outlines two current algorithms established on the discrete logarithm problem. 

\section{Discrete Logarithms in Finite Fields}

The key interest of this text dwells around the subject of discrete logarithms in the finite field \textit{q}, where \textit{q}=2$^n$. The algorithms presented, are defined in the generic setting of a finite cyclic group G (multiplicatively written) of order \textit{n}, with generator $\alpha$, also known as the primitive element $\alpha$ of the multiplicative group $\mathbb{F}_p$. To take a more tangible approach, it can be advised that it is suitable for the reader to think G to be the multiplicative group $\mathbb{F}^{*}_{p}$ of order ($p$-1), the group operation of which is multiplication modulo \textit{p}.

\begin{mydef}
Let \textit{G} be a finite cyclic group of order n, $\alpha$ is a generator of G, and $\beta$$\in$G. The discrete logartihm problem of $\beta$ to the base $\alpha$, written $log_\alpha$$\beta$, is the distinct integer x, 0 $\leq$ x $\leq$ n-1, such that $\beta$=$\alpha$$^x$.
\end{mydef}

As mentioned above it may help the reader to understand the multiplicative group $\mathbb{Z}^{*}_{p}$ = [1,...,\textit{p}-1] as a concrete instance of the finite cyclic group \textit{G}. So:

\begin{center}
\textbf{log$_\alpha$: $\mathbb{Z}^{*}_{p}$ $\longrightarrow$ $\mathbb{Z}_{p-1}$}
\end{center}
such that the discrete logarithm problem converts integer multiplication of modulo a prime \textit{p} into integer addition of modulo \textit{p}-1. To aid understanding, an example is presented below.

\newtheorem{example}{Example}
\begin{example}

Let p=29, then G:=$\mathbb{Z}^{*}_{29}$ is a finite cyclic group of order n=28. A generator of $\mathbb{Z}^{*}_{29}$ is $\alpha$= 2 and $\beta$ = 17. The discrete logarithm holds as a unique integer \textit{x} such that \textit{0 $\leq$ x $\leq$ 28} and $\beta$=$\alpha$$^x$.
\end{example}

This gives 17 = 2$^x$ so the discrete logarithm is:

\begin{center}
\textit{x} = log$_\alpha$17 = log$_2$17
\end{center}

Now

\begin{center}
\textit{$\alpha$$^x$} = 17mod \textit{p}

$\Rightarrow$ \textit{$\alpha$$^x$} = 17mod 29

$\Rightarrow$ 2$^x$ = 17mod 29
\end{center}

Since 2$^{21}$ = 2097152, element $\beta$ will take the value \textbf{17} as:

\begin{center}
17(mod29) = x = log$_2$(17) = 21
\end{center}

Meaning that the \textbf{discrete logarithm is}:

\begin{center}
x = log$_2$(17) = 21
\end{center}

Now when \textit{x} = 21 it holds that:

\begin{center}
2$^{21}$ = 17mod 29
\end{center}

The following steps outline why \textit{$\beta$} takes the value of 17:

\begin{center}

\begin{enumerate}

\item 2$^{21}$ = 2097152 

\item 2097152mod 29 = 72315.58621. 

\item The integer value 72315 is then taken as the quotient.

\item Now 72315 x 29 = 2097135.

\item Finally, we now calculate the difference between the answers from step 1 and step 4, 2097152 - 2097135 = 17

\item Hence, \textit{$\beta$} = 17.

\end{enumerate}

\end{center}

This proves that \textit{$\beta$} = 17 is a sufficient element of \textit{G} and that \textit{x} = 21 is the unique integer for 0 $\leq$ \textit{x} $\leq n$-1, such that \textit{$\beta = \alpha^x$}. Before progressing further, it is important to state some elementary facts about logarithms.
\\
\\
\textbf{Fact 6} Let $\alpha$ be a generator of a cyclic group \textit{G} of order \textit{n} and let \textit{$\beta,\alpha\in G$}. Let \textit{s} be an integer. Then:

\begin{center}
\begin{itemize}

\item log$_\alpha$($\beta$$\gamma$) = (log$_\alpha$$\beta$ + log$_\alpha$$\gamma$)mod\textit{n}

\item log$_\alpha$($\beta$$^s$) = \textit{s}log$_\alpha$$\beta$mod\textit{n}

\item log$_\alpha$($\frac{\beta}{\gamma}$) = (log$_\alpha$$\beta$ - log$_\alpha$$\gamma$)mod\textit{n}

\end{itemize}
\end{center}

In cryptography, the groups of most interest are multiplicative group $\mathbb{Z}^{*}_{p}$ of the finite field $\mathbb{F}_p$, especially the cases of the multiplicative group $\mathbb{Z}^{*}_{p}$ of the integers modulo a prime \textit{p}, and the multiplicative group $\mathbb{Z}^{*}_{2^n}$ of the finite field $\mathbb{F}_{2^n}$ of characteristic two. Now we continue on to defining the discrete logarithm problem for both of these fields.

\subsection{The Discrete Logarithm Problem in $\mathbb{F}_p$}

\begin{mydef}
The discrete logarithm problem (DLP) in $\mathbb{F}_p$ is the following: given a cyclic group $G$, a prime \textit{p}, a generator \textit{$\alpha$} of $G$ and an element $\beta\in G$, find the integer \textit{x}, 0 $\leq$ \textit{x} $\leq$ p-1, such that \textit{$\alpha$$^x$=$\beta$(mod)p}.
\end{mydef}

\subsection{The Discrete Logarithm Problem in $\mathbb{F}_{2^n}$}

\begin{mydef}
The discrete logarithm problem (DLP) in $\mathbb{F}_{2^n}$ is the following: given an irreducible (primitive) polynomial $f$($x$) of degree n, a cyclic group $G=\mathbb{Z}^{*}_{2^n}$, a generator $\alpha$, and a primitive element $\beta$ $\in$ $G$, find the integer \textit{x}, 0 $\leq$ \textit{x} $\leq$ ${2^n}$-1, such that \textit{$\alpha$$^x$=$\beta$}.
\end{mydef}

\textbf{Note 2:} \textit{Solving the discrete logarithm problem in a finite cyclic group G of order n is actually computing an isomorphism between G and $\mathbb{Z}_n$}. Any two cyclic groups that are isomorphic means that they have the same structure though the elements within them can be written in differing representations. Nevertheless, having kept this property in mind it does not follow that having found an efficient algorithm for computing logarithms in one group will also lead to an efficient algorithm for the second group. To understand this, take it that every cyclic group of order \textit{n} is isomorphic to the additive group of order $\mathbb{Z}_n$, i.e. the integers \{0,1,2,...,\textit{n}-1\} with group operation addition modulo \textit{n}. Moreover, in the latter group, the problem of finding a distinctive integer \textit{x} satisfying \textit{ax $\equiv$ b(mod n)} such that \textit{a,b$\in$}$\mathbb{Z}_n$, is as straight forward as demonstrated in the following. Firstly, it is important to note that there is no solution \textit{x} if \textit{d}=\textit{(a,n)} is not divisible by \textit{b}. Or else, if \textit{d} is divisible by \textit{b}, then it is possible to use the extended Euclidean algorithm to determine integers \textit{s} and \textit{t}, such that \textit{as+nt=d}. Now, multiplying both sides of this equation by integer \textit{($\frac{b}{d}$)} will give: \textit{a($\frac{sb}{d}$)} + \textit{n($\frac{tb}{d}$)} = b and reducing by modulo \textit{n} holds \textit{a($\frac{sb}{d}$)}$\equiv$\textit{b}mod \textit{n}. Therefore \textit{x} = \textit{($\frac{sb}{d}$)}mod \textit{n} is the easily obtainable and needed solution.
\\
\\
The algorithms for the DLP are outlined in detail in Chapter 5 of this text, however in brief can be categorised in the following way:

\begin{enumerate}

\item Algorithms that work in arbitrary groups such as:  exhaustive search, Shanks' ``Baby-Step Giant-Step'' algorithm and Pollard's Rho algorithm. 

\item Algorithms working in arbitrary groups are efficient, particularly if the group has only small prime factors e.g. The Pohlig-Hellman algorithm and

\item The Index-Calculus algorithms, that are effective in certain groups only.

\end{enumerate}

\section{Properties of the Discrete Logarithm}

The properties of the discrete logarithm problem are the same to those of the familiar logarithm \textbf{[Fact 6]}. We here define an additional property, once again common to both and readers are to understand \textit{G} to be a finite cyclic group of order \textit{n} written multiplicatively, where \textit{$\alpha$} is a generator of \textit{G}.

\begin{mydef}
Change of Base Property
\end{mydef}

$\widetilde{\alpha}$ is an element, a second generator of \textit{G} and \textit{h} is an element of \textit{G}, then

\begin{center}
log$_\alpha$(\textit{$\frac{h}{\widetilde{\alpha}}$})$\equiv$(log$_\alpha$(\textit{h}) - log$_\alpha$($\widetilde{\alpha}$)(mod \textit{n}))
\end{center}

\textit{Proof}. The proofs of these properties will not be considered in this text, but if the reader wishes to understand the proofs then this is left as an exercise. $\Box$
\\
\\
\textit{Remark}: Division may not always be possible because not all the elements of the additive group $\mathbb{Z}_n$, then \textit{r} will be invertible iff gcd(\textit{r,n}) = 1 (greatest common divisor), where both \textit{r} and \textit{n} are relatively prime. Nevertheless provided that $\widetilde{\alpha}$ is a generator of \textit{G} and that $\widetilde{\alpha}$=$\alpha$$^k$ for some \textit{k} in $\mathbb{Z}_n$ if and only if gcd(\textit{k,n}) = 1, meaning it is now clear that  log$_\alpha$($\widetilde{\alpha}$) = \textit{k} is invertible in $\mathbb{Z}_n$.

In relation to the Change-of-Base property, it does not matter what generator is chosen as this does not impact the difficulty level of the discrete logarithm problem. This is evident in the following: assume a method exists such that the discrete logarithm problem can be solved for base \textit{$\alpha$} in \textit{G}. A second generator $\widetilde{\alpha}$ of \textit{G} is then given with \textit{h$\in$G}, so that the problem of finding log$_\alpha$(\textit{h}) can be efficiently converted into a problem with the discrete logarithm base $\alpha$ by the Change-of-Base property. Hence, making all the generators effectively the same. 

\newpage
\begin{theorem}
Discrete Logarithms of Products
\end{theorem}

\textit{It is true for any finite field F$_q$, primitive element $\alpha$ and elements $\beta_0, \beta_1,...,\beta_{k-1}\in$$\mathbb{Z}^{*}_{q}$ that:}
\begin{center}

log$_\alpha$($\prod\limits_{i=0}^{k-1} \beta_i$) $\equiv \sum\limits_{i=0}^{k-1}$ log$_\alpha (\beta_i)$ mod \textit{(q-1)}
\end{center}

With consideration to the above, the discrete logarithms of $\mathbb{F}^{*}_{q}$ are thought to be elements of the additive group $\mathbb{Z}_{q-1}$. Further, it will suffice to think the discrete logarithm function as an isomorphism log$_\alpha$:$\mathbb{F}^{*}_{q}$ $\longrightarrow$ $\mathbb{Z}_{q-1}$, and the key interest which we are focusing on is the analysis of this isomorphism.

\section{Complexity}

\begin{mydef}
Time and Space Complexity
\end{mydef}

\textit{Time complexity} is a term used to indicate the number of steps an algorithm must go through to reach a solution of a problem, expressed as a function of input size normally denoted \textit{n}.

Likewise, \textit{space complexity} as from it's name, relates to the amount of elementary units of ``memory" required by an algorithm. Space complexity is also understood under the same input size and in the situation of an algorithm defined probabilistic, both time and space complexities involve the \textit{predicted} numbers of steps and units of storage.
\\
\\
Algorithms involving finite fields, take for their elementary computation, field addition and/or field multiplication. This thesis will take an elementary computation as a multiplication between two field elements. It is to be made clear therefore that it follows that the algorithms computational complexity is not affected by the number of field additions that a particular algorithm is in need of. This choice of elementary computation is sufficient as we feel additions in the general case are performed at a quicker rate than compared to multiplications on computers and in the majority of algorithms, multiplications are not normally outnumbered by additions by an excessive quantity. The elementary storage unit is nearly always understood as a bit, and this the element size is log$_q$ for an element of $\mathbb{F}_q$. 

Two algorithms will now be defined in terms of time complexity - the \textit{Polynomial Time Algorithm} and the \textit{Exponential Time Algorithm}.

\begin{mydef}
Polynomial Time Algorithm
\end{mydef}

An algorithm whose worst-case running time function is of the form \textit{O(n$^k$)}, where \textit{n} is the input size and \textit{k} is a constant, is known to be a \textit{polynomial time algorithm}. Any algorithm whose time complexity is not so bounded is an \textit{exponential time algorithm}.
\\
\\
It is understood that polynomial time algorithms are \textit{efficient} whilst exponential-time algorithms are not such and considered \textit{inefficient}. Having stated this, these distinction rely on independent scenario's as for some practical situations they do not apply. The degree of polynomial is of great importance when thinking about polynomial-time complexity. If we consider an algorithm with running time \textit{O(n$^{ln(lnn)}$)}, where \textit{n} is the input size, then it is asymptotically slower if compared to an algorithm with running time \textit{O($n^{100}$)}. However, for smaller values of \textit{n}, particularly if the constants hidden by the \textit{big-O} notation are smaller, then the former algorithm may prove practically faster. But, the present discussion is in the light of worse-case complexities, we would like to remind the reader that in the field of cryptography, it is average-case complexity that is of more relevance rather than worst-case complexity. Moreover, a cryptanalysis problem that is on average difficult and not only for isolated cases is one that is understood as a secure combination for encryption schemes.
\\
\\
The ``big-O" notation was mentioned above when explaining running time for both time and space complexities. This notation is one that is commonly seen when discussing such complexities and the definiton to follow should suffice in understanding this important notation.
\\
\\
Let us remind the reader, despite having already explained the fundamental theorems and terms in group theory in this thesis, a well versed mathematical background would prove beneficial. 

\begin{mydef}
``Big-O" Notation
\end{mydef}

A function \textit{f(n) = Og(n)} if for a positive constant \textit{c\textgreater0} there exists a constant \textit{n$_0$} such that \textit{0 $\leq$ f(n) \textless cg(n)} for all \textit{n $\geq$ $n_0$}.
\\
\\
May we take this opportunity to also define the following:
\begin{enumerate}

\item \textit{(Asymptotic Lower Bound) f(n) = $\Omega$(g(n))} if constant \textit{c}\textgreater0 and integer \textit{n$_0$}\textgreater0 such that \textit{0 $\leq$ cg(n) $\leq$ f(n)} for all \textit{n$\geq$n$_0$}.

\item \textit{(Asymptotic Tight Bound) f(n) = $\Theta$(g(n))} if constants \textit{c$_1$, c$_2$} \textgreater 0 and integer \textit{n$_0$} \textgreater 0 so that \textit{c$_1$g(n)$\leq$f(n)$\leq$c$_2$g(n)} for all \textit{n}\textgreater\textit{n$_0$}. 
\\
\\
\textit{f(n) = O(g(n))} has the meaning that, compared to \textit{g(n)}, asymptotically \textit{f} grows no faster within a constant multiple whereas, \textit{f(m) = $\Omega$(g(n))} tells one that \textit{f(n)} at the minimum, grows at an equivalent rate asymptotically as \textit{g(n))} under the same context. There also exists a small o-notation, the definition of which is ditto to``Big-O" notation:

\item A function \textit{f(n) = o(g(n))} if for any positive constant \textit{n$_0$}\textgreater0 such that \textit{0 $\leq$ f(n) $\leq$ cg(n)} for all \textit{n$\geq$n$_0$}.

\end{enumerate}

Furthermore, \textit{f(n) = o(g(n))} has the meaning that \textit{g(n)} is not an asymptotically tight upper bound for function \textit{f(n)}. Alternatively this can be understood as \textit{f(n)} being insignificant relative to \textit{g(n)} as \textit{n} increases. The particular expression \textit{o(1)} most generally means:

\begin{center}
\textbf{$\lim_{n\to\infty}$ \textbar f(n)\textbar = 0}
\end{center}

\section{Public Key Cryptography with Discrete Logarithms}

Having covered the historic perspective and cryptographic developments in the literature review, it can justly be summarised that the key concept behind a public key cryptosystem is to allow one party \textit{A} to send an encrypted message \textit{m} to another party \textit{B} via the use of a publicly known encryption key \textit{e$_A$}. However, it is such that the encrypted message can only be decrypted by party \textit{B} by it's secret private decryption key denoted \textit{d$_A$}.

Computationally, \textit{d$_A$} must be infeasible to derive from the public encryption key \textit{e$_A$}. This certain computational property acts as a security measure against opponents/unauthorised parties, were they to attempt to eavesdrop during the transmission process of \textit{m} from \textit{A} to \textit{B}, and try to decrypt the message with knowledge of \textit{e$_A$}. 

It may have already been understood from previous reading that the public key cryptosystem was first proposed by Diffie and Hellman in \cite{NDCrypt} after which many further developments followed; the RSA public cryptosystem was invented by Rivest, Shamir and Aldeman. This system relied on the difficulty of the integer factorisation problem for it's security, whilst ElGamal published a public key system based on the discrete logarithm problem in the multiplicative group of a prime field in 1985[].  To cite an example of how a public key cryptosystem functions:

\begin{itemize}

\item Take \textit{p} to be a prime such that the discrete logarithm problem in ($\mathbb{Z}/\mathbb{Z}_p)^*$ is instractible, and \textit{a} is a generator of $\mathbb{Z}/\mathbb{Z}_{p}^*$.

\item Party \textit{A} decides on a secret key \textit{d$_A$}, (belonging to $\mathbb{Z}$) whilst alongside publishing it's public encryption key \textit{e$_A$} - the integer \textit{a$^{d_A}$}mod \textit{p}. 

\item On the other hand, party \textit{B} choose a random \textit{k}$\in\mathbb{Z}/(p-1)\mathbb{Z}$ for the encrypted message \textit{m} that it intends to send to \textit{A} to read. Once, \textit{k} is chosen, \textit{B} then computes the pair (\textit{y$_1$,y$_2$}), where

\begin{center}
\textit{y$_1$} = \textit{a$^k$}mod \textit{p}, \textit{y$_2$} = \textit{m$e^{k}_{A}$}mod \textit{p}.
\end{center}

Now as:

\begin{center}
\textit{$\frac{y_2}{y_1^{d_A}}$} $\equiv$ \textit{$\frac{me^{k}_{A}}{a^{kd_A}}$} $\equiv$ \textit{$\frac{ma^{kd_A}}{a^{kd_A}}$} $\equiv$ \textit{m}mod \textit{p},
\end{center}

it is now possible for party \textit{A} to decrypt \textit{m} by calculating the inverse of \textit{y$_1$}mod \textit{p} followed by the computation of \textit{y$_2(y_1^{-1})^{d_A}$}mod \textit{p}.

Now we describe two cryptographic protocols that are used in practical scenario's to achieve secret communication. They are of particular interest because the security of both these cryptosystems depends on the difficulty of computing discrete logarithms, outlining their importance and application to the field of cryptography. Both protocols see the use of parties \textit{A} and \textit{B}.

\end{itemize}

\subsection{The Diffie-Hellman Key Exchange}

To begin with we review the Diffie-Hellman key exchange protocol. This key agreement was the first solution to the key distribution problem (explained above) that enables two parties without prior acquaintance to establish a shared secret over an insecure connection/open channel. 

This procedure keeps the key protected from passive adversaries, however, fails to do so for active adversaries, which can intercept, modify or inject messages. Both parties don't have key authentication or entity authentication, hence the source identity of the incoming message or the identity of the party which could know the resulting key are known by either party. The Diffie-Hellman key agreement procedure is as follows:
\\
\\
\textbf{Diffie-Hellman Key Exchange}

\begin{enumerate}

\item \textit{One-time Setup.} \textit{A} and \textit{B} both select an appropriate prime \textit{p} and generator \textit{$\alpha$} of $\mathbb{Z^*_p}$ over the insecure channel.

\item \textit{Protocol messages:}

\begin{center}
\textit{A} $\longrightarrow$ \textit{B}: $\alpha^x$mod \textit{p} 
\\
\textit{A} $\longleftarrow$ \textit{B}: $\alpha^y$mod \textit{p}
\end{center}

\item \textit{Protocol actions.} Every time a shared key is needed then perform the following steps:

a) \textit{A} chooses a random secret \textit{x}, 1$\leq$ \textit{x} $\leq$ \textit{p} - 2 and sends \textit{B} the message 
\\ \textit{A} $\longrightarrow$ \textit{B}: $\alpha^x$mod \textit{p} .
\\
b) \textit{B} chooses a random secret \textit{y}, 1$\leq$ \textit{y} $\leq$ \textit{p} - 2 and sends \textit{A} the message 
\\ \textit{A} $\longleftarrow$ \textit{B}: $\alpha^y$mod \textit{p}.
\\
c) \textit{B} receives \textit{$\alpha^x$} and computes the shared key as \textit{K} = \textit{($\alpha^x)^y$}mod \textit{p}
\\
d) \textit{A} receives $\alpha^y$ and computes the shared key as \textit{K} = \textit{($\alpha^y)^x$}mod \textit{p}

\end{enumerate}

Though it may seem the Diffie-Hellman key agreement lets each party ensure key freshness and prevent key control, by using exponentiation by squaring (explained in next chapter) steps 2 and 3 can be computed efficiently.  However, a crucial fact is that both \textit{A} amd \textit{B}  arrive at equivalent random keys in step 3 because:

\begin{center} 
\textit{K} $\equiv$ \textit{B$^x$} $\equiv$ ($\alpha^y)^x$ $\equiv$ ($\alpha^x)^y$ $\equiv$ \textit{A$^y$}(mod \textit{p})
\end{center} 

This, therefore enables both parties to finalise a random secret key in $\mathbb{Z^{*}_p}$ without prior communication over their insecure channel. 

It further follows that for passive adversaries, computing \textit{K} = \textit{$\alpha^{xy}$}(mod \textit{p}) from \textit{A}:=\textit{$\alpha^x$}(mod \textit{p}) and \textit{B}:=$\alpha^y$(mod \textit{p}) directly would hold to be a challenging task, and is named the computational Diffie-Hellman (CDH) assumption.

This, therefore further leads to the summarisation that the greatest chance for one to obtain the secret key is by using the discrete logarithm to find \textit{a} = log$_\alpha$(\textit{A}) or \textit{b} = log$_\alpha$(\textit{B}), then compute \textit{K} = \textit{B$^a$}mod \textit{p}, or \textit{K} = \textit{A$^b$}mod \textit{p}. But, for suitable primes \textit{p}, the complexity assumption on the discrete logarithm problem indicates the task to be one of great difficulty thereby making the Diffie-Hellman key exchange quite secure.

\subsection{The ElGamal Cryptosystem}

The ElGamal Cryptosystem was first proposed by E.ElGamal in 1985, the security of this too relied on the complexity of computing discrete logarithms. In current times the default public key cipher to be used in cryptographic software such as GNU Privacy Guard is in fact the \textit{ElGamal Cryptosystem}. Below we outline briefly the cryptosystem:

\newpage
\textbf{Elgamal Cryptosystem}

\begin{enumerate}

\item \textit{One-time setup (key generation and publication)}. Every user \textit{B} does the following: 

\begin{itemize}
\item Pick an appropriate prime \textit{p} and generator $\alpha$ of $\mathbb{Z^*_p}$. 
\item Select a random integer \textit{b}, 1$\leq$\textit{b}$\leq$\textit{p }- 2 and compute \textit{$\alpha^b$}mod \textit{p}. This is the private key. \textit{B} then publishes it's public key (\textit{p},$\alpha,\alpha^b$), whilst private key \textit{b} is kept secret. 
\end{itemize}

\item \textit{Protocol messages:}

\begin{center}
\textit{A} $\longrightarrow$ \textit{B}: $\alpha^x$mod \textit{p} 
\end{center}

\item \textit{Protocol actions.} Every time a shared key is needed, the following steps are performed:

a) An authentic copy of \textit{B's} public key (\textit{p},$\alpha,\alpha^b$) is recieved by \textit{A}. \textit{A} now chooses a random integer \textit{x}, 1$\leq$\textit{x}$\leq$\textit{p} - 2, and sends \textit{B} the message \textit{A} $\longrightarrow$ \textit{B}: $\alpha^x$mod \textit{p}. The key \textit{K} = ($\alpha^b)^x$mod \textit{p} is computed by \textit{A}.
\\
b) Party \textit{B} computes the same key on reciept of the message \textit{A} $\longrightarrow$ \textit{B}: $\alpha^x$mod \textit{p} as \textit{K} = (\textit{$\alpha^x$})$^b$mod \textit{p}.

\end{enumerate}

From the above it is evident that in order to decrypt the message, an eavesdropper would need to share knowledge of the private key. In order to extract \textit{b} from the information collected, the adversary would need to compute the discrete logarithm, but if this is infeasible, then secure and private communication amongst both parties \textit{A} and \textit{B} is guaranteed. 





\chapter{Efficient Computations in Finite Fields}

This chapter is fully devoted to the concept of finite fields and their computational representations to allow the performance of different operations on them. Polynomials and ring integers are two such representations that we take high interest in this text, juxtaposition efficient arithmetic techniques and the computation of greatest common divisors (GCD's) will also be reviewed. Readers are to be made aware that all content discussed in this chapter is considered `preliminary', however, hold no direct connection to the coming chapters and so can be skipped if desired. This chapter considers ideas more known to be ``behind the scenes" than compared to those visible to the outside world or considered ``higher level" content, which is left to discuss in later chapters.

\section{Finite Field Representations}

It is of grave importance to understand that finite fields are abstract structures and so far any computation to be performed within them, they need a certain representation. The particular word representation can be described as such under this particular context - \textit{a solid description of all field elements involved and their interaction under binary operations of addition and multiplication.} 

Depending on the representation adapted, each has it's advantages and disadvantages in relation to the required CPU memory needed to represent an element of a field on a computer and the number of processor cycles needed to perform operations. 

In particular, focus shall remain on one representation for \textit{prime order fields} and one representation for \textit{prime power order fields} throughout, mainly because of the two being spontaneous, are likely to be familiar to the reader and are rather straight-forward to implement on a computer.

\subsection{Fields of Prime Order}

To begin with, we shall deal with fields of prime order more commonly understood as \textit{integer representation}. When dealing with such a representation the operations are of modular nature, i.e. modular arithmetic, including modular addition, subtraction, multiplication and division. 

As this thesis is not a study on, modular arithmetic, we shall not discuss it in detail, but instead briefly mention and explain related properties.

\subsubsection{Properties of Modular Arithmetic}

Consider the set $\mathbb{Z}_n$ as the non-negative integers less than \textit{n}:

\begin{center}
$\mathbb{Z}_n$ = \{0,1,...,(\textit{n} - 1)\}
\end{center}

This particular set is called the \textbf{set of residues}, in which every integer in $\mathbb{Z}_n$ represents a residue class. From all these, the smallest non-negative integer is mostly taken to be the one representing the residue class. Residue class (mod\textit{n}) can be labelled as \{0\}, \{1\}, \{2\},...,\{\textit{n} - 1\} where:

\begin{center}
{\textit{\{r\}}} = {\textit{\{a:a}} is an integer, {\textit{\{a\}}} $\equiv$ \textit{r}(mod) \textit{n}\}
\end{center}

To cite an example:
\begin{center}
The residue classes (mod4) are:
\\
\{0\} = \{...,-16, -12, -8, 0, 4, 0, 8, 12, 16,...\}
\\
\{1\} = \{...,-15, -11, -7, -3, 1, 5, 9, 13, 17,...\}
\\
\{2\} = \{...,-14, -10, -6, -2, 2, 6, 10, 14, 18,..\}
\\
\{3\} = \{...,-13, -9, -5, -1, 3, 7, 11, 15, 19,...\}
\end{center}

The properties of Modular Arithmetic for integers in $\mathbb{Z}_n$ can be summarised as such:

\begin{enumerate}
\item \textbf{Commutative Laws}

\begin{itemize}

\item (\textit{w} + \textit{x})mod \textit{n} = (\textit{x} + \textit{w})mod \textit{n}
\item (\textit{w} $\times$ \textit{x})mod \textit{n} = (\textit{x} $\times$ \textit{w})mod \textit{n}

\end{itemize}

\item \textbf{Associative Laws}

\begin{itemize}

\item ((\textit{w+x}) + \textit{y})mod \textit{n} = (\textit{w} + (\textit{x+y}))mod \textit{n}
\item ((\textit{w$\times$x}) $\times$ \textit{y})mod \textit{n} = (\textit{w} $\times$ (\textit{x$\times$y}))mod \textit{n}

\end{itemize}

\item \textbf{Distributive Law}

\begin{itemize}

\item (\textit{w} $\times$ (\textit{x+y}))mod \textit{n} = ((\textit{w$\times$x}) + (\textit{w$\times$y}))mod \textit{n}

\end{itemize}

\item \textbf{Identities}

\begin{itemize}

\item (0+\textit{w})mod \textit{n} = \textit{w}mod \textit{n}
\item (1$\times$\textit{w})mod \textit{n} = \textit{w}mod \textit{n}

\end{itemize}

\item \textbf{Additive Inverse (\textit{-w})}

\begin{itemize}

\item For each \textit{w}$\in\mathbb{Z}_n$ there exists a \textit{z} such that \textit{w}+\textit{z} $\equiv$ 0mod \textit{n}.

\end{itemize}

\end{enumerate}

Division in modular arithmetic is carried out by using the Extended Euclidean algorithm, which is also used to calculate multiplicative inverses and then perform a multiplication. The predecessor, Euclidean algorithm can be used to calculate greatest common divisors. Both Euclidean algorithms will not be considered in detail but the following theorem summarises the former:

\begin{theorem}
For any non-negative integer a and any positive integer b,
\end{theorem}

\begin{center}
gcd($a,b$) = gcd($b$, $a$mod$b$)
\end{center}

\begin{example}
gcd(55,22) = gcd(22, 55mod22) = gcd(22,11) = 11.
\end{example}

Meletiou and Mullen discuss fields of prime order and fields of prime power order in a very theoretical and mathematical perspective in \cite{NDL} to which readers are referred to if they desire to gain insight knowledge.

The next section discusses prime power order fields that are represented via polynomials.

\subsection{Finite Fields of Prime Power Order}

This representation involves the use of polynomials, in particular each polynomial coefficient. Nevertheless it is required that the polynomial be \textbf{irreducible}. When we say irreducible we mean ``a polynomial \textit{f}(\textit{x}) over a field $\mathbb{F}$ is \textbf{irreducible} if and only if \textit{f}(\textit{x}) can't be written as a product of two polynomials, both over $\mathbb{F}$, and both with a degree lower than that of \textit{f}(\textit{x}). By analogy to integers, an irreducible polynomial is also called a \textbf{prime polynomial}".
\\
\\
\textbf{Note 3:} We refer to the finite field $\mathbb{F}$ above to be of order \textit{p$^m$}.
\\
\\
\textbf{Fact 7} Let \textit{f}(\textit{x})$\in\mathbb{Z}_p$[\textit{x}] be an irreducible polynomial of degree \textit{m}. Then $\mathbb{Z}_p$[\textit{x}]/\textit{f}(\textit{x}) is a finite field of order \textit{p$^m$}. Addition and multiplication of polynomials is performed modulo \textit{f}(\textit{x}).

\subsubsection{Polynomial Arithmetic}

The fact to follow ensures that all finite fields can be represented through polynomials.
\\
\\
\textbf{Fact 8} For each \textit{m}$\geq$1, there exists a monic irreducible polynomial of degree \textit{m} over $\mathbb{Z}_p$. Therefore, every finite field has a polynomial basis representation. 
\\
\\
Determining polynomials that are irreducible over finite fields will be explained in a later section in this chapter. 

As for elements of the finite field $\mathbb{F}_{p^m}$, these can be represented by polynomials in $\mathbb{Z}_{p}$[\textit{x}] of degree less than \textit{m}. Say the two polynomials \textit{g}(\textit{x}) and \textit{h}(\textit{x}) belong to $\mathbb{F}_{p^m}$ it then follows that addition is the same as normal polynomial addition in $\mathbb{Z}_p$[\textit{x}]. The product \textit{g}(\textit{x})\textit{h}(\textit{x}) can be obtained by firstly multiplying \textit{g}(\textit{x}) and \textit{h}(\textit{x}) as polynomials via the ordinary method, and then dividing by \textit{f}(\textit{x}) and taking the remainder, (where \textit{f}(\textit{x}) denotes an irreducible polynomial$\in\mathbb{Z}_p$[\textit{x}]). As with integers, multiplicative inverses in $\mathbb{F}_{p^m}$ can also be calculated via the extended Euclidean algorithm for the polynomial ring $\mathbb{Z}_p[\textit{x}]$. 
\\
\\
To cite examples of polynomial arithmetic please consider the following: 

\begin{example}
Consider the finite field $\mathbb{F}_{2^4}$ (of order 16) and the irreducible polynomial \textit{f}(\textit{x}) = \textit{x}$^4$ + \textit{x} + 1 over $\mathbb{Z}_2$ (The irreducibility of \textit{f}(\textit{x}) can be verified with the algorithm presented in the next section). This then yields that the finite field $\mathbb{F}_{2^4}$ can be represented as the set of all polynomials over $\mathbb{F}_2$ of degree less than 4. So, 

\begin{center}
$\mathbb{F}_{2^4}$ = \{\textit{a}$_3$\textit{x}$^3$ + \textit{a}$_2$\textit{x}$^2$ + \textit{a}$_1$\textit{x} + \textit{a}$_0$ \textbar a$_i\in$\{0,1\}\}.
\end{center}

For simplicity, the polynomial \textit{a}$_3$\textit{x}$^3$ + \textit{a}$_2$\textit{x}$^2$ + \textit{a}$_1$\textit{x} + \textit{a}$_0$ can be seen as the vector (\textit{a}$_3$\textit{a}$_2$\textit{a}$_1$\textit{a}$_0$) with length 4, and

\begin{center}
$\mathbb{F}_{2^4}$ = \{(\textit{a}$_3$\textit{a}$_2$\textit{a}$_1$\textit{a}$_0$) \textbar   \textit{a}$_i\in$\{0,1\}\}.
\end{center}
\end{example}

The following present examples of field arithmetic:

\begin{enumerate}

\item Addition of field elements is done component wise: e.g. (1011) + (1001) $\equiv$ (0010).

\item The field elements (1101) and (1001) can be multiplied  as polynomials and then the remainder taken after this product is divided by \textit{f}(\textit{x}):

(\textit{x}$^3$ + \textit{x}$^2$ + 1)(\textit{x}$^3$ + 1) = \textit{x}$^6$ + \textit{x}$^5$ + \textit{x}$^2$ +1 $\equiv$ \textit{x}$^3$ + \textit{x}$^2$ + \textit{x} + 1 (mod \textit{f}(\textit{x})),

this implies that (1101)(1011) = (1111).

\item The multiplicative identity is $\mathbb{F}_{2^4}$ is (0001).

\item The inverse of (1011) is (0101). This can be verified by considering:

(\textit{x}$^3$ + \textit{x} + 1)(\textit{x}$^2$ + 1) = \textit{x}$^5$ + \textit{x}$^2$ + \textit{x} + 1 $\equiv$ 1mod (\textit{f}(\textit{x})), implying 

(1011)(0101) = (0001).

\end{enumerate}

\textit{f}(\textit{x}) is a primitive polynomial, or, equally, the field element \textit{x} = (0010) is a generator of $\mathbb{F}^{*}_{2}$. This can be proven by checking that all the non-zero elements in $\mathbb{F}_{2^4}$ can be obtained as powers of \textit{x}. The below table summarises computations of \textit{x modulo f}(\textit{x}).

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
\multicolumn{3}{|c|}{\textit{The powers of x modulo f(x) = $x^4 + x +1$}} \\
\hline
$i$ & $x^{i}$ mod $x^4 + x$ +1 & Vector Notation \\ \hline
0 & 1 & (0001) \\ 
1 & $x$ & (0010) \\
2 & $x^2$ & (0100) \\ 
3 & $x^3$ & (1000) \\
4 & $x+1$ & (0011) \\
5 & $x^2 + x$ & (0110)\\
6 & $x^3 + x^2$ & (1100)\\
7 & $x^3 + x +1$ & (1011)\\
8 & $x^2 + 1$ & (0101)\\
9 & $x^3 + x$ & (1010)\\
10 & $x^2 + x + 1$ & (0111)\\
11 & $x^3 + x^2 + x$ & (1110)\\
12 & $x^3 + x^2 + x + 1$ & (1111)\\
13 & $x^3 + x^2 +1$ & (1101)\\
14 & $x^3 + 1$ & (1001)\\
\hline
\end{tabular}
\end{center}

Considering the above from a computational perspective, it follows that a sufficient irreducible polynomial \textit{f}($x$) is first to be found to use as a modulus, after which implementation can follow accordingly. 

\subsection{Further Reading}

Despite having reviewed both integer and polynomial representation and arithmetic in this chapter, we would consider to mention \cite{NDL} again in which Meletiou and Mullen discuss both prime order and prime power order fields in grave mathematical detail. For deeper understanding on polynomial arithmetic please refer to \cite{CNS}, which gives a breakdown of polynomial arithmetic in a step-by-step manner.

\section{Discrete Exponentiation}

In continuation to the above subject of finite field arithmetic, this section considers the topic of exponentiation. Exponentiation is closely linked to the operation of multiplication in finite fields and is one of the most important arithmetic operations for public-key cryptography. Just to emphasise its important, the famous RSA scheme requires exponentiation in $\mathbb{Z}_m$ for some positive integer \textit{m}, similarly both the Diffie-Hellman key agreement and the ElGamal encryption scheme use exponentiation in $\mathbb{Z}_p$ for some large prime \textit{p}.

Coming back to the discrete logarithm problem, as difficult as it's solution may be believed to be, it is also believed to be an example of a one-way function and it turns out that it is easier to define it as it's inverse - the discrete exponentiation function. We refer to the discrete exponentiation as the analogue of the well known exponentiation, but occurring in a finite cyclic group. 

\begin{mydef}
Discrete Exponentiation
\end{mydef}

\textit{G} is a finite cyclic group of order \textit{n}, written multiplicatively, and let $\alpha$ be a generator of \textit{G}. The discrete exponentiation function is then defined as would be expected:

\begin{center}
exp$_\alpha$: $\mathbb{Z}_n  \longrightarrow \textit{G},   \textit{x} \longmapsto \textit{$\alpha$}^x$
\end{center}

It follows that the elements $\alpha^i$ for \textit{i} in $\mathbb{Z}_n$ are unique from one another as $\alpha$ is a generator of \textit{G} with order \textit{n}. The map exp$_\alpha$ can therefore be called injective, yet the domain $\mathbb{Z}_n$ and the range \textit{G} of this map both contain \textit{n} elements meaning exp$_\alpha$ is actually bijective. Now the simple method of computing this function involves repeatedly multiplying \textit{$\alpha$} by itself $x$-1 times \textit{$\alpha$}$^x$ = $\overbrace{\alpha...\alpha}^x$ needing \textit{O}($x$) group operations. Nevertheless, there exists a much more superior and efficient technique and the next section is dedicated to this very technique.

\section{Exponentiation by Squaring}

Exponentiation by squaring allows a faster exponentiation method by exploiting the binary representation of the exponent \textit{x} = (\textit{x}$_{k-1}$,...,\textit{x}$_1$\textit{x}$_0$)$_2$. Before we continue let us note that,

\begin{center}
\textit{x} = $\displaystyle\sum\limits_{j=0}^{k-1} x_{j}2^j$ = $\displaystyle\sum\limits_{x_{j}=1} 2^j$
\end{center}

It follows that \textit{$\alpha$}$^x$ can then be written as:

\begin{center}
\textit{$\alpha$}$^x$ = \textit{$\alpha$}$^{\displaystyle\sum\nolimits_{x_i = 1} 2^i}$ = $\displaystyle\prod\limits_{x_i = 1} \textit{$\alpha$}^{2^i}$
\end{center}

Further,

\begin{center}
${\textit{$\alpha$}^{2}}^{i}$ = ${({\textit{$\alpha$}^{2}}^{i-1})}^2$
\end{center}

${\textit{$\alpha$}^{2}}^{i}$ can be found by successive use of single squaring. It can then be said that the number of required group operations to compute \textit{$\alpha$}$^x$ is dependent on the binary length of \textit{x}!

Exponentiation by squaring can be recursively expressed as such:

\begin{center}
exp$_\alpha$(\textit{x}) := $\left\{
\begin{array}{l l l}
	1, & \quad \textrm{if $x$ = 0}\\
	exp_{\alpha}^2(x/2), & \quad \textrm{if $x$ is even}\\
	\textit{$\alpha$}.exp_{\alpha}^2((\textit{x}-1)/2), & \quad \textrm{if $x$ is odd}\\
\end{array} \right.$
\end{center}

The key advantage of exponentiation by squaring is that it is extremely fast in it's algorithmic calculation, no matter how large the value of $x$ is. This is because the maximum number of multiplication and squaring operations it requires is equal to the length of the binary version of the input. Therefore, this method has a runtime of only $O$(log$_2$($x$)). We can continue that the properties of groups ensures $\alpha^{-1}$ = ${(\alpha^x)}^{-1}$ adapting this method to also be usable when involving negative exponents exp$_\alpha$(-$x$), given that the elements can be inverted. 
\\
\\
The following presents an algorithm for computing exponentiation by squaring:

\begin{algorithm}
\caption{Exponentiation by Squaring}
\begin{algorithmic} 
\REQUIRE $\alpha$ in $G$ and $x$ in $\mathbb{Z}$ with a multiplicative cyclic group $G$
\ENSURE $\beta$ = $\alpha^x$
\begin{enumerate}
\STATE $\beta \leftarrow 1$ /* 1 is the identity element of $G$ */
\WHILE{$x > 0$}
\IF{$x$ is odd} 
\STATE $\beta \leftarrow \beta \times \alpha$
\STATE $x \leftarrow x - 1$
\ENDIF
\STATE $\beta \leftarrow \beta^2$
\STATE $x \leftarrow x/2$
\ENDWHILE
\end{enumerate}
\end{algorithmic}
\end{algorithm}

\section{Irreducible Polynomials}

If we recall,  a polynomial \textit{f}($x$)$\in\mathbb{Z}_p$[$x$] of \textit{m}$\geq$1 is \textit{irreducible over} $\mathbb{Z}_p$ if it can't be written as a product of two polynomials in $\mathbb{Z}_p$[$x$]. each with degree less than $m$. \textit{f}($x$) allows elements of the finite field $\mathbb{F}_{p^m}$ as $\mathbb{F}_{p^m}$ = $\mathbb{Z}_p$[$x$]/\textit{f}($x$), with all polynomials in $\mathbb{Z}_p$[$x$] of degree \textless $m$ and polynomials is carried out modulo \textit{f}($x$).

We present in this section a method through how irreducible polynomials can be constructed over $\mathbb{Z}_p$ in which $p$ is a prime. For crytpographic applications however, finite fields of characterstic two $\mathbb{F}_{2^m}$ are of particular interest as these fields allow efficient arithmetic performance in both software and hardware. Hence, irreducible polynomials over $\mathbb{Z}_2$ are of close attention.

If the chosen irreducible polynomial has few non-zero terms then finite field arithmetic is made more efficient to implement. Consider \textit{f}($x$) to be an irreducible polynomial over $\mathbb{Z}_p$ a non-zero element in $\mathbb{Z}_p$, it then follows that a \textit{f}($x$) is also irreducible over $\mathbb{Z}_p$. It can therefore be said that we can limit our focus down to monic polynomials in $\mathbb{Z}_p$ polynomials which have a leading co-efficient of 1. This therefore means if \textit{f}($x$) is an irreducible polynomial, it's constant term has to then be non-zero, especially in the case when \textit{f}($x$)$\in\mathbb{Z}_2$[$x$], for which it's constant term must be 1. 

There exists a formula for calculating the exact number of monic irreducible polynomials in $\textit{Z}_p$[\textit{x}] with fixed degree, via the aid of a function called the M\"obius function.

\begin{mydef}
Let m be a particular integer. The M\"obius function $\mu$ is defined by, 

\begin{center}
$\mu$(m)= $\left\{
\begin{array}{l l l}
	1, & \quad \textrm{if m = 1}\\
	0, & \quad \textrm{if m is divisible by the square of a prime}\\
	-1^{k}, & \quad \textrm{if m is the product of k distinct primes}\\
\end{array} \right.$
\end{center}

\end{mydef}

\begin{example} (M\"obius function)
\\
\\
The table below shows the first 10 values of $m$ for the Mobi\"ous function $\mu$(m): 

\begin{table}[ht]
\caption{First 10 values of Mobi\"ous function}
\centering
\begin{tabular}{|c||c|c|c|c|c|c|c|c|c|c|}
\hline
\textit{m} & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\ [0.5ex]
\hline
$\mu$($m$) & 1 & -1 & -1 & 0 & -1 & 1 & -1 & 0 & 0 & 1 \\ [1ex]
\hline
\end{tabular}
\label{table:nonlin}
\end{table} 
\hfill $\Box$

\end{example}

\subsection{Testing for irreducibility}

We now present an algorithm which allows for testing a polynomial for irreducibility. In comparison to testing primality  of integers, testing polynomials for irreducibility in $\mathbb{Z}_p$[$x$] is much simpler. All that has to be done is test whether a polynomial has no irreducible factors with degree $\leq$ [$m$/2].
\\
\\
\textbf{Fact 9} Consider \textit{p} a prime and \textit{k} a positive integer:

\begin{enumerate}

\item The product of all monic irreducible polynomials in $\mathbb{Z}_p$[$x$] of degree dividing \textit{k} is equivalent to ${\textit{x}^p}^k$ - $x$.

\item Allow \textit{f}($x$) to be a polynomial with degree $m$ in $\mathbb{Z}_p$[$x$]. \textit{f}($x$) is then irreducible over $\mathbb{Z}_p$ iff gcd(\textit{f}($x$), ${\textit{x}^p}^k$ - $x$) = 1 for every $i$, 1 $\leq$$i$$\leq$[$m$/2]. 

\end{enumerate}  

\begin{algorithm}
\caption{Testing a polynomial for irreducibility}
\begin{algorithmic}
\REQUIRE a prime $p$ and a monic polynomial \textit{f}($x$) of degree $m$ in $\mathbb{Z}_p$[$x$]
\ENSURE an answer to the question "Is \textit{f}($x$) irreducible over $\mathbb{Z}_p$?"
\begin{enumerate}
\STATE $u(x) \leftarrow x$ 
\FOR {$i=1$ from 1 \TO [m/2]}
\STATE  - Compute $u(x) \leftarrow u(x)^p$ mod $f(x)$ using the \textit{Repeated square-and-multiply algorithm for exponentiation in $\mathbb({F}_{p^m})$}. (Note that $u(x)$ is a polynomial in $\mathbb{Z}_p[x]$ of degree less than $m$)
\STATE  - Compute $d(x)$ = gcd($f(x),u(x)-x$)(Using the Euclidean Algorithm for $\mathbb{Z}_p[x]$
\STATE  - If $d(x) \neq 1$ then return("irreducible")
\ENDFOR
\STATE \textbf{return}("irreducible")
\end{enumerate}
\end{algorithmic}
\end{algorithm}

\newpage 

\subsection{Generating irreducible polynomials}

We now present an algorithm for generating a random monic polynomial over $\mathbb{Z}_p$.

\begin{algorithm}
\caption{Generating a random monic irreducible polynomial over $\mathbb{Z}_p[x]$}
\begin{algorithmic}
\REQUIRE a prime $p$ and a positive integer $m$
\ENSURE a monic irreducible polynomial \textit{f}($x$) of degree $m$ in $\mathbb{Z}_p$[$x$]
\begin{enumerate}
\STATE Repeat the following:
\STATE (\textit{Generate a random monic polynomial of degree m in $\mathbb{Z}_p[x]$}). Randomly select integers $a_0$, $a_1$, $a_2$,...,$a_{m-1}$ between 0 and $p$ - 1 with $a_0$ $\neq$ 0. Let $f(x)$ be the polynomial $f(x)$ = $x^m$ + $a_{m-1}x^{m-1}$ +...+$a_{2}x^{2}$+$a_{1}x$+$a_0$
\STATE Use Algorithm 2 to test whether $f(x) $ is irreducible over $\mathbb{Z}_p$
\STATE Until $f(x)$ is irreducible 
\STATE \textbf{return}($f(x)$)
\end{enumerate}
\end{algorithmic}
\end{algorithm}

\section{Primitive Polynomials}

\begin{mydef}
An irreducible polynomial f(x) $\in \mathbb{Z}_{p}$[x] of degree $m$ is called a primitive polynomial if $x$ is a generator of $\mathbb{Z}_{p^m}^{*}$, the multiplicative group of all the non-zero elements in $\mathbb{F}_{p^m} = \mathbb{Z}_{p}$[x]/(f(x)).
\end{mydef}

If the factorisation of the integer $p^{m}$ - 1 is known, Fact 5 then holds true an effective algorithm (Algorithm 4) to assess if $f(x)$ is a primitive polynomial or not. However, if the factorisation of $p^m$ - 1 is not known then there is no algorithm known for this test.
\\
\\
\textbf{Fact 10} Consider $p$ to be prime and let the unique prime factors of $P^m$-1 be $r_1,r_2,...,r_t$. It then follows that an irreducible polynomial $f(x) \in \mathbb{Z}_p$[$x$] is primitive iff for each $i$, $1 \leq i \leq t$: 

\begin{center}
$x^{(p^{m} - 1)/{r_i}} \not\equiv 1$ (mod $f(x)$).
\end{center}

(Such that, $x$ is an element of order $p^{m}-1$ in the field $\mathbb{Z}_{p}[x]/(f(x))$.)
\\
\\
The next page outlines an algorithm for testing if an irreducible polynomial is primitive or not.

\begin{algorithm}
\caption{Testing whether an irreducible polynomial is primitive}
\begin{algorithmic}
\REQUIRE a prime $p$, a positive integer $m$, the unique prime factors $r_1, r_2,...,r_t$ of $p^m$ -1, and a monic irreducible polynomial $f(x)$ of degree $m$ in $\mathbb{Z}_{p}$[$x$].
\ENSURE An answer to the question: ``Is $f(x)$ a primitive polynomial?"
\begin{enumerate}
\FOR{$i$ from 1 $t$}
\STATE 1.1 Compute $l(x) = x^{(p^{m}-1)/{r_i}}$mod $f(x)$ (Using Algorithm 8).
\STATE 1.2 If $l(x) = 1$ thn \textbf{return}(``not primitive").
\ENDFOR
\STATE \textbf{Return}(``primitive").
\end{enumerate}
\end{algorithmic}
\end{algorithm}

\newpage

Precisely there exists $\phi(p^{m}-1)/m$ monic primitive polynomials with degree $m$ in $\mathbb{Z}_p$[$x$], i which the Euler phi function is $\phi$. As the quantity of monic irreducible polynomials with degree $m$ is approximately $p^{m}/m$, it holds true that the likelihood of a random monic irreducible polynomial with degree $m$ in $\mathbb{Z}_p$[$x$] is primitive is roughly $\phi(p^{m}-1)/p^{m}$. Considering the lower bound for the Euler phi function, there is at minimum 1/(6lnln$p^m$) possibility that this can be seen. This then yields the algorithm outlined below for generating primitive polynomials.

\begin{algorithm}
\caption{Generating a random monic primitive polynomial in $\mathbb{Z}_p$}
\begin{algorithmic}
\REQUIRE a prime $p$, integer $m \geq 1$, and the unique prime factors $r_1, r_2,...,r_t$ of $p^m$ -1.
\ENSURE A monic primitive polynomial $f(x)$ of degree $m$ in $\mathbb{Z}_p$[$x$].
\begin{enumerate}
\STATE Repeat the following until $f(x)$ is primitive:
\STATE Use Algorithm 3 to generate a random monic irreducible polynomial $f(x)$ of degree $m$ in $\mathbb{Z}_{p}$[$x$]
\STATE Use Algorithm 4 to test whether $f(x)$ is primitive
\STATE \textbf{Return}($f(x)$).
\end{enumerate}
\end{algorithmic}
\end{algorithm}

\subsection{Further Reading}

We can understand the level of relevance and importance irreducible polynomials carry for finite fields of prime power order. It is through this property that polynomials can be used to represent finite fields GF(\textit{p}$^m$). Integer representation in $\mathbb{Z}_p$ allows for modular arithmetic whilst representation in GF(\textit{p}$^m$) asks for polynomial modular arithmetic also known as finite filed arithmetic. In addition to the material discussed in this chapter, finite field representation also touches the topic of irredicuble trinomials, which have not been discussed in this chapter as they pose to be extra knowledge on the subject of polynomials. For this reason we recommend readers refer to \cite{HAC} Handbook of Applied Cryptography for further knowledge on this subject and in depth detail on monic polynomials, which have been very briefly considered in review of this chapter.




\chapter{Determining the Discrete Logarithm}

We now consider the different algorithms that exist for solving the discrete logarithm problem. Through presenting these algorithms we shall adapt an understanding on why it is believed to be computationally difficult and study the time and space complexities of the different algorithms. 

The algorithms can be grouped into two categories \textit{generic} and \textit{non-generic}. We first present algorithms belonging to the generic class in the following order:

\begin{enumerate}

\item Brute Force Search 

\item Shanks' ``Baby-Step Giant-Step" Method

\item Pollard's $\rho$ Algorithm for logarithms (1978)

\item Pohlig-Hellman Algorithm (1978)

\end{enumerate}

The chapter then reviews an algorithm which is of ``\textit{non-generic"} nature called the Index-Calculus Algorithm. Till date this algorithm is said to accomplish the lowest complexities known. The Index-Calculus Algorithm is specific only to finite fields and $\mathbb{Z}^{*}_{p}$ which are the key interest of this text, whilst the generic group algorithms are applicable over any type of cyclic group, including elliptic curves groups and subgroups of $\mathbb{Z}^{*}_{p}$, where more efficient methods are not known to apply. 

Any of the techniques discussed in the previous chapter for efficient computations in finite fields can be used in implementing these algorithms, and readers are to understand the pseudocode's and examples illustrated in this chapter are under the context of the finite field $\mathbb{F}_p$ for ease of understanding and explanatory purposes. For finite field $\mathbb{F}_{2^n}$ we are to take the input as irreducible polynomials of the form $f(x)$ and $g(x)$ and the mathematical operations as polynomial arithmetic, unless stated.

\section{Procedures in Generic Discrete Logarithm Algorithms}

Before moving on to present and discuss the generic Discrete Logarithm Algorithms we would here like to first briefly present the procedures that the algorithms individually use to obtain $x$ = log$_{\alpha}\beta$.

\subsection{Extended Euclidean Algorithm}

The \textit{Extended Euclidean Algorithm} is an extension of its predecessor the Euclidean Algorithm and is used to compute the greatest common divisor $d$ of two integers $a$ and $b$ alongside integers $x$ and $y$ that satisfy the property $ax + by =d$.

\begin{algorithm}
\caption{Extended Euclidean Algorithm}
\begin{algorithmic}
\REQUIRE Two non-negative integers $a$ and $b$ with $a \geq b$
\ENSURE $d$ = gcd($a, b$) and integers $x$, $y$ satisfying $ax + by = d$
\begin{enumerate}
\IF{$b$ = 0} 
\STATE $d \leftarrow a, x \leftarrow 1, y \leftarrow 0$, and \textbf{return}($d,x,y$)
\ENDIF
\STATE Set $x_{2} \leftarrow 1, x_{1} \leftarrow 0, y_{2} \leftarrow 0, y_{1} \leftarrow 1$
\WHILE{$b > 0$}
\STATE $q \leftarrow [a/b], r \leftarrow a-qb, x \leftarrow x_{2}-qx_{1}, y \leftarrow y_{2}-qy_{1}$
\STATE $a \leftarrow b, b \leftarrow r, x_{2} \leftarrow x_{1}, x_{1} \leftarrow x, y_{2} \leftarrow y_{1}$, and $y_{1} \leftarrow y$
\ENDWHILE 
\STATE Set $d \leftarrow a, x \leftarrow x_{2}, y \leftarrow y_{2}$, and \textbf{return}($d,x,y$)
\end{enumerate}
\end{algorithmic}
\end{algorithm}

The above procedure has a running time of $O$((log$n$)$^2$) bit operations.

\begin{example}{(Extended Euclidean Algorithm)}
\end{example}

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
\hline
\multicolumn{10}{|c|}{\textit{Extended Euclidean Algorithm with inputs a} = 4864, $b$ = 3458}\\
\hline
$q$ & $r$ & $x$ & $y$ & $a$ & $b$ & $x_{2}$ & $x_{1}$ & $y_{2}$ & $y_{1}$ \\ \hline\hline
- & - & - & - & 4864 & 3458 & 1 & 0 & 0 & 1 \\ 
1 & 1406 & 1 & -1 & 3458 & 1406 & 0 & 1 & 1 & -1 \\ 
2 & 646 & -2 & 3 & 1406 & 646 & 1 & -2 & -1 & 3 \\ 
2 & 114 & 5 & -7 & 646 & 114 & -2 & 5 & 3 & -7 \\ 
5 & 76 & -27 & 38 & 114 & 76 & 5 & -27 & -7 & 38 \\ 
1 & 38 & 32 & -45 & 76 & 38 & -27 & 32 & 38 & -45 \\ 
2 & 0 & -91 & 128 & 38 & 0 & 32 & -91 & -45 & 128 \\ 
\hline
\end{tabular}
\end{center}

The table overleaf outlines the steps of Algorithm 6 with inputs $a$ = 4864 and $b$ = 3458. Therefore gcd(4864,3458) = 38 and (4864)(32) + (3458)(-45) = 38.
\hfill $\Box$

\subsection{Multiplicative Inverse}

\begin{algorithm}
\caption{Computing multiplicative inverses in $\mathbb{Z}_n$}
\begin{algorithmic}
\REQUIRE $a \in \mathbb{Z}_n$
\ENSURE $a^{-1}$mod $n$, provided that it exists
\begin{enumerate}
\STATE Use the extended euclidean algorithm (Algorithm 6) to find integers $x$ and $y$ such that $ax + ny = d$, where $d$ = gcd($a, n$)
\IF{$d > 1$}
\STATE $a^{-1}$ mod $n$ does not exist. Otherwise, \textbf{return}($x$)
\ENDIF
\end{enumerate}
\end{algorithmic}
\end{algorithm}

\subsection{Square-and-Multiply}

\begin{algorithm}
\caption{Repeated square-and-multiply algorithm for exponentiation in $\mathbb{Z}_n$}
\begin{algorithmic}
\REQUIRE $a \in \mathbb{Z}_n$, and integer 0 $\leq k < n$ where $k$ = $\displaystyle\sum\nolimits_{i = 0}^t k_{i}2^i$
\ENSURE $a^{k}$mod$n$
\begin{enumerate}
\STATE $b \leftarrow 1$. 
\STATE \textbf{if} $k$ = 0 then \textbf{return}($b$)
\STATE \textbf{end if}
\STATE Set $A \leftarrow a$
\STATE \textbf{if} $k_0$ = 1 then set $b \leftarrow a$
\STATE \textbf{end if}
\STATE \textbf{for} $i$ from 1 to $t$ \textbf{do}
\\		
7.1 Set $A \leftarrow A^2$ mod $n$
\\
7.2 \textbf{if} $k_i$ = 1 then set $b \leftarrow A \times (b$mod $n$)
\STATE \textbf{end if}
\STATE \textbf{end for}
\STATE \textbf{return}($b$)
\end{enumerate}
\end{algorithmic}
\end{algorithm}

\subsection{Chinese Remainder Theorem, CRT}

 If the integers $n_1, n_2, ... , n_k$ are pairwise relatively prime, then the system of simultaneous congruences

\begin{center}
$x \equiv a_1$ (mod $n_1$)
\\
$x \equiv a_2$ (mod $n_2$)
\\
$\vdots$
\\
$x \equiv a_k$ (mod $n_k$)
\end{center}

has a unique solution modulo $n$ = $n_{1}n_{2}...n_{k}$.

\subsection{Gauss's Algorithm}

 The solution $x$ to the simultaneous congruences in the Chinese Remainder Theorem can be computed as $x = \displaystyle\sum\nolimits_{i = 1}^k a_{i}N_{i}M_{i}$ mod $n$, where $N_{i} = n/n_{i}$ and $M_{i} = N_{i}^{-1}$ mod $n_i$. These computations require $O(($log$n)^2)$ bit operations.

\subsection{Floyd's Cycle-finding algorithm}

\textit{Floyd's Cycle-finding algorithm} begins with the pair ($x_1$, $x_2$), and iteratively computes ($x_i, x_{2i}$) from a pre-computed pair ($x_{i-1}, x_{2i-2}$), until $x_m = x_{2m}$ for some $m$. If the tail of the sequence has length $\lambda$ and the cycle has length $\mu$, then the first occurance of $x_m = x_{2m}$ is at the point when $m = \mu(1+[\lambda/\mu])$. We note here that $\lambda < m \leq \lambda + \mu$, and as a result the anticipated running time of Floyd's cycle-finding algorithm is $O(\sqrt{n})$.

\section{Generic Discrete Logarithm Algorithms}

We now present the generic Discrete Logarithm Algorithms. Alongside analysesand description we will also present pseudocode for each and the variable structure will be as such:

\begin{itemize}
\item $\alpha$ = Generator of the cyclic group \textit{G}
\item $\beta$ = An element of \textit{G}
\item \textit{n} = The order of the group \textit{G}
\end{itemize}

\newpage 

\subsection{Brute-Force Search}

The first and foremost approach in solving the discrete logarithm problem would be to begin with the simplest method, Brute-Force (This method can be referred to as \textit{Exhaustive Search} or \textit{Trial Exponentiation}.) This approach simply involves trying every possible exponent ($\alpha^0, \alpha^1, \alpha^2...$) until a match is obtainable i.e. until $\alpha^x = \beta$. 

\begin{algorithm}
\caption{Brute-Force Search}
\begin{algorithmic}
\REQUIRE A generator $\alpha$, group element $\beta$ and cyclic group $G$ of order $n$
\ENSURE The discrete logarithm $x$ = log$_{\alpha}\beta$
\begin{enumerate}
\STATE $b \Leftarrow 1$
\STATE $x \Leftarrow 0$
\WHILE{$\beta \neq b$}
\STATE $b \Leftarrow b \times \alpha$
\STATE $x \Leftarrow x + 1$
\ENDWHILE
\STATE \textbf{return} $x$
\end{enumerate}
\end{algorithmic}
\end{algorithm}

The point at which $\alpha^x = \beta$, determines the solution $x$ (the discrete logarithm). Please refer back to Chapter 3 of this text to review the Discrete Logarithm problem in detail. Yet, this method is inefficient when dealing with too large a number $n$ i.e. the group order is exceedingly large (particularly for cryptographic interest.) This is becasue, as with the general case, the brute-force requires $O(n)$ group operations to run.

\subsection{Shanks' ``Baby-Step Giant-Step" Algorithm}

The next algorithm presented to solve the discrete logarithm problem is known as Shanks' ``Baby-Step Giant-Step" Algorithm, which was proposed by D.Shanks and is a time memory trade-off of the \textit{brute-force search}. As from it's name, it consists of two stages: the first stage involves consecutively stepping through the first $j$ powers of $\alpha^j : \alpha^1, \alpha^2,...,\alpha^{j-1}$ known as the \textbf{``Baby-Steps"} of the algorithm. Each exponent value $j$ is stored in a hash table/list, which is indexed by $\alpha^j$. After completing $j$ steps, we have a discrete logarithm table coinciding however, to only the first $j$ elements of the cyclic group.

The \textbf{``Giant-Steps"} are based on the following observation, if $\beta = \alpha^x$, then it is possible to write $x=im + j$ where $m = \sqrt{n}$, $j<m$ and $0 \leq i$. It follows that:

\begin{center}
$\alpha^x = \alpha^{im}\alpha^j $
\\
$\Rightarrow \beta(\alpha^{-m})^{i} = \alpha^j$
\end{center}

meaning that in this second stage the input $\beta = \alpha^x$ is transformed into a value which lies in the precomputed discrete logarithm range. We begin at $\alpha^x$ and check through the cyclic group at $x$ elements at a time until we reach the beginning of the cycle of the precomputed logarithms. This then leads to the algorithm outlined below for computing $x$:

\begin{algorithm}
\caption{Shanks' ``Baby-Step Giant-Step" Algorithm}
\begin{algorithmic}
\REQUIRE A generator $\alpha$, group element $\beta$ and cyclic group $G$ or order $n$
\ENSURE The discrete logarithm $x$ = log$_{\alpha}\beta$
\begin{enumerate}
\STATE Set $m \leftarrow \sqrt{n}$
\STATE Construct a table with entries ($j, \alpha^j$) for $0 \leq j \leq m$. Sort this table by second component
\STATE Compute $\alpha^{-m}$ and set $\gamma \leftarrow \beta$
\FOR {$i$ from 0 \TO $m$-1}
\STATE 4.1 Check if $\gamma$ is the second component of some entry in the table
\STATE 4.2 If $\gamma = \alpha^j$ then \textbf{return}($x = im + j$)
\STATE 4.3 Set $\gamma \leftarrow \gamma \times \alpha^{-m}$
\ENDFOR
\end{enumerate}
\end{algorithmic}
\end{algorithm}

Algorithm 10 needs a storage space for holding $O$($\sqrt{n}$) number of group elements. The table in step 2 requires $O$($\sqrt{n}$) multiplications to make and $O$($\sqrt{n}$log$n$) comparisons to sort. Once the table has been constructed, step 4 then takes $O$($\sqrt{n}$) table look-ups. We here assume that a group multiplication takes longer than log$n$ comparisons, the running time of Shanks' Algorithm is as such.
\\
\\
\textbf{Fact 11} The running time of Algortihm 5 is $O$($\sqrt{n}$) group multiplications.
\begin{example} Shanks' ``Baby-Step Giant-Step" Algorithm for logarithms in a cyclic group $G$.
\end{example}

Let $p$ = 113. The element $\alpha$ = 3 is a generator of  cyclic group $G$ of order $n$ = 112. Consider $\beta$ = 57. Then log$_{3}57$ is computed as follows. 

\begin{enumerate}
\item Set $m$ $\leftarrow$ 112 = 11.
\item Construct a table whose entries are ($j$, $\alpha^j$ mod$p$) for 0 $\leq j < 11$: 
\begin{table}[ht]
\centering
\begin{tabular}{|c||c|c|c|c|c|c|c|c|c|c|c|}
\hline
\textit{j} & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\ [0.5ex]
\hline
3$^j$ mod113 & 1 & 3 & 9 & 27 & 81 & 17 & 51 & 40 & 7 & 21 & 63 \\ [1ex]
\hline
\end{tabular}
\label{table:nonlin}
\end{table} 

and sort the table by second component:

\begin{table}[ht]
\centering
\begin{tabular}{|c||c|c|c|c|c|c|c|c|c|c|c|}
\hline
\textit{j} & 0 & 1 & 8 & 2 & 5 & 9 & 3 & 7 & 6 & 10 & 4 \\ [0.5ex]
\hline
3$^j$ mod113 & 1 & 3 & 7 & 9 & 17 & 21 & 27 & 40 & 51 & 63 & 81 \\ [1ex]
\hline
\end{tabular}
\label{table:nonlin}
\end{table} 

\item Using the multiplicative inverse method, compute $\alpha^{-1} = 3^{-1}$mod 113 = 38 and then compute $\alpha^{-m} = 38^{-11}$ mod 113 = 58.
\item Next $\gamma = \beta\alpha^{-mi}$mod 113 for $i$ = 0,1,2,... is computed until a value in the second row of the table is obtained. This yields:

\begin{table}[ht]
\centering
\begin{tabular}{|c||c|c|c|c|c|c|c|c|c|c|}
\hline
\textit{i} & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\ [0.5ex]
\hline
$\gamma = 57 \times 58^{i}$mod 113 & 57 & 29 & 100 & 37 & 112 & 55 & 26 & 39 & 2 & 3 \\ [1ex]
\hline
\end{tabular}
\label{table:nonlin}
\end{table} 

Finally, since $\beta\alpha^{-9m}$ = 3 = $\alpha^1$, $\beta = \alpha^{100}$ and, therefore, log$_{3}$57 = 100.
\hfill $\Box$
\end{enumerate}

\textbf{Note 4:} Step 3 of Algorithm 10 uses the \textit{multiplicative inverse}, (Algorithm 7) whilst step 4 requires the use of the \textit{square-and-multiply} method (Algorithm 8) for $\gamma = \beta\alpha^{-mi}$ especially when dealing with large power values.

\subsection{Pollard's $\rho$ Algorithm for Discrete Logarithms}

The next algorithm we present is known as Pollard's $\rho$ (pronounced ``Rho") Algorithm for logarithms.
We would like to mention here that another algorithm with the same name i.e. Pollard's $\rho$ method exists, however is of a different nature to the current topic of discussion. Both algorithms however, have been proposed by J.Pollard in 1978, the former being for discrete logarithms whilst the latter deals with prime factorisation.

This third algorithm shares an equivalent running time to that of Algorithm 10 - Shanks' ``Baby-Step Giant-Step" Algorithm, however is practically more efficient and prefferabe due to it's negligable storage requirement. 

It is currently the most generic algorithm known for computing discrete logarithms and is a randomised algorithm because it's time complexity is derived from an assumption based on a pseudorandom sequence as outlined below:
\\
\\
Take $S_1$, $S_2$ and $S_3$ to be three equally sized sets of a partitioned group $G$. The set size of each is to be based on a trivially testable property and when selecting the partition, care must be taken, e.g. 1 $\notin S_2$. A sequence of group elements $x_0, x_1, x_2,...$ with $x_0$ = 1 can then be defined and

\begin{equation}\label{}
x_{i+1}= f(x_i) = \left\{
\begin{array}{l l l}
	\beta \times x_i, & \quad \textrm{if} x_i \in S_1\\
	x_{i}^2, & \quad \textrm{if} x_i \in S_2\\
	\alpha \times x_i, & \quad \textrm{if} x_i \in S_3\\
\end{array} \right.
\end{equation}

for $i \geq 0$. Following (5.1), two further integer sequences (5.2) and (5.3) can be derived for $a_0, a_1, a_2,...$ and $b_0, b_1, b_2,...$ which satisfies $x_i = \alpha^{a_i}\beta^{b_i}$ for $i \geq 0 : a_0 = 0, b_0 = 0$ and for $i \geq 0$,

\begin{equation}\label{}
a_{i+1}= \left\{
\begin{array}{l l l}
	a_i, & \quad \textrm{if} x_i \in S_1\\
	(2a_i) modn, & \quad \textrm{if} x_i \in S_2\\
	(a_i + 1) modn, & \quad \textrm{if} x_i \in S_3\\
\end{array} \right.
\end{equation}

and

\begin{equation}\label{}
b_{i+1}= \left\{
\begin{array}{l l l}
	(b_i + 1 )modn, & \quad \textrm{if} x_i \in S_1\\
	(2b_i) modn, & \quad \textrm{if} x_i \in S_2\\
	b_i, & \quad \textrm{if} x_i \in S_3\\
\end{array} \right.
\end{equation}

Pollard's $\rho$ algorithm then uses Floyd's cycle finding algorithm (\S5.1.6) to determine two group elements $x_i$ and $x_{2i}$ such that $x_i$ = $x_{2i}$. This, therefore leads to:

\begin{center}
$\alpha^{a_i}\beta{b_i} = \alpha^{a_{2i}}\beta^{b_{2i}}$
\\
$\Rightarrow \beta^{{b_i}-b_{2_i}} = \alpha^{a_{2i}-{a_i}}$
\end{center}

If logarithms to the base $\alpha$ are then taken from both sides, the following is obtained:

\begin{center}
($b_i -  b_{2i}$) $\times$ log$_{\alpha}\beta \equiv (a_{2i} - a_i)$(mod $n$)
\end{center}

The discrete logarithm log$_{\alpha}\beta$ can be obtained by effectively solving the equation ($b_i -  b_{2i}$) $\times$ log$_{\alpha}\beta \equiv (a_{2i} - a_i)$(mod $n$), considering $b_i \not\equiv b_{2i}$ (mod $n$).
\\
\\
\textbf{Note 5:} $b_i \equiv b_{2i}$ takes place with negligible probability.
\\
\\
The next page illustrates pseudocode for Pollard's $\rho$ algorithm followed by an example. 

\newpage

\begin{algorithm}
\caption{Pollard's $\rho$ algorithm for computing discrete logarithms}
\begin{algorithmic}
\REQUIRE A generator $\alpha$, group element $\beta$ and cyclic group $G$ or order $n$
\ENSURE The discrete logarithm $x$ = log$_{\alpha}\beta$
\begin{enumerate}
\STATE Set $x_0 \leftarrow 1, a_0 \leftarrow 0, b_0 \leftarrow 0$
\FOR {$i$ = 1,2,...} 
\STATE - Using the quantities $x_{i-1}, a_{i-1}, b_{i-1}$, and $x_{2i-2}, a_{2i-2}, b_{2i-2}$ computed \STATE previously, compute $x_i, a_i, b_i$ and $x_{2i}, a_{2i}, b_{2i}$ using the above three equations
\IF{$x_i = x_{2i}$}
\STATE Set $r \leftarrow b_i - b_{2i}$ mod$n$
\IF{$r$ = 0}
\STATE then terminate the algorithm with failure; 
\ENDIF
\STATE otherwise, compute $x$ = $r^{-1}(a_{2i} - a_i)$ mod$n$ and \textbf{return}($x$)
\ENDIF
\ENDFOR
\end{enumerate}
\end{algorithmic}
\end{algorithm}

We note here if Algorithm 11 fails (in the rare occasion) then the method can be repeated with random integers $a_0, b_0$ in the range [1, $n$ - 1] and using $x_0$ = $\alpha^{a_0}\beta^{b_0}$ as the starting value.

\begin{example}{Pollard's rho algorithm for logarithms of the subgroup $G$}.
\end{example}

The element $\alpha$ = 2 is a generator of the subgroup $G$ of order $n$ = 191. Suppose $\beta$ = 228. Partition the elements of $G$ into three subsets according to the rule $x \in S_1$ if $x \equiv 1$ (mod 3), $x \in S_2$ if $x \equiv 0$ (mod 3), and $x \in S_3$ if $x \equiv 2$ (mod 3). The below table shows values of $x_i, a_i, b_i, x_{2i}, a_{2i}$ and $b_{2i}$ at the end of each oteration of step 2 of Algorithm 11. Note that $x_{14} = x_{28}$ = 144. Finally, compute $r = b_{14} - b_{28}$ mod 191 = 125, $r^{-1} = 125^{-1}$ mod191 = 136, and $r^{-1}(a_{28}-a_{14})$ mod191 = 110. Therefore, log$_{2}228$ = 110.
\hfill $\Box$

\begin{center}
\begin{tabular}{|c||c|c|c||c|c|c|}
\hline
\multicolumn{7}{|c|}{\textit{Intermediate steps of Pollard's $\rho$ algorithm in Example 7}}\\
\hline
$i$ & $x_{i}$ & $a_{i}$ & $b_{i}$ & $x_{2i}$ & $a_{2i}$ & $b_{2i}$ \\ \hline\hline
1 & 228 & 0 & 1 & 279 & 0 & 2 \\ 
2 & 279 & 0 & 2 & 184 & 1 & 4 \\
3 & 92 & 0 & 4 & 14 & 1 & 6 \\
4 & 184 & 1 & 4 & 256 & 2 & 7 \\
5 & 205 & 1 & 5 & 304 & 3 & 8 \\
6 & 14 & 1 & 6 & 121 & 6 & 18 \\
7 & 28 & 2 & 6 & 144 &  12 & 38 \\
8 & 256 & 2 & 7 & 235 & 48 & 152 \\
9 & 152 & 2 & 8 & 72 & 48 & 154 \\
10 & 304 & 3 & 8 & 14 & 96 & 118 \\
11 & 372 & 3 & 9 & 256 & 97 & 119 \\
12 & 121 & 6 & 18 & 304 & 98 & 120 \\
13 & 12 & 6 & 19 & 121 & 5 & 51 \\
14 & 144 & 12 & 38 & 144 & 10 & 104 \\
\hline
\end{tabular}
\end{center}

\textbf{Fact 12} Take $G$ to be a group of order of a prime number $n$. Assume a function $f$ : $G \longrightarrow G$ behaves like a random function, it can then be anticipated that the running time of Pollard's $\rho$ algorithm for discrete logarithms in $G$ is $O(\sqrt{n})$ number of group operations. Further, the algorithm uses negligible space.

\subsection{Pohlig-Hellman Algorithm}

The last generic discrete logarithm algorithm known is called the Pohlig-Hellman algorithm and was initially discovered by R.Silver however was first published by S.Pohlig and M.Hellman, hence getting its name. It is also sometimes referred to as the ``Silver Pohlig-Hellman" Algorithm. 

It begins by using prime factorization to factorise the order $n$ of the cyclic group $G$, where the prime factorisation of $n$ is $n = p_{1}^{e_1}p_{2}^{e_2}...p_{r}^{e_r}$. This is also denoted as $n$ = $\displaystyle\prod\limits_{i = 1}^{k} p_{i}^{e_i}$ in which $p_i$ corresponds to the distinct primes whilst $e_i$ represents the natural exponents. The algorithm then uses the Chinese Remainder Therorem (\S5.1.4) so that log$_{\alpha}\beta$ can be recovered from $x_i, x_2,...,x_i$ , log$_{\alpha}\beta$ modulo $n$ where:

\begin{center}
$x_1 \equiv$ log$_{\alpha}\beta$ (mod $p_{1}^{e_1}$)
\\
$x_2 \equiv$ log$_{\alpha}\beta$ (mod $p_{2}^{e_2}$)
\\
$\vdots$
\\
$x_i \equiv$ log$_{\alpha}\beta$ (mod $p_{i}^{e_i}$)
\end{center}

Every $x_i$ integer value is found from computing the digits $l_(e_{i}-1)$ respectively of it's $p_{i}$-ary representation: $x_{i} = l_{0} + l_{1}p_{i}+...+ l_{e_i} - l_{p_1}^{e_{i}-1}$ for which 0 $\leq l_j \leq p_{i} - 1$.

To verify the correctness of Algorithm 12, first observe that in step 2.3 $\overline{\alpha}$ is of order $q$. It then yields that at iteration $j$ of the next step, $\gamma = \alpha^{l_{0} + l_{1q} + ... + l_{j-1}q^{j-1}}$. It therefore follows:

\begin{center}
$\overline{\beta} = (\beta\gamma)^{n/q^{j+1}} = (\alpha^{x-l_{0}-l_{i}q-...-l_{j-1}q^{j-1}})^{n/q^{j+1}}$
\\
=($\alpha^{n/q^{j+1}}$)$^{x_1-l_0-l_{1}q-...-l_{j-1}q^{j-1}}$
\\
=($\alpha^{n/q^{j+1}}$)$^{l_{j}q^{j}+...+l_{e-1}q^{e-1}}$
\\
=($\alpha^{n/q}$)$^{l_j+...+l_{e-1}q^{e-1-j}}$
\\
=($\overline{\alpha}$)$^{l_j}$
\end{center}

which holds true the last equality as $\overline{\alpha}$ has order $q$. It therefore follows that log$_{\overline{\alpha}}\overline{\beta} \equiv l_j$.

\begin{algorithm}
\caption{Pohlig-Hellman algorithm for computing discrete logarithms}
\begin{algorithmic}
\REQUIRE A generator $\alpha$, group element $\beta$ and cyclic group $G$ or order $n$
\ENSURE The discrete logarithm $x$ = log$_{\alpha}\beta$
\begin{enumerate}
\STATE Find the prime factorization of $n: n = p_{1}^{e_1}p_{2}^{e_2}...p_{r}^{e_r}$, where $e_i \geq 1$
\FOR {$i$ from 1 to $r$} 
\STATE ($Compute$ $x_i = l_0 + l_{i}p_{i} +...+l_{{e_1}-1}p_i^{{e_i}-1}$, $where$ $x_i = x$ mod $p_i^{e_i}$)
\STATE 2.1 (\textit{Simplify the notation}) Set $q \leftarrow p_i$ and $e \leftarrow e_i$
\STATE 2.2 Set $\gamma \leftarrow 1$ and $l_{-1} \leftarrow 0$
\STATE 2.3 Compute $\overline{\alpha} \leftarrow \alpha^{n/q}$
\STATE 2.4 Now compute the $l_j$:
\FOR {$j$ from 0 to $e$-1} 
\STATE Compute $\gamma \leftarrow \gamma\alpha^{l_{j-1}q^{j-1}}$ and $\overline{\beta} \leftarrow (\beta\gamma^{-1})^{n/{q^{j+1}}}$
\STATE Compute $\l_j \leftarrow$ log$_{\overline{\alpha}}\overline{\beta}$ (e.g. using Algorithm 10; see (3) in the Note 7)
\ENDFOR
\STATE 2.5 Set $x_i \leftarrow l_0 + l_{1}q +...+ l_{e-1}q^{e-1}$
\ENDFOR
\STATE Use Gauss's Algorithm () to compute the integer $x$, 0 $\leq x \leq n - 1$, such that $x \equiv x_i$ (mod $p_i^{e_i}$) for 1 $\leq i \leq r$
\STATE \textbf{return}($x$)
\end{enumerate}
\end{algorithmic}
\end{algorithm}

The below example demonstrates Algorithm 12 with artificially small parameters.

\begin{example}{Pohlig-Hellman algorithm for logarithms in G}
\end{example}

Let $p$ = 251. The element $\alpha$ = 71 is a generator of the group G of order $n$ = 250 ($n$ = $p$ -1). Consider $\beta$ = 210, then $x$ = log$_{71}210$ is computed as follows.

\begin{enumerate}

\item The prime factorisation of $n$ is 250 = 2 $\times 5^3$.

\item ($Compute$ $x_1 = x$ mod2) Compute $\overline{\alpha} = \alpha^{n/2}$ mod$p$ = 250 and $\overline{\beta} = \beta^{n/2}$ mod$p$ = 250. Then $x_1$ = log$_{250}250$ =1.

\item ($Compute$ $x_2 = x$ mod$5^3$ = $l_0 + l_{1}5 + l_{2}5^2$)

\begin{itemize}

\item Compute $\overline{\alpha} = \alpha^{n/5}$ mod$p$ =20.

\item Compute $\gamma$ = 1 and $\overline{\beta} = (\beta\gamma^{-1})^{n/5}$ mod$p$ = 149. Using brute-force search (Algorithm 7), compute $l_0$ = log$_{20}149 = 2$.

\item Compute $\gamma$ = $\gamma\alpha^{2}$ mod$p$ = 21 and $\overline{\beta} = (\beta\gamma^{-1})^{n/25}$ mod$p$ = 113. Using brute-force search, compute $l_1$ = log$_{20}113 = 4$.

\item Compute $\gamma$ = $\gamma\alpha^{4 \times 5}$ mod$p$ = 115 and $\overline{\beta} = (\beta\gamma^{-1})^{(p-1)/125}$ mod$p$ = 149. Using brute-force search, compute $l_2$ = log$_{20}149 = 2$.

\item Hence, $x_2 = 2 + 4 \times 5 + 2 \times 5^2 = 72$.

\end{itemize}

\item Finally, solve the pair of congruences $x \equiv 1$ (mod2), $x \equiv 72$ (mod125) to get $x$ = log$_{71}210$ = 197.

\end{enumerate}
\hfill $\Box$

\textbf{Fact 13} Having factorised $n$, the Pohlig-Hellman Algorithm has a running time of $O(\displaystyle\sum\nolimits_{i = 1}^r e_i$(log $n$ + $\sqrt{p_i}$)) group multiplications.
\\
\begin{mydef}
Smooth Integer
\end{mydef}

Let $B$ be a positive integer. An integer $n$ is said to be $B-smooth$, or \textit{smooth with respect to a bound B}, if all it's prime factors are $\leq B$.
\\
\\
\textbf{Note 6:} (\textit{Efficiency of Pohlig-Hellman}) The Pohlig-Hellman algorithm is only effective if every prime divisor $p_i$ of $n$ is relatively small; if $n$ is a smooth integer (Definition 15). The below example illustrates a group in which the Pohlig-Hellman algorithm is effective. Consider $p$ a 107-digit prime, of the group $G$:

\begin{center}
$p$ = 227088231986781039743145181950291021585250524967592855
96453269189798311427475159776411276642277139650833937.
\end{center}

The order of $G$ is $n$ = $p$ -1 = $2^4 \times 104729^8 \times 224737^8 \times 350377^4$. As the largest prime divisor of $p$ - 1 is only 350377, it is fairly straight-forward to calculate logarithms in this group witht the Pohlig-Hellman algorithm.

\newpage

\textbf{Note 7:} ($miscellaneous$)

\begin{enumerate}

\item The Pohlig-Hellman Algorithm is the same as Shanks' Algorithm if the order $n$ of group $G$ is a prime.

\item It is necessary for the order $n$ to be a smooth integer, or else the Pohlig-Hellman Algorithm becomes inefficient. Further, in step 1 of Algorithm 12 a factorising algorithm that finds small factors should first be employed. An example of such an algorithm is Pollard's $\rho$ algorithm for prime factorisation which was mentioned earlier in this chapter when discussing Algorithm 11.

\item The storage needed for Algorithm 10 in step 2.4 can be overcome by using Pollard's $\rho$ Algorithm (Algorithm 11).

\item Shanks' ``Baby-Step Giant-Step" algorithm is viewed as hypothetical interest, as it is practical. On the other hand, Pollard has an equivalent time and the space is smaller and so there are two ways in which this can progress. The first is regarding the upper bound that the algorithm needs, to say, the order of the group, and the other is regarding the bound running-time and a validity is required. Yet, some arguments are still made about the assumption of approximate running time. 

\end{enumerate}



\subsection{Further Reading}

The previous section reviews the ``generic" algorithms available today to solve the discrete logarithm problem. The information provided in this chapter is sufficient enough for readers to understand these algorithms, yet algorithm specific papers exist for Pollard's $\rho$ algorithm for logarithms and the Pohlig-Hellman Algorithm, which study both in grave mathematical detail. If the reader so wishes to visit these texts and study these algorithms to a deeper understanding then please refer to \cite{PRho} and \cite{PH}.



\section{Non-generic Discrete Logarithm Algorithm}

This section outlines the Index-Calculus algorithm and illustrates how it works in two kinds of groups used in practical applications.



\subsection{Index-Calculus Algorithm}

This is known to be the most powerful method for computing discrete logarithms and is understood to give a subexponential-time algorithm. We cover the Index-Calculus algorithm under two contexts; the first describes the method in the general setting of a cyclic group $G$, for whihc an algorithm follows, and the second illustrates the Index-Calculus Method in $\mathbb{F}_{2^n}^{*}$.

This algorithm begins by having to choose a relatively small subset of $S$ of elements of $G$, known as the \textit{factor base}. This selection is done in such a way that a large fraction of elements of $G$ can be efficiently expressed as element products from $S$. The following algorithm proceeds to precompute a database of logarithms consisting of all elements in $S$, and then repeatedly use this database every time the logarithm of a certain group element is desired. Yet, we mention here that the next algorithm is incomplete for two reasons. The first being that no method is specified for choosing the factor base $S$. Secondly, a technique for efficiently generating relations outlined in Algorithm 13 is neither specified. For ease and reduction in size for the system of equations to solve in Step 3, it is necessary that the factor base $S$ must be a subset of $G$ that is small but not too small either (so that the anticipated trial number to generate a relation (5.5) is not exceedingly large). Adequate factor bases and techniques however, do exist for generating relations for some cyclic groups $G$ and $\mathbb{F}_{2^n}^{*}$, in particular the multiplicative group $G$ of a general finite field $\mathbb{F}_p$. These will be discussed in the next two sections.
\\
\\
The next page illustrates pseudocode for the Index-Calculus Algorithm in cyclic groups.

\begin{algorithm}
\caption{Index-Calculus algorithm for computing discrete logarithms in cyclic groups}
\begin{algorithmic}
\REQUIRE A generator $\alpha$, group element $\beta$ and cyclic group $G$ or order $n$
\ENSURE The discrete logarithm $y$ = log$_{\alpha}\beta$
\begin{enumerate}
\STATE \textit{(Select a factor base S)} Choose a subset $S$ = $[p_1,p_2,...,p_t]$ of $G$ such that a ``significant proportion" of all elements in $G$ can be efficiently expressed as a product of element form $S$.
\STATE \textit{Collect linear relations involving logarithms of elements in S)}

	2.1 Select a random ingeter $k$, 0$\leq k \leq n$ -1, and compute $\alpha^{k}$.

	2.2 Try to write $\alpha^k$ as a product of elements in $S$: 

\begin{equation}\label{}
$$
\begin{center}

$\alpha^{k} = \displaystyle\prod\limits_{i = 1}^{t} p_{i}^{c_i}$, where $c_i\geq0$. 

\end{center}
$$
\end{equation}

	If successful, take logarithms of both sides of the above equation to obtain a linear relation 

\begin{equation}\label{}
$$
\begin{center}

$k \equiv \displaystyle\sum\limits_{i=0}^{t} c_{i}$log$_{\alpha}p_{i}$ (mod$n$).

\end{center}
$$
\end{equation}

	Repeat steps 2.1 and 2.2 until $t$ + $c$ relations of the above form are obtained ($c$ is a small positive integer, e.g. $c$ = 10, such that te system of equations given by the $t + c$ relations has a unique solution with high probability).

\STATE (\textit{Find the logarithms of elements in S}) Working modulo $n$, solve the linear system of $t + C$ equations (in $T$ unknows) of the form (5.5) collected in step 2 to obtain the values of log$_{\alpha}p_i, 1\leq i \leq t$.

\STATE (\textit{Compute y})

	4.1 Select a random integer $k, 0 \leq k \leq n$ -1, and compute $\beta \times \alpha^k$.
	
	4.2 Try to write $\beta \times \alpha^k$ as a product of elements in $S$:

\begin{center}

$\beta \times \alpha^k  \equiv \displaystyle\sum\limits_{i=1}^{t} p_{i}^{d_i}$, where $d_i \geq 0$.

\end{center}

	If the attempt is unsuccesful then repeat 4.1. Otherwise, taking logarithms of both sides of the above equation yields log$_{\alpha}\beta = (\displaystyle\sum\nolimits_{i = 1}^t d_i$(log$_{\alpha}p_{i} - k$) mod$n$; thus compute $y = (\displaystyle\sum\nolimits_{i = 1}^t d_i$(log$_{\alpha}p_{i} - k$) mod$n$ and \textbf{return}($y$).

\end{enumerate}
\end{algorithmic}
\end{algorithm}

\newpage

\subsection{Index-Calculus Algorithm in $\mathbb{F}_{p}^{*}$}

For finite fields $\mathbb{F}_p$ in which $p$ is a prime, the first $t$ prime numbers are used to select the factor base $S$. To generate a relation (5.4) $\alpha^k$ mod$p$ is first computed after which tiral division is used to verify if this intger is a product of primes in $S$. The example below outlines Algorithm 13 in $\mathbb{F}_{p}^{*}$ in a problem with artificially small parameters.

\begin{example}({Index-Calculus algorithm for logarithms in $\mathbb{F}_{229}^{*}$})
\end{example}

Let $p$ = 229. The element $\alpha$ = 6 is a generator of $\mathbb{F}_{229}^{*}$ of order $n$ = 228. Consider $\beta$ = 13. The log$_6$13 is computed as follows, using the index-calculus technique.

\begin{enumerate}

\item The factor base is chosen to be the first 5 primes: $S$ = [2,3,5,7,11].

\item The follwoing six relations consisting of the elements of the factor base are obtained (unsuccessful attempts are note shown):

\begin{center}

$6^{100}$ mod229 = 180 = $2^{2} \times 3^{2} \times 5$
\\
$6^{18}$ mod229 = 176 = $2^{4} \times 11$
\\
$6^{12}$ mod229 = 165 = $3 \times 5 \times 11$
\\
$6^{62}$ mod229 = 154 = $2 \times 7 \times 11$
\\
$6^{143}$ mod229 = 198 = $2 \times 3^{2} \times 11$
\\
$6^{206}$ mod229 = 210 = $2 \times 3 \times 5 \times 7$.

\end{center}

The next six equations involving the logarithms of elements in the factor base, follow from the above relations:

\begin{center}

100 $\equiv 2$log$_{6}$2 + 2log$_{6}$3 + log$_{6}$5 (mod228)
\\
18 $\equiv 4$log$_{6}$2 + log$_{6}$11 (mod228)
\\
12 $\equiv$ log$_{6}$3 + log$_{6}$5 + log$_{6}$11 (mod228)
\\
62 $\equiv$ log$_{6}$2 + log$_{6}$7 + log$_{6}$11 (mod228)
\\
143 $\equiv$ log$_{6}$2 + 2log$_{6}$3 + log$_{6}$11 (mod228)
\\
206 $\equiv$ log$_{6}$2 + log$_{6}$3 + log$_{6}$5 + log$_{6}$7 (mod228).

\end{center}

\item Solving the linear system of six equations in five unknown (the logarithm $x_{i}$ = log$_{6}p_i$) yields the solutions log$_{6}$2 = 21, log$_{6}$3 = 208, log$_{6}$5 = 98, log$_{6}$7 = 107, and log$_{6}$11 = 162.

\item Suppose that the integer $k$ = 77 is selected. Since $\beta \times \alpha^{k}$ = 13 $\times 6^{77}$ mod229 = 147 = 3 $\times 7^2$, it follows that

\begin{center}

log$_{6}$13 = (log$_{6}$3 + 2log$_{6}$7 - 77) mod228 = 117.

\end{center}

\end{enumerate}
\hfill $\Box$



\subsection{Index-Calculus Algorithm in $\mathbb{F}_{2^n}^{*}$}

For finite fields $\mathbb{F}_{2^n}^{*}$, the factor base $S$ is selected as the set of all irreducible polynomials in $\mathbb{F}_{2}$[$x$] where some prescribed bound $b$ is at most taken as it's degree. a relation (5.4) is found by computing $\alpha^x$ mod$f(x)$ then trial division is used to make sure this polynomial is a product of polynomials in $S$. Example 10 illustrates the index-calculus algorithm in $\mathbb{F}_{2^n}^{*}$ on a problem with once again artificially small parameters.

\begin{example}{(Algorithm 13 for logarithms in $\mathbb{F}_{2^n}^{*}$)}
\end{example}

The polynomial $f(x) = x^7 + x + 1$ is irreducible over $\mathbb{F}_2$. Hence, the elements of the finite field $\mathbb{F}_{2^7}$ of order 128 can be represented as the set of all polynomials in $\mathbb{F}_2$[$x$] of degree at most 6, where multiplication is performed modulo $f(x)$. The order of $\mathbb{F}_{2^7}^{*}$ is $n = 2^7$-1 = 127, and $\alpha = x$ is a generator of $\mathbb{F}_{2^7}^{*}$. Suppose $\beta = x^4 + x^3 + x^2 + x + 1$. Then $y$ = log$_{x}\beta$ can be computed as follows, using  the index-calculus method.

\begin{enumerate}

\item The factor base is selected to be the set of all irreducible polynomials in $\mathbb{F}_2$[$x$] of degree at most 3: $S$ = \{$x, x+1, x^2+x+1, x^3+x+1, x^3+x^2+1$\}.

\item The following five relations involving elements of the factor base are obtained (unsuccessful attempts are not shown):

\begin{center}

$x^{18}$ mod$f(x)$ = $x^6+x^4 = x^4(x+1)^2$
\\
$x^{105}$ mod$f(x)$ = $x^6+x^5+x^4+x = x(x+1)^2(x^3+x^2+1)$
\\
$x^{72}$ mod$f(x)$ = $x^6+x^5+x^3+x^2 = x^2(x+1)^2(x^2+x+1)$
\\
$x^{45}$ mod$f(x)$ = $x^5+x^2+x+1 = x(x+1)^2(x^3+x+1)$
\\
$x^{121}$ mod$f(x)$ = $x^6+x^5+x^4+x^3+x^2+x+1 = (x^3+x+1)(x^3+x^2+1)$.

\end{center}

From these relations, the following five equations involving the logarithms of elements in factor base (for notation efficiency, let $p_1$ = log$_{x}x$, $p_2$ = log$_x(x+1)$, $p_3$ = log$_{x}(x^2+x+1)$, $p_4$ = log$_{x}(x^3+x+1)$, and $p_5$ = log$_{x}(x^3+x^2+1)$:

\begin{center}

18 $\equiv 4p_1+2p_2$  (mod127)
\\
105 $\equiv p_1+2p_2+p_5$ (mod127)
\\
72 $\equiv 2p_1+2p_2+p_3$ (mod127)
\\
45 $\equiv 2p_2+p_4$ (mod127)
\\
121 $\equiv p_4+p_5$ (mod127).

\end{center}

\item Solving the linear system of five equations in five unknowns yields the values $p_1 = 1, p_2 =7, p_3 =56, p_4 = 31$, and $p_5 = 90$.

\item Suppose $k$ = 66 is selected. Since:

\begin{center}
$\beta\alpha^k = (x^4+x^3+x^2+x+1)x^{66}$ mod$f(x) = x^5+x^3+x = x(x^2+x+1)^2$,
\end{center}

it follows that

\begin{center}
log$_{x}(x^4+x^3+x^2+x+1) = (p_1+2p_3-66)$ mod127 = 47.
\end{center}
\end{enumerate}
\hfill $\Box$
\\
\textbf{Note 8:} \textit{(Running-time of the Index-Calculus method)} The size $t$ of the factor base should be selected thoughtfully in order to enhance the running time of the Index-Calculus method. Ideally, this choice is based in acquaintance regarding the allocation of smooth integer in the interval [1, $p$-1] for $\mathbb{F}_{p}^{*}$ and on the distribution of \textit{smooth polynomials} (polynomials which all the have irreducibe factors of small degrees) amid polynomials in $\mathbb{F}_{2}$[$x$] with degree less than $m$. Having an ideal $t$ value the index-calculus algorithm as earlier explained for $\mathbb{F}_{p}^{*}$ and $\mathbb{F}_{2^n}^{*}$ has an anticipated running time of L$_{1}[\frac{1}{2}, c]$ where $q=p$, $q$=2$^n$, and $c >$ 0 is a constant.
\\
\\
\textbf{Note 9:} \textit{(Fastest algorithms known for discrete logarithms in $\mathbb{F}_{p}^{*}$ and $\mathbb{F}_{2^n}^{*}$)} At present for $\mathbb{F}_{p}^{*}$, the best algorithm known for computing discrete logarithms is a combination of the index-calculus algorithm called the $\textit{Coppersmith algorithm}$ and has an anticipated running-time of $L_{2^n}[\frac{1}{3},c]$ for some constant $c <$ 1.587. For $\mathbb{F}_{p}^{*}$, the best known algorithm is the \textit{number field sieve}, with an expected running time of $L_p[\frac{1}{3},1.923]$. Both of these techniques however, will not be considered in detail in this text, so readers are advised to refer to \cite{BSc} for further detailed knowledge on the \textit{Coppersmith algorithm} and the \textit{number field sieve}.
\\
\\
\textbf{Note 10:} \textit{(Parallelisation of the Index-Calculus algorithm)} 

\begin{enumerate}

\item In the case of ideal choice of parameters, the phase that takes up the most time in the Index-Calculus algorithm is generally step 2 in algorithm 11, in which relations involving factor base logarithms are determined. This task is trivial to split between a processor network by allowing the processors to search for relations independently of each other. All the relations that are generated are gathered bu one central processor. Once a sufficient member of relations have been generated, then relations in step 3 of algorithm 11 can be solved on one single (even possibly parallel) computer.

\item For a given finite field the database of factor base logarithms is only required to be computed once. Relative to this, step 4 of algorithm 11 in which individual logarithms are calculated is exceptionally quicker.

\end{enumerate}





\chapter{Implementation in C++}

This chapter discusses the implmentation of the algorithm's discussed in the previous chapter. The programming language used was C++ and we illustrate what representations of finite fields have been considered for the implementations (Chapter 4 $\S4.5.1$ and $\S4.5.2$), what psuedocode was used, the testing procedure, the functionality of each preogram and their robustness and efficiency. Initially programming started with the Dev C++ Integrated Development Environment (IDE) but was later changed to Visual Studio 2010 and Eclipse IDE, the reasons for which will follow in this chapter.
We begin by noting that all the ``generic" discrete logarithm algorithms have been implemented in the chosen language, that is:

\begin{enumerate}

\item Brute-Force Search

\item Shanks' ``Baby-Step Giant-Step" Method

\item Pollard's $\rho$ Algorithm for logarithms (1978)

\item Pohlig-Hellman Algorithm (1978)

\end{enumerate}

The pseudocode provided for each algorithm (including the Index-Calculus algorithm) in the previous chapter are all from \cite{HAC}, however various different sources have been referred to during implementation. For the Brute-Force search pseudocode from \cite{MSc2} was used, \cite{HAC} was referred to for Shanks' ``Baby-Step Giant-Step" Method, and the Pohlig-Hellman algorithm whilst \url{http://www-ti.informatik.uni-tuebingen.de/~reinhard/krypto/English/pollardrho_e.html} was used for Pollard's $\rho$ algorithm for logarithms.



\section{Implementation for $\mathbb{F}_p$}

For the finite field $\mathbb{F}_p$, four algorithms have been implemented (as already mentioned) of $integer$ representation for which no external libraries were used. 



\subsection{Functionality}

The Brute-Force Search, Shanks' ``Baby-Step Giant Step" Method, Pollard $\rho$ algorithm for logarithms and Pohlig-Hellman algorithm all funtion in the same way with input of $\alpha\in G$, $\beta \in G$ and the order $n$ of the cyclic group $G$. (To quickly recap, for this field $\alpha$ is a generator of the group $G$ and $\beta$ an element of the group $G$). Each algorithm solves the Discrete Logarithm Problem by finding the unique integer $x$ such that $\alpha^x = \beta$.

Each implementation is an exectuable program, using command prompt to take in input arguments. The algorithms function such that upon execution a command line window is opened that:

\begin{enumerate}

\item Firstly asks the user to input the value of group element $\alpha$ (remember input in $\mathbb{F}_p$ is integer value):

\begin{center}

\textit{``Please enter a value for the generator $\alpha$: ..."}

\end{center}

\item Once having entered the value for $\alpha$, the program then displays a message asking the user to input the value of $\beta$:

\begin{center}

\textit{``Please enter a value for the element $\beta$: ..."}

\end{center}

\item After this, the last argument that needs to be inputted is the value of the gorup $n$.

\begin{center}

\textit{``Please enter a value for the order `n' of the group:"}

\end{center}

\item The program then displays the exponent value `$x$' in the form of $\alpha^x = \beta$ or $x$=log$_{\alpha}\beta$:

\begin{center}

\textit{``The discrete logarithm x is ..."}

\end{center}

\end{enumerate}

In the case when no $x$ values exist, depending on the algorithm being used, according outputs will be displayed:

\begin{itemize}

\item Brute-Force displays 0.

\item Shanks' ``Baby-Step Giant Step" Method returns the following message if the multiplicative inverse is incomputable `\textit{Multiplicative inverse cannot be computed, please check input!'}, or if the value of $\alpha$ is not primitive, then the program will not display anything further information and terminates. For some strange cases where the multiplicative inverse cannot be calculated, the program will display the above message as well as a value for the discrete logarithm $x$. In this case, the value $x$ is to be ignored as this value is incorrect.

\item Pollards $\rho$ algorithm for logarithms displays a `\textit{no unique value x exists}' message and 0. When (in the rare case) the discrete logarithm '$x$' is displayed as 0 alone without the message, it means that the unique integer $x$ is 0.

\item Pohlig-Hellman algorithm doesn't display any answer if values are not relatively prime or terminates if $p$ has no prime factors.

\end{itemize}

\textbf{Note 11:} In all functions, the intermediate steps are NOT displayed, only the final answer is given, as we believe these were not neccessary to be known by the user. For intermediate steps please refer to the hyperlinks used during testing, or please see the examples provided for each algorithm in this text as they clearly illustrate the procedures step by step.



\subsection{Efficiency}

To make the programs more robust and efficient, the elapsed processor times have also been calculated. This is robust as the efficiency of software is judged in context of the processor time than compared to real time, giving a realistic time measure on the speed of each algorithm to a sufficient level of accuracy. The processor times are displayed in seconds as such:

\begin{center}

\textit{``The processor time elapsed is: `...' seconds"}

\end{center}



\subsection{Testing and Debugging Procedures}

The same testing procedure was carried out for all four algorithms:

\begin{itemize}

\item \textbf{Brute-Force Search} - This was the most trivial algorithm to implement from the four and due to this fact it was possible to calculate values using mental arithmetic (on paper), to which the program output values were then compared. It is yet evident that mentally, calculations would only be possible for restricted values, because for too large values the algorithm and mental calculation both become inefficient. As for wirtten examples in books, no such examples exist due to the trivial nature of the algorithm. Debugging consisted in the form of printing each line of caclulation until the final answer. This posed as a mechanism for backtracking and verifying mathematical error in the code were any to occur.

\item \textbf{Shanks' ``Baby-Step Giant-Step" Method} - The same technique was adapted for Shanks' ``Baby-Step Giant-Step" Method as to the Brute-Force Search, in which an example from \cite{HAC} was used to verify with during the debugging process. For fairness and correctness of the algorithm, various online examples using \url{http://www-ti.informatik.uni-tuebingen.de/~reinhard/krypto/English/shank_e.html}, an online Discrete Logarithm applet, were tested. The usefulness and advantage of the online applet will follow as the same resource hase been used for the next two algorithms too, the benefits of which are ditto for the former and latter. For further verification, other text book examples were used.

\item \textbf{Pollard's $\rho$ algorithm for logarithms and Pohlig-Hellman Algorithm} - For both the final two algorithms the hyperlinks provided at the start of this chapter were used, to recite \url{http://www-ti.informatik.uni-tuebingen.de/~reinhard/krypto/English/pollardrho_e.html} and \url{http://www-ti.informatik.uni-tuebingen.de/~reinhard/krypto/PohligHellman/english.html}. Both these pages provided  online calculators for the Discrete Logarithm Problem for the Pollards $\rho$ and Pohlig-Hellman algorithms and proved to be excellent resources during the testing stage as experiments could be carried out for all values and directly compared. Values were first tested on the online calculator then on the executable programs implemented. The bigger advantage gained by using the hyperlinks was that each line of computation was printed on screen along with the final answer, which proved extremely useful during the debugging stage. Yet, one thing was spotted during testing with the Pohlig-Hellman algorithm; most values obtained by both the online calculator and written program were the same, however for some examples this was not the case. Particular examples in different answers between both sources; we believe the only reason for this being the source of pseudocode on which the programs are based. The applet having provided it's own, yet as mentioned earlier, our implemented version using the pseudocode from \cite{HAC}, distinguishing the slight variation amongst both. It is was also seen that for a certain minority of cases with the Pohlig-Hellman algorithm, Eclipse IDE threw \textbf{`Range 1 error'}; 95\% of the time a range 1 error is thrown due to a vector problem using g++.exe. This is a compiler issue beyond our control to resolve, however, is only thrown for a very few examples (as already mentioned) hence, can be passed without too much of a concern.



\end{itemize}




\subsection{Elapsed Time}

When testing, the elapsed times for each of the algorithms were taken in consideration. In the general case, the Pohlig-Hellman algorithm proved to take the longest, which was anticipated, yet their were cases where the elapsed time was computationaly quick. Conversely, at times Pollard's $\rho$ algorithm for discrete logarithms and and Shank's method proved to take longer than the latter. An observation that was collected from the testing procedure was that the input values would reflect the elapsed time and for this reason, it wouldn't be appropriate to come to a  concluded decision upon the time efficiency regarding which procedure from those stated would be best suited to solve the discrete logarithm problem.

Ofcourse, a further consideration and observation taken into account during this stage was on the various conditions posed by the different algorithms. To cite an example, in order for the Pohlig-Hellman algorithm to function, it is required that the value of the input $n$ has prime factors, i.e. is factorisable, and that both $\alpha$ and $\beta$ are relatively prime. Also for Shank's "Baby-Step Giant-Step" Method it is required that $\alpha$ is primitive and that the multiplicative inverse is computable, without which the entire algorithm is of no use. To further explain, for Pollard's $\rho$ algorithm if the value of $r$ is equivalent to 0 then the algorithm will terminate from this point; in all such situations, the elapsed time was disregarded as the final answer due to the procedure terminating and as a result the problem not being solved.




\subsection{Implementation Issues}

Two key issues were faced during the implementation stage for finite fields $\mathbb{F}_p$. In particular for Pollards $\rho$ algortihm for logarithms for which a challenge was faced on what implementation to follow, as various different versions of pseudocode was seen. However, this was overcome once having found the online calculator for this algorithm as pseudocode was also provided with the working solution. Readers are to be reminded here that for this reason a different answer will be obtained to that shown in example 7 of this text if tested with the program written, the former being from \cite{HAC} a different slightly different version of the algorithm to the actual source used. Note, example 7 was used in particular for fairness i.e. keeping to a single source for examples, further it illustrates the use of Pollars $\rho$ algorithm to a high standard of understanding. As for Brute-Force Search, Shanks' ``Baby-Step Giant Step" Method the only issue faced (and remains unresolved) was the unexpected appearance of a discrete logarithm value in the case where the multiplicative inverse in uncomputable. This probelm is rather strange and it is strongly believed that this error should not be occuring as the source code was repeatedly tested and varied, yet this remains to be a minor `bug' in the program.

The second issue that was faced, was one beyond one's control, to say a compiler issue. Whilst implementing the Pohlig-Hellman algorithm, a problem regarding array size was confronted, in which an integer value $k$ was assigned to a vector of size $x$ in the following way:

\begin{center}

\textbf{int k = x.size()}

\end{center}

Two arrays were then required, both the size of vector $x$, which would be initialised in C++ in the follwoing way:

\begin{center}

\textbf{m[k], a[k]}

\end{center}

Yet, Visual Studio 2010 threw an error on this line stating, \textit{``array size has to be constant value"}. However, when the same line of code was attempted in Eclipse IDE, no such errors were thrown. This clearly illustrates the difference in compiler set-up. Eclipse IDE uses \textit{mingw} and \textit{cygwin}, whilst Visual Studio 2010 makes use of the \textit{ms compiler}. Initially, this was thought to be bad programming practice, however it was clarified to be a compiler issue after professional consultation.




\section{Implementation for $\mathbb{F}_{2^n}$}

For the finite field $\mathbb{F}_{2^n}$ initially a new library with a new class was to be constructed as C++ does not have a predefined type \textit{Galois Field Element}. However, this idea was later dropped as an already Galois Field Arithmetic library had been written by an individual named Arash Partow and was available online to download and use. This was considerably helpful because it saved a substantial amount of time compared to wiritng one up from scratch. The external library was downloaded from \url{http://www.partow.net/projects/galois/} and comes with a free use permission licence under the guidelines and in accordance with the most current version of the ``Common Public Licence".

For this representation the Brute-Force Search, Shanks' ``Baby-Step Giant-Step" Method and Pollard's $\rho$ algorithm for logarithms were implemented, however, a different version of pseudocode for the Brute-Force Search was used i.e. a precomputed table version in which a list/table is used to compare values as demonstrated in Shanks' ``Baby-Step Giant-Step" Method. This version was used as it was much more efficient and accurate for the context $\mathbb{F}_{2^n}$ and the polynomial representation and the main advantage of this method is the instant solutions of subsequent discrete logarithms in the same group; only a single table lookup is needed. This pseudocode (Algorithm 14) is provided on the next page and the source was once again \cite{MSc2}:

\begin{algorithm}
\caption{Brute-Force Search - Precomputed Table Algorithm}
\begin{algorithmic}
\REQUIRE A generator $\alpha$, primitive element $\beta$ and a primitive polynomial $f$($x$)     \STATE	           of degree $n$
\ENSURE The discrete logarithm $\alpha^x = \beta$
\begin{enumerate}
\STATE First build the table such that $hash[\alpha^x] = x$ for $0 \leq x < 2^{n} - 1$ 
\STATE $b \Leftarrow 1$
\FOR {$x$ = 0 to [table size]}
\STATE hash[$b$] $\Leftarrow x$
\STATE $b \Leftarrow b \times \alpha$
\ENDFOR
\STATE Now perform the table lookup
\STATE $x \Leftarrow$ hash[$\beta$]
\STATE \textbf{return} $x$
\end{enumerate}
\end{algorithmic}
\end{algorithm}


This algorithm is exponential in both time and space complexities and the table holds $2^{n}$ - 1 values of size $n$ which gives an asymptotic size of $O(n2^{n})$.



\subsection{Functionality}

Functionality for the three algorithms were not exactly as desired due to the limitations posed by the external library, as implementation had to be done according to the library. This is one key disadvantage (under all contexts, not just for this project) of using external libraries. 

The same implementation of Brute-Force Search, Shanks' ``Baby-Step Giant-Step" Method and Pollard's $\rho$ algorithm for logarithms for $\mathbb{F}_p$ were used, but just modified for use with the library. As implementations already existed, there was no neccessity to re-implement, as the same procedures applied to $\mathbb{F}_{2^n}$, however just under the context of a Galois Field. 

Continuing with functionality, all three algorithms work in a different way to their twins. Due to the restricted functionality and simplicity of the library, all input arguments had to be hardcoded into the program, and modified accordingly. A new namespace \textbf{`galois'} had to be used to enable the functionality of library in addition to including the required header files. More on this will be explained in the section to follow.

In order to use the algorithms a primitive polynomial has to be initialised in the form of a vector in which the polynomial coefficients are to coded in ascending order. Hence the polynomial $p(x) = x^4 + x^3 + 0x^2 + x + 1$ is defined as such:

\begin{center}

\textbf{unsigned int poly[5] = \{1, 1, 0, 1, 1\}}

\end{center}

The Galois Field is then setup, what is important in this is the exponent value e.g. $2^n$. So, for a Galois Field of type $2^4$ we use:

\begin{center}

\textbf{galois::GaloisField gf(4, poly)}

\end{center}

Once the field has been set-up, the Galois Field Element needs to be initialised. The way in which this is done, is to reference an already initialised Galois field to pass to the field element and the field element's initial vector form value within the particular Galois field also has to be passed as such:

\begin{center}

\textbf{galois::GaloisFieldElement element1(\&gf, 1)}
\\
\textbf{galois::GaloisFieldElement element2(\&gf, 2)}

\end{center}

\textbf{Note 12:} In the case of this project, element 1 = $\alpha$ and element 2 = $\beta$. This therefore yeids:

\begin{center}

\textbf{galois::GaloisFieldElement $\alpha$(\&gf, 2)}
\\
\textbf{galois::GaloisFieldElement $\beta$(\&gf, 4)}

\end{center}

where the value of $\alpha$ is always 2, and $\beta$ is subject to change, however for fairness in testing $\beta$ was fixed to 4. Variable $n$ is replaced by $o$, still representing the order of the group, i.e. the number of elements. For $\mathbb{F}_{p}$ $n$ denoted $n = p-1$, likewise for $F_{2^n}$ $o$ denotes $o = (2^n)-1$.
\\
\\
The remaining algorithms are the same, however, adapted where needed for convenience, execution and for Finite Field Arithmetic. The source codes 
\\
\textbf{`ex\_search\_2n.cpp'}, \textbf{`BSGS\_2n.cpp'} and \textbf{`Pollard\_Rho\_2n.cpp'} illustrate the use of the Galois Field Arithmetic library.
\\
\\
\textbf{Note 13:} A keen eye has to be kept when editing and changing the primitive polynomials and field size, in particualr for Shanks' ``Baby-Step Giant-Step" Method and Pollard's $\rho$ algorithm for logarithms. Care has to be taken these two algorithms because they both require various areas at which changes need to me made according to the value of the field size, and therefore when the field size is changed, these areas will also have to be modified (these lines have cleary been highlighted in the source code through commenting). Further, a change in field size would therefore mean a change in polynomial size i.e. the number of polynomial coefficients, and in the case this is forgotten to do, an `unhandled win32 exception' occurs causing the program to crash. This exception deems extremely useful when such an error has occured and proves to be a beneficial debugging tool.
\\
\\
\textbf{Note 14:} For all three algorithms is it essential to use ONLY irreducible primitive polynomial coefficients or else they will crash displaying the already mentioned `unhandled win32 exception'. If a mistake is made with entering the coefficient values and an exception is to occur, it may seem to the user that the program is not functioning when in reality this is not the case, hence, the use of irreducible primitive polynomials is to be ensured.

\subsection{Efficiency}

Once again, for the same reasons stated in $\S6.1.2$ the elapsed processor time in calculating $x$ for the algorithms are measured and displayed in the same format. 

\subsection{Testing and Debugging Procedures}

For the testing procedure, irreducible (primitive) polynomials were used. For fairness, for each degree $n$, the primitive polynomials used were selected at random, the Galois Field Element $\alpha$ fixed at value 2 and $\beta$ fixed at value 4. The primitive polynomials used were selected from `test data', to say, a \textit{table of irreducible polynomials for the modulus 2}, where $n$ ranged from 1 to 10. The same debugging process to $\S6.1.3$ was followed. 




\subsection{Elapsed Time}

When testing with the Brute-Force Search for $\mathbb{F}_{2^n}$ rather interesting yet, anticipated results were obtained. The table on the next page outlines the test data used; the degree of the poynomial, the polyomial coefficients, and elapsed time in seconds, $n$ = 1, 2 and 3 have been disregarded for accuracy and efficiency. 

\newpage

\textbf{Brute-Force Search Results}
\\
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
\multicolumn{3}{|c|}{\textit{Irreducible Polynomials for the Modulus 2}} \\
\hline
\textbf{$n$} & \textbf{Polynomial coefficients} & \textbf{Elapsed processor time in secs} \\ \hline
4 & 10011 & 0.031s  \\ 
 & 11001 & 0.031s \\ \hline
5 & 100101 & 0.032s \\ 
 & 101001 & 0.032s \\
 & 101111 & 0.015s \\
 & 110111 & 0.031s \\
 & 111011 & 0.015s \\
 & 111101 & 0.031s \\ \hline
6 & 1000011 & 0.031s \\
 & 1011011 & 0.016s\\
 & 1100001 & 0.032s \\
 & 1100111 & 0.016s \\
 & 1101101 & 0.031s \\
 & 1110011 & 0.016s \\ \hline
7 & 10000011 & 0.031s \\
 & 10001001 & 0.032s \\
 & 10011101 & 0.031s \\
 & 10100111 & 0.031s \\
 & 10111111 & 0.031s \\
 & 11000001 & 0.031s \\
 & 11101111 & 0.031s \\
 & 11110001 & 0.031s \\ \hline
8 & 100011101 & 0.031s \\
 & 101001101 & 0.032s \\
 & 110101001 & 0.609s \\
 & 111001111 & 0.610s \\
 & 111100111 & 0.610s \\
 & 111110101 & 0.594s \\ \hline
9 & 1000010001 & 1.125s \\
 & 1000100001 & 1.093s \\
 & 1010100101 & 1.093s \\
 & 1101111111 & 1.110s \\
 & 1100011111 & 1.094s \\
 & 1111001011 & 1.109s \\ \hline
10 & 10000001001 & 2.015s\\
\hline
\end{tabular}
\end{center}


The results shown in the table above are only a sample of the tested data used with the intention to illustrate the scope, efficieny and time difference amongst the calculations. An interesting observation was gathered from the testing procedure; the results illustrated show a genuine increase in time from $n$ = 8, meaning, as there is an increase in polynomial size, the elapsed processor time will also accordingly increase. Further, the results gathered were tested one after another without any intermediate interference in ascending order, i.e. from $n$ = 4 to $n$ = 10, yet when the same test was carried out again reversely then a different result base was obtained. 

For accuracy, the same test was again carried out on the following day to the above, however, in reverse order and it was discovered that the running processor times were different to those stated in the table. In fact, the elapsed time for larger polynomials i.e. when $n$ = 8, 9 and 10, was 0.31 seconds, clearly meaning that if tests are repeatedly carried out in ascending order of polynomial degree then this will effect the elapsed calculation time for larger degree powers. A definite reason for this could not be confirmed, yet one of two assumptions could be made. Computationally, it was seen that for the former experiment the program took longer than usual time to execute for larger polynomials before an output was displayed on command line; a waiting time of 20 - 30 \textit{real-time} secs. It could be understood that this waiting time is considered within the elapsed time, hence resulting in an overall longer time frame for calculation. A second assumption could be related to the amount of storage memory required by the program, hence reflecting the time and speed difference, the worst case scenario being an overload of memory. This was the key reason for why the table on the previous page contains only one polynomial for $n$ = 10, it wasn't that no further data for this value was available but in fact, computation was taking a considerable amount of time. Besides, the maximum value taken by $n$ in the test data was 10 and so it can be fair to say that the algorithm functions for all tested polynomial sizes. But in addition to this statement, the latter experiment too saw an equivalent waiting time before an output was displayed yet the elapsed time was revealed as 0.31 seconds, making the the former argument carry no weight. 

Therefore, taking into account the observations, analysis and results from both tests, it can be accomplished that the average processor time taken by the Brute-Force Search under the finite field $\mathbb{F}_{2^n}$ is 0.31 seconds.

The results for Shanks' ``Baby-Step Giant-Step" Method and Pollard's Rho algorithm for logarithms will now also be illustrated in the following pages.

\newpage

\textbf{Shanks' ``Baby-Step Giant-Step" Method Results}
\\
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
\multicolumn{3}{|c|}{\textit{Irreducible Polynomials for the Modulus 2}} \\
\hline
\textbf{$n$} & \textbf{Polynomial coefficients} & \textbf{Elapsed processor time in secs} \\ \hline
4 & 10011 & 0.016s  \\ 
 & 11001 & 0.031s \\ \hline
5 & 100101 & 0.031s \\ 
 & 101001 & 0.031s \\
 & 101111 & 0.015s \\
 & 110111 & 0.031s \\
 & 111011 & 0.031s \\
 & 111101 & 0.032s \\ \hline
6 & 1000011 & 0.015s \\
 & 1011011 & 0.031s\\
 & 1100001 & 0.015s \\
 & 1100111 & 0.031s \\
 & 1101101 & 0.031s \\
 & 1110011 & 0.031s \\ \hline
7 & 10000011 & 0.031s \\
 & 10001001 & 0.031s \\
 & 10011101 & 0.031s \\
 & 10100111 & 0.031s \\
 & 10111111 & 0.031s \\
 & 11000001 & 0.032s \\
 & 11101111 & 0.032s \\
 & 11110001 & 0.032s \\ \hline
8 & 100011101 & 0.016s \\
 & 101001101 & 0.031s \\
 & 110101001 & 0.031s \\
 & 111001111 & 0.015s \\
 & 111100111 & 0.032s \\
 & 111110101 & 0.031s \\ \hline
9 & 1000010001 & 0.031s \\
 & 1000100001 & 0.031s \\
 & 1010100101 & 0.015s \\
 & 1101111111 & 0.031s \\
 & 1100011111 & 0.031s \\
 & 1111001011 & 0.031s \\ \hline
10 & 10000001001 & 0.016s\\
\hline
\end{tabular}
\end{center}

\newpage

\textbf{Pollard's $\rho$ algorithm for logarithms Results}
\\
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
\multicolumn{3}{|c|}{\textit{Irreducible Polynomials for the Modulus 2}} \\
\hline
\textbf{$n$} & \textbf{Polynomial coefficients} & \textbf{Elapsed processor time in secs} \\ \hline
4 & 10011 & 0.031s  \\ 
 & 11001 & 0.031s \\ \hline
5 & 100101 & 0.031s \\ 
 & 101001 & 0.031s \\
 & 101111 & 0.047s \\
 & 110111 & 0.031s \\
 & 111011 & 0.046s \\
 & 111101 & 0.031s \\ \hline
6 & 1000011 & 0.031s \\
 & 1011011 & 0.032s\\
 & 1100001 & 0.031s \\
 & 1100111 & 0.046s \\
 & 1101101 & 0.031s \\
 & 1110011 & 0.031s \\ \hline
7 & 10000011 & 0.031s \\
 & 10001001 & 0.031s \\
 & 10011101 & 0.031s \\
 & 10100111 & 0.031s \\
 & 10111111 & 0.046s \\
 & 11000001 & 0.047s \\
 & 11101111 & 0.031s \\
 & 11110001 & 0.031s \\ \hline
8 & 100011101 & 0.032s \\
 & 101001101 & 0.031s \\
 & 110101001 & 0.047s \\
 & 111001111 & 0.047s \\
 & 111100111 & 0.047s \\
 & 111110101 & 0.047s \\ \hline
9 & 1000010001 & 0.031s \\
 & 1000100001 & 0.047s \\
 & 1010100101 & 0.047s \\
 & 1101111111 & 0.047s \\
 & 1100011111 & 0.047s \\
 & 1111001011 & 0.047s \\ \hline
10 & 10000001001 & 0.046s\\
\hline
\end{tabular}
\end{center}

Once again the results for the final two tables illustrate that the average running times for both Shanks' ``Baby-Step Giant-Step" Method and Pollard's $\rho$ algorithm for logarithms is also 0.031 processor seconds. From this data it can be concluded that all three algorithms in $\mathbb{F}_{2^n}$ have the same running time, providing the same efficiency level for each.

Yet, as for robustness, two particular analysis' were made. Firstly, when using Shanks' Method, in addition to the testing stage, it was seen that when the value of $\beta$ is assigned to the value 9 or above, regardless of the field size or primitive polynomial, the program will execute, however, will not display an answer; only a description of the program is displayed on screen. This is the case when the multiplicative inverse cannot be computed for the algorithm meaning the program will no longer continue and terminate. As with it's sister implementation for $\mathbb{F}_{p}$, a message was conditioned to be displayed, however the same program was faced, this time to a much higher degree. Depsite the \textbf{if} and \textbf{else} statements, the message displayed for every answer and it deemed fit to therefore, remove the message entirely as this is not at all professional or efficient.

Secondly, regarding Pollard's $\rho$ algorithm, this was also tested using the results illustrated in the corresponding table and strangley enough, for all primitive polynomials, field sizes and values for $\beta$, no discrete logarithm $x$ existed due to the value of $r$ equating 0. For this reason, one may argue that the algorithm does not function, however in defence it can be clearly said, the algorithm does indeed function correctly as different values have different elapsed times, and further, as an increase in field size is seen, a real-time wait of 20-30 secs is also experienced as explained already for the Brute-Force Search. This clearly identifies that the program is in fact running and functioning as required, however as the algorithm states, certain conditions allow for the answer specified. Another assumption that could be made from this result is that Pollard's $\rho$ algorithm for logarithms is not applicable to the finite field $\mathbb{F}_{2^n}$. We say this as till date, all uses of this algorithm have been illustrated under $\mathbb{F}_p$, and so it cannot be said for sure how accurate this assumption could be. Yet, to determine this, a considerable amount of time would be needed, and hence this could become a foundation for future work. 

In summary, all three algorithms function as required and are of equivalent efficiency, however, from the three the Brute-Force Search can be believed to be the most reliable in providing an answer/output, due to the conditions and reasons discussed above and put forward by the latter procedures. Nevertheless, this does not mean that only Brute-Force is to be used, as the other algorithms may prove to be more suited based on what output/result is required.

\subsection{Implementation Issues}

Once having downloaded the external library, it was first tested for use with only the header files alone. This trial was first carried out in Dev C++ IDE, however a link error was faced as no library could be found, or connected to.

The same trial was then carried out in Visual Studio 2010 and yet again a link error was faced. It was then discovered that despite having downloaded the external library, the $.lib$ file that makes the library was missing.

A downside to the library was that poor documentation was provided for it, which at times posed to be very inefficient. This meant that the static library had to be built using the downloaded files with an IDE.

Initially it was believed that the library was corrupt however after thorough research and professional consultation, it came forward that no $.lib$ file existed. 

Visual Studio 2010 was then used to create a static Galois field library and then referenced and linked to the associated source files after which the source successfully compiled and ran. 

This experiment was also tried in Eclipse IDE by creating the static library again, linking, building and running \textbf{`ex\_search\_2n.cpp'}, \textbf{`BSGS\_2n.cpp'} and \textbf{`Pollard\_Rho\_2n.cpp'}. Yet, once again, the difference in compilers was evident as the programs terminated without execution in Eclipse IDE, whilst executing smoothly in Visual Studio 2010.






\chapter{Conclusion}

In conclusion, it can be summarised that there is room for further research and questioning upon the level of security for fields $\mathbb{F}_{2^n}$, in particular for cryptographic applications. The discrete logarithm problem will therefore continue to be a subject of research and this text reflects and surveys it's importance.

Through the study of known algorithms, this text confronts the discrete logarithm problem under two types of finite fields $\mathbb{F}_p$ and $\mathbb{F}_{2^n}$. It is evident why discrete logarithms in $\mathbb{F}_p$ carry a much easier implementation level and provide a greater and increased level of security in cryptographic applications than $\mathbb{F}_{2^n}$.

As a whole, the project has progressed smoothly. Initially, focus began on the field $\mathbb{F}_{2^n}$, yet as time progressed $\mathbb{F}_p$ was also bought into consideration. Having programmed in both fields raised practical awareness about both implementation issues and compiler differences, all of which have clearly been discussed and presented in this thesis. Other than those stated, no other real challenges were faced, and development was checked on a fortnightly basis to ensure consistency was maintained. Nevertheless, it can rightfully be said that there is still scope of future improvement for this project.

Theoretical research has stated the Index-Calculus method to be the best and most efficient algorithm known till date for $\mathbb{F}_{2^n}$, yet time did not allow this statement to be proven through implementation. Therefore, a future improvement to the project could involve implementing and investigating into solving the discrete logarithm problem using the Index-Calculus method, firstly for $\mathbb{F}_p$ and if possible $\mathbb{F}_{2^n}$. It would also have been of benefit to implement the `Pohlig-Hellman' algorithm for the field $\mathbb{F}_{2^n}$ for this project; this was a thought considered and attempted but due to the difference in compilers this could not be completed. As for the mathematical, analytical and written content provided, this can be passed as sufficient; to summarise - for future improvements, effort and endeavor is needed practically rather than theoretically.

To say the least, generally speaking, the results produced in support and completion of this project, in the timescale allocated, can be taken as fruitful and understood to have fulfilled the purpose of the \textbf{`Discrete Logarithm Problem in finite fields and applications to cryptography'}.







\bibliographystyle{plain}
\cleardoublepage
\phantomsection

\begin{thebibliography}{33}
\bibitem{HAC} A.J.Menezes, P.C.Van Oorschot, S.A.Vanstone
\newblock ``Handbook of Applied Cryptography"
\newblock {\em CRC Press LLC}, 1997

\bibitem{CNS} W.Stallings
\newblock ``Cryptography and Network Security - Principles and Practice (Fifth Edition)"
\newblock {\em Pearson Education Inc.}, 2011

\bibitem{CRYPT} D.R.Stinson
\newblock ``Cryptography - Theory and Practice"
\newblock {\em CRC Press LLC}, 2000

\bibitem{GRT} W.R.Scott
\newblock ``Group Theory"
\newblock {\em Dover Publications, Inc. New York}, 1987

\bibitem{GAT} S.H.Weintraub
\newblock``Galios Theory"
\newblock {\em Springer Science+Business Media, Inc. USA}, 2006

\bibitem{TGT} G.Smith and O.Tabachnikova
\newblock ``Topics in Group Theory"
\newblock {\em Springer-Verlag London Limited}, 2000

\bibitem{FFCSE} R.J.Mceliece
\newblock``Finite Fields for Computer Scientists and Engineers"
\newblock {\em Kluwer Academic Publishers. USA}, 1987

\bibitem{AC} B.Schneier
\newblock ``Applied Cryptography, SECOND EDITION: Protocols, Algorithms and Source Code in C"
\newblock {\em John Wiley and Sons, Inc.}, 1996

\bibitem{GF(2n)} I.F.Blake, R.C.Mullin and S.A.Vanstone
\newblock ``Computing Logarithms in GF(2$^n$)"
\newblock {\em Advances in Cryptology-BERLIN: SPRINGER, (Vol 196)},  1985

\bibitem{IndexCalc} O.Schirokauer, D.Weber and T.Denny
\newblock``Discrete Logarithms and the Effectiveness of the Index Calculus Method"
\newblock {\em Department of Mathematics - Oberlin College, USA,  Universit\"at des Saarlandes, Germany}

\bibitem{NDCrypt} W.Diffie and M.E.Hellman
\newblock``New Directions in Cryptography"
\newblock {\em IEEE Transactions on Information Theory (Vol-IT 22/6)}, 1976

\bibitem{Char2} D.Coppersmith
\newblock ``Fast Evaluation of Logarithms in Fields of Characteristic Two"
\newblock {\em IEEE Transactions on Information Theory (Vol-IT 30/4)}, 1984

\bibitem{SigScheme} E.Taher
\newblock``A Public Key Cryptosystem and a Signature Scheme Based on Discrete Logarithms"
\newblock {\em IEEE Transactions on Information Theory, (Vol-IT 31/4)},  1985

\bibitem{GF(p2)} E.Taher
\newblock ``A Subexponential-Time Algorithm for Computing Discrete Logarithms over GF(p$^2$)"
\newblock {\em IEEE Transactions on Information Theory (Vol-IT 31/4)}, 1985

\bibitem{ShortProof} H.Niederreiter
\newblock ``A Short Proof for Explicit Formulas for Discrete Logarithms in Finite Fields"
\newblock {\em AAECC (Vol 1), Springer-Verlag}, 1990

\bibitem{CPTFF} L.Rudolf
\newblock ``Computational Problems in the Theory of Finite Fields"
\newblock {\em AAECC (Vol 2), Springer-Verlag}, 1991

\bibitem{CGDLP} A.J.Menezes and S.A.Vanstone
\newblock ``A Note on Cyclic Groups, Finite Fields, and the Discrete Logarithm Problem"
\newblock {\em AAECC (Vol 3), Springer-Verlag}, 1992

\bibitem{NDL} G.Meletiou and G.L.Mullen
\newblock ``A Note on Discrete Logarithms in Finite Fields"
\newblock {\em AAECC (Vol 3), Springer-Verlag}, 1992

\bibitem{PH} A.J.Ly Thiong
\newblock ``A Serial Version of the Pohlig-Hellman Algorithm for Computing Discrete Logarithms"
\newblock {\em AAECC (Vol 4), Springer-Verlag}, 1993

\bibitem{DL} A.M.Odlyzko
\newblock ``Discrete Logarithms: The Past and the Future"
\newblock {\em Designs, Codes and Cryptography (Vol 19), Kluwer Academic Publishers, Boston}, 2000

\bibitem{PrimeFields} B.A.Lamacchia and  A.M.Odlyzko
\newblock ``Computation of Discrete Logarithms in Prime Fields"
\newblock {\em Designs, Codes and Cryptography (Vol 1), Academic Publishers}, 1991

\bibitem{Poly} R.L.Bender and C.Pomerance
\newblock ``Rigorous discrete logarithm computations in finite fields via smooth polynomials"
\newblock {\em AMS/IP Studies in Advanced Mathematics (Vol 7)}, 1998

\bibitem{SubExpo} L.M.Adleman and J.Demarrais
\newblock ``A Subexponential Algorithm for Discrete Logarithms over all Finite Fields"
\newblock {\em Mathematics of Computation (Vol 61/203) }, 1993

\bibitem{PRho} E.Teske
\newblock ``Speeding up Pollards Rho Method for computing Discrete Logarithms"
\newblock {\em Technische Universit\"at Darmstadt, Institut f\"ur Theoretische Informatik, Alexander-Strasse 10, 64283, Darmstadt, Germany}

\bibitem{BasesFF} H.Davenprot
\newblock ``Bases for Finite Fields"
\newblock {\em J.London Math Society, (Vol 43)}, 1968

\bibitem{DLP} K.S.McCurley
\newblock``The Discrete Logarithm Problem"
\newblock {\em American Mathematical Society - Proceedings of Symposis in Applied Mathematics, (Vol 42)}, 1990

\bibitem{DLCS} A.M.Odlyzko
\newblock ``Discrete Logarithms in Finite Fields and their Cryptographic Significance"
\newblock {\em AT and T Laboratories, New Jersey}

\bibitem{ElDL} C.Pomerance
\newblock``Elementary thoughts on discrete logarithms"
\newblock {\em Algorithmic Number Theory, MSRI Publications, (Vol 44)}, 2008

\bibitem{SoftGF(2n)} E.D.Win, A.Bosselaers, S.Vandenberghe, P.D.Gersem, J.Vandewalle
\newblock ``A Fast Software Implementation for Arithmetic Operations in GF(2$^n$) (PREPRINT)"
\newblock {\em Katholieke Universiteit, Leuven, ESAT-COSIC, K. Mercieriaan 94, B-3001 Henverlee, Belgium}

\bibitem{IntroMC} J.Hoffstein, J.Pipher and J.H.Silverman
\newblock ``An Introduction to Mathematical Cryptography"
\newblock {\em Mathematics 158, Brown University - Fall 2004}, Preliminary Version

\bibitem{MSc} R.Knight
\newblock ``Individual Bit Security of the Discrete Logarithm: Theory and Implementation Using Oracles"
\newblock {\em Master Thesis}, 2007

\bibitem{MSc2} J.Mihalcik
\newblock ``An analysis of Algorithms for solving Discrete Logarithms in fixed groups"
\newblock {\em Thesis}, Naval Postgraduate School, Monterey, California, 2010

\bibitem{BSc} L.Maurits
\newblock ``Public Key Cryptography using Discrete Logarithms in Finite Fields: Algorithms, Efficient Implementation and Attacks"
\newblock {\em BSc Thesis}, The University of Adelaide, Australia



\end{thebibliography}

\backmatter
\appendix


\chapter{Source Codes}

\section{Algorithms for $\mathbb{F}_p$}

\subsection{Brute-Force Search}

\begin{verbatim}

/*-------------------------ex_search.cpp----------------------

Implementation of the Exhaustive Search/Brute force method for 
computing the unique integer x such that alpha^x=beta for the 
Discrete Logarithm Problem in GF(p), with cyclic group G, order 
n, generator alpha and group element beta.

Code written by Divyesh B Chudasama on 07/07/2012.
Copyright (c) 2012

---------------------------ex_search.cpp--------------------*/

/*----------------Exhaustive Search Method-------------------*/

#include <stdio.h>
#include <time.h>
#include "std_lib_facilities.h"

int ex_search(int alpha, int beta, int n){ // Function Exhaustive Search
    
int b = 1;
int x = 0; 
        
while (beta != b){
      b = b*alpha;
      x = x + 1;
      }
      
      return x;
}

/*----------------End of Exhaustive Search Method----------------*/

/*-------------------------Main Function-------------------------*/

int main(){
    
int alpha;
int beta;
int n;
int ans =0;

    double time, timedif; // Double is used here to show small values

    time = (double) clock(); // Get the intial time
    time = time/CLOCKS_PER_SEC;  // Time in seconds 
    
    cout<<"\n Divyesh B Chudasama"
          "\n Copyright (c) 2012";

    cout<<"\n \n Implementation of the Exhaustive Search Method for" 
	          "\n computing the unique integer x such that" 
		          "\n x = log_{alpha}beta for the Discrete Logarithm" 
		    "\n Problem in GF(p), with cyclic group G," 
	    "\n order n, generator alpha and group element beta. ";	
             
    cout<<"\n \n Please enter a value for the generator `alpha': ";
    cin>>alpha;
    cout<<"\n Please enter a value for the element `beta': ";
    cin>>beta;
    cout<<"\n Please enter a value for the order `n' of the group:";
    cin>>n;
    
    ans = ex_search(alpha, beta, n); // Calling Exhaustive Search
    
    cout<<endl<<"\n The discrete logarithm x is: "<<ans<<endl<<endl;
    
    timedif = ( ((double) clock()) / CLOCKS_PER_SEC) - time;
    // Calling clock() function from start of program, subtracting 
    // its return value, then to obtain the final processor time 
    // in seconds, divide the value returned by clock() by 
    // CLOCK_PER_SEC 
    
    cout<<"\n The processor time elapsed is: "<<timedif<<" seconds"
    <<endl<<endl;
    
    keep_window_open();
    
    return 0;
}       
    
/*-----------------------End of Main Function--------------------*/

\end{verbatim}



\subsection{Shanks' ``Baby-Step Giant-Step" Method}

\begin{verbatim}

/*----------------------------BSGS.cpp-----------------------------

Implementation of Shanks' Baby-Step Giant Step Method for computing 
the unique integer x such that x = log_{alpha}(beta) for the Discrete 
Logarithm Problem, in GF(p), with cyclic group G, order n, generator 
alpha and group element beta.

Code written by Divyesh B Chudasama on 17/06/2012.
Copyright (c) 2012

-----------------------------BSGS.cpp----------------------------*/

/*---------------------Variable Declarations---------------------*/

#include <stdio.h>
#include "std_lib_facilities.h"
#include <iostream>
#include <math.h>
#include <list>
#include <time.h>

using namespace std;

/***************************Functions*****************************/

/*-----------------Multiplicative inverse in Z[n]----------------*/

struct  euclidean { // Creating a structure called euclidean
        
        int a; // First element in struct 
        int b; // Second element in struct
        int c; // Third element in struct
        
};

euclidean extended_euclidean(int a, int n) // Function 
//extended_euclidean that will return type euclidean

{
    // Using the extended Euclidean algorithm to find integers x 
    //such and y such that ax+ny = d, where d=gcd(a,n)

    int x,y,d,q,r;
    
    //Step 1.  
    if(n==0){ 
    d=a; // d<-a
    x=1; // x<-1
    y=0; // y<-0
    
    euclidean result={d,x,y}; // In the struct euclidean, 
    //elements 1,2 and 3 are d,x and y respectively
    
    return result; // return result
}
    
    //Step 2.
    int x2=1; // x2<-1
    int x1=0; // x1<-0
    int y2=0; // y2<-0
    int y1=1; // y1<-1
   
    
    //Step 3.
    while (n>0) { // While n>0 do the following:
          
          q=a/n; // q<-a/n
          r=a-(q*n); // r<-a-(q*n)
          x =(x2-(q*x1)); // x<-(x2-(q*x1))
          y=y2-(q*y1); // y<-y2-(q*y1)
          a=n; // a<-n
          n=r; // n<-r
          x2=x1; // x2<-x1
          x1=x; // x1<-x
          y2=y1; // y2<-y1
          y1=y; // y1<-y
    }
    
    //Step 4.
    d=a; // d<-a
    x=x2; // x<-x2
    y=y2; // y<-y2
    
    euclidean result={d,x,y}; // In the struct euclidean, 
    //elements 1,2 and 3 are d, x and y respectively
    
    return result; // return result
    
}   // This ends the extended Euclidean's algorithm

int mult_inv(int alpha,int n){
        
    // Making a new structure

    euclidean result_new = extended_euclidean(alpha,n); //Calling 
    // the function extended_euclidean and assigning it as type 
    //euclidean
    
    if(!(result_new.a>1)){ // If d (the first element in the struct) 
    //is greater 1 then a^(-1) mod n does not exist 

    return result_new.b; 
    // Return x (the second element in the struct)
    }

    else{

    cout<<"\n \n Multiplicative inverse cannot be computed"
          "\n please check input!"<<endl;
    
    return result_new.a; 
}   
}

/*--------------End of Multiplicative inverse in Z[n]-------------*/

/*----------------Square and Multiply algorithm-------------------*/

int s_and_m(int alpha, int A, int n){
    
    int b=1;
    
    while(A>0) // While A>0 do:
    {
              if ((A-1)%2==0) // If A=1{mod2}
              {
                              b=b*alpha; //b=b*alpha
                              b=b%n; // b=(b*alpha)modn
              }
              alpha=alpha*alpha; // alpha=alpha^2
              alpha=alpha%n; // alpha=alpha^2(modn)
              A=int(A/2); // A=[A/2]
    }
    return b; // Return b
    
}

/*-----------------End of Square and Multiply--------------------*/ 

/*----------------Big-Step Giant-Step function-------------------*/

int bsgs(int alpha, int beta, int n){ 
    int m;
    int j;
    int p=n+1; 
    int i;
    int x;
    
//Step 1.
m=int(sqrt(n))+1; //  Setting variable m to the square root of n 
//then add 1

//Step 2.
vector<int> B1; // B1 is a list of entries of values of size m
vector<int> B2; // Second list for sorting, this is the same as B1

/*-----------Baby Step: B=(j, (alpha^j)modp) for 0<=j<m-----------*/

double a;
a = double(alpha);
for(j=0;j<m;j++)
{				
			
      B1.push_back((int(pow(a, j)))%p); // Adds a new element at each
      // iteration to list B1, where the second element from each 
      // pair is (alpha^j)modp. 
      B2.push_back((int(pow(a, j)))%p); // Adding elements to list B2
              
                 }

sort(B2.begin(), B2.end()); // Sorting the second list 

//Step 3.
int c=mult_inv(alpha,p); // Assigning integer c to multiplicative 
//inverse of (alpha^-1)modp

double e=double(s_and_m(c,m,p)); // Using square and multiply method
//to calculate (alpha^-m)modp.

/*--------------------End of Baby Step--------------------------*/

/*------Giant Steps: gamma=(beta)(alpha^(-m*i))modp, 2)gamma^i where 
i=1,2,3..... and then comparing the values with the BabyStep results 
to find a common value---------*/ 

//Step 4.
int gamma;

bool endwhile=true; 
int z;
i=0;
while(endwhile){
              
              gamma=s_and_m(e,i,p); // square and multiply for values 
              //(e^i)modp
              gamma=gamma*beta; // gamma = gamma*beta
              gamma=gamma%p; // gamma = (gamma)modp
              
              for(int l=0; l<m; l++){
                      
              if(B2[l]==gamma){ // Comparing values from B2 to gamma
                            endwhile=false; 
                            z=i; 
                            
              for (int delta=0; delta<m; delta++){
                  
                  if (B2[l]==B1[delta]){ // Comparing lists B2 
		                  //and B1 to find the common component 
		                  //in both

                  j=delta;
                  //cout << j << endl;
                  }
                            }
              }
              }
              gamma=0;
              i++;
              }
              //return z;
              
              x=(z*m)+j;  // x=(z*m)+j    
              
                         return x;
              
                         }                        

/*---------------------End of Giant Step-----------------------*/

/*------------End of Baby-Step Giant-Step Function-------------*/

/************************End of Functions************************/

/*-----------------------Main Function--------------------------*/

int main(){
    
int alpha;
int beta;
int n;

    double time, timedif; // Double is used here to show small values

    time = (double) clock(); // Get the intial time
    time = time/CLOCKS_PER_SEC;  // Time in seconds 
    
    cout<<"\n Divyesh B Chudasama"
          "\n Copyright (c) 2012";
          
    cout<<"\n \n Implementation of Shanks' Baby-Step Giant-Step Method" 
		          "\n for computing the unique integer x such that" 
		          "\n x = log_{alpha}beta for the Discrete Logarithm Problem" 
	          "\n in GF(p), with cyclic group G, order n, generator alpha"
          "\n and group element beta. ";
             
    cout<<"\n \n Please enter a value for the generator `alpha': ";
    cin>>alpha;
    cout<<"\n Please enter a value for the element `beta': ";
    cin>>beta;
    cout<<"\n Please enter a value for the order `n' of the group:";
    cin>>n;
    
    int x=bsgs(alpha,beta,n); // Calling Baby-Step Giant-Step
    
    cout<<endl<<"\n The discrete logarithm x is: "<<x<<endl<<endl;
    
    timedif = ( ((double) clock()) / CLOCKS_PER_SEC) - time; 
    // Calling clock() function from start of program, subtracting 
    // its return value, then to obtain the final processor time 
    //in seconds, divide the value returned by clock() 
    //by CLOCK_PER_SEC
    
    cout<<"\n The processor time elapsed is: "<<timedif<<" seconds"
    <<endl<<endl;
    
    keep_window_open();
    
    return 0;
}       
    
/*-------------------End of Main Function-----------------------*/    

\end{verbatim}




\subsection{Pollard's $\rho$ algorithm for logarithms}

\begin{verbatim}

/*---------------------pollard_rho.cpp---------------------------

Implementation of Pollard's Rho Method for computing the unique 
integer x such that x = log_{alpha}(beta) for the Discrete Logarithm 
Problem in GF(p), with cyclic group G, order n, generator alpha 
and group element beta.

Code written by Divyesh B Chudasama on 09/07/2012.
Copyright (c) 2012

----------------------pollard_rho.cpp---------------------------*/

#include <stdio.h>
#include <time.h>
#include "std_lib_facilities.h"

/***************************Functions****************************/

/*---------------Set functions for S1, S2 and S3----------------*/

int alpha;
int beta;
int n;

int f(int x){// Function f(x_i) for sequence of group elements 
             //x_(i+1) where, x=(x_i)
    
    if(x%3==0){ // If x_i is an element of S2
                x=(x*x)%n;// x_(i+1)=((x_i)^2)modn
                }
                
                else if(x%3==1){ // If x_i is an element of S3
                     x=(alpha*x)%n; // x_(i+1)=(alpha*(x_i))modn
                     }
                     
                else if(x%3==2){ // If x_i is an element of S1
                     x=(beta*x)%n; // x_(i+1)=(beta*(x_i))modn
                     }
                     return x;
                     }

int g(int x, int a){ // Function g(x_i,a_i) for sequence of 
                     //integers a_(i+1) where x=(x_i) and 
                     //a=(a_i)/a_(i+1)
    
    if(x%3==0){ // If x_i is an element of S2
               a=(2*a); // a_(i+1)=(2*(a_i))
               }
               
               else if(x%3==1){ // If x_i is an element of S3
                    a=(a+1); // a_(i+1)=(a_i)+1
                    }
                    
               else if(x%3==2){ // If x_i is an element of S1
                    a=a; // a_(i+1)=a_i
                    } 
                    return a;      
                    }
                    
int h(int x, int b){ // Function h(x_i,b_i) for sequence of 
                     //integers b_(i+1)
                     // where x=(x_i) and b=(b_i)/b_(b+1)
    
    if(x%3==0){ // If x_i is an element of S2
               b=(2*b); // b_(i+1)=(2*(b_i))
               }
               
               else if(x%3==1){ // If x_i is an element of S3
                    b=b; // b_(i+1)=(b_i)
                    }
                    
               else if(x%3==2){ // If x_i is an element of S1
                    b=(b+1); // b_(i+1)=(b_i)+1
                    }
                    return b;
                    }
                                   
/*------------End of Set functions for S1, S2 and S3-----------*/

/*--------------------Pollard's Rho function-------------------*/

int pollard_rho(int alpha, int beta, int n){ 
    
    int i;
    
    vector<int> x; // Vector list x
    vector<int> a; // Vector list a
    vector<int> b; // Vector list b
    
    x.push_back(1); // Adding entry x_0=1 to the vector list x
    a.push_back(0); // Adding entry a_0=0 to the vector list a
    b.push_back(0); // Adding entry b_0=0 to the vector list b
    
    int X;
    int A;
    int B;
    int r;
    int c;
    int d;
    int e;
    int z = 0;
    int p=n-1;
    
    
    for(i=1; i<n; i++){
    // Computing the values x_i, a_i and b_i using the quantities 
    // of x_(i-1), a_(i-1) and b(i-1) computed previously from  
    // functions f, g and h         
             
             c=f(x[i-1]); // c=f(x_(i-1))
             
             x.push_back(c); // Each iterative value of c is added 
             // to vector list x
             
             d=(g(x[i-1], a[i-1]))%p; // d=g(x_(i-1),a_(i-1))
             a.push_back(d); // Each iterative value of d is 
             //added to vector list a
             
             e=(h(x[i-1], b[i-1]))%p; // e=h(x_(i-1),b(i-1))
             b.push_back(e); // Each iterative value of e is 
             //added to vector list b

             }
             
    for(i=1; i<n; i++){
    // Now computing x_(2i), a_(2i) and b_(2i)
            
             if(x[i]==x[2*i]){
            
             X=f(f(x[(2*i)-2])); // X=x_(2i)
             
             A=(g(f(x[(2*i)-2]), g(x[(2*i)-2], a[(2*i)-2])))%p; 
             // A=a_(2i)
        
             B=(h(f(x[(2*i)-2]), h(x[(2*i)-2], b[(2*i)-2])))%p; 
             // B=b_(2i)
             
             break;
             }
             }
    for(i=1; i<n; i++){     
       if( x[i] == X ){ // If x_i = x_(2i)
                   
                r=(b[i]-B); // r=((b_i)-b_(2i))
                
       if(r==0){ // If r=0

            cout<<"\n 'Pollard's rho method failed to find unique 
                  "\n integer x as r=0!"
                  "\n No Discrete Logarithm x for the above values!'"
                  <<endl;

            return r;
            break; // Terminate algorithm with failure
            }

            else{
                  
                 z=(a[i]-A)/(B-b[i]); 
                 // z=(((a_i)-a_(2i))/(b_(2i)-b_i)) 
                 z= z%p;
                 if(z<0){ // If z is -ve
                         z=(p+z); // then mod(n-1)+z
                         }
                         }
                 return z;
                 break;
                 }
                 
}
}

/*------------------End of Pollard's Rho function-----------------*/

/***********************End of Functions***************************/

/*-------------------------Main function--------------------------*/

int main(){
    
    double time, timedif; // Double is used here to show small values

    time = (double) clock(); // Get the intial time
    time = time/CLOCKS_PER_SEC;  // Time in seconds 
    
    cout<<"\n Divyesh B Chudasama"
          "\n Copyright (c) 2012";
    
    cout<<"\n \n Implementation of Pollard's Rho Method for computing" 
          "\n the unique integer x such that x = log_{alpha}beta" 
          "\n for the Discrete Logarithm Problem in GF(p), with cyclic" 
          "\n group G, order n, generator alpha and group element" 
          "\n beta. ";
              
    cout<<"\n \n Please enter a value for the generator `alpha': ";
    cin>>alpha;
    cout<<"\n Please enter a value for the element `beta': ";
    cin>>beta;
    cout<<"\n Please enter a value for the order `n' of the group:";
    cin>>n;
    
    int y=pollard_rho(alpha, beta, n); //Calling Pollard Rho
    
    cout<<endl<<"\n The discrete logarithm x is: "<<y<<endl<<endl;
    
    timedif = ( ((double) clock()) / CLOCKS_PER_SEC) - time; 
    // Calling clock() function from start of program, subtracting 
    // its return value, then to obtain the final processor time in 
    // seconds, divide the value returned by clock() by CLOCK_PER_SEC
    
    cout<<"\n The processor time elapsed is: "<<timedif<<" seconds"
    <<endl<<endl;
    
    keep_window_open();
    
    return 0;
}       

/*----------------------End of Main function----------------------*/

\end{verbatim}





\subsection{Pohlig-Hellman Algorithm}

\begin{verbatim}


/*----------------------Pohlig_Hellman.cpp--------------------------

Implementation of the Pohlig-Hellman Algorithm for computing the 
unique integer x such that x = log_{alpha}(beta) for the Discrete 
Logarithm Problem,in GF(p), with cyclic group G, order n, generator 
alpha and group element beta.

Code written by Divyesh B Chudasama on 12/08/2012.
Copyright (c) 2012

------------------------Pohlig_Hellman.cpp------------------------*/

#include <stdio.h>
#include <iostream>
#include <cmath>
#include <stdlib.h>
#include <time.h>
#include "std_lib_facilities.h"

/****************************Functions*****************************/

struct ph{ // Structure ph
       vector<int> a; // First element in structure
       vector<int> b; // Second element in structure
       };
       
struct  euclidean { // Creating another structure called euclidean
        
        int a; // First element in struct 
        int b; // Second element in struct
        int c; // Third element in struct
        
};

euclidean extended_euclidean(int a, int n) 
// Function extended_euclidean that 
// will return type euclidean

{
    // Using the extended Euclidean algorithm to find integers x 
    // such and y such that ax+ny = d, where d=gcd(a,n)

    int x,y,d,q,r;
    
    //Step 1.  
    if(n==0){ 
    d=a; // d<-a
    x=1; // x<-1
    y=0; // y<-0
    
    euclidean result={d,x,y}; // In the struct euclidean, 
    //elements 1,2 and 3 are d,x and y respectively
    
    return result; // return result
}
    
    //Step 2.
    int x2=1; // x2<-1
    int x1=0; // x1<-0
    int y2=0; // y2<-0
    int y1=1; // y1<-1
   
    
    //Step 3.
    while (n>0) { // While n>0 do the following:
          
          q=a/n; // q<-a/n
          r=a-(q*n); // r<-a-(q*n)
          x =(x2-(q*x1)); // x<-(x2-(q*x1))
          y=y2-(q*y1); // y<-y2-(q*y1)
          a=n; // a<-n
          n=r; // n<-r
          x2=x1; // x2<-x1
          x1=x; // x1<-x
          y2=y1; // y2<-y1
          y1=y; // y1<-y
    }
    
    //Step 4.
    d=a; // d<-a
    x=x2; // x<-x2
    y=y2; // y<-y2
    
    euclidean result={d,x,y}; // In the struct euclidean, 
    //elements 1,2 and 3 are d, x and y respectively
    
    return result; // return result
    
}   // This ends the extended Euclidean's algorithm

int mult_inv(int alpha,int n){
        
    // Making a new structure

    euclidean result_new = extended_euclidean(alpha,n); 
    //Calling the function extended_euclidean and 
    //assigning it as type euclidean 
    
    if(!(result_new.a>1)) // If d (the first element in the struct) 
    // is greater 1 then a^(-1) mod n does not exist 

    return result_new.b; // Return x (the second element in the struct)
    
    else 
    
    return result_new.a; 
}

/*-------------------Greatest Common Divisor---------------------*/

int gcd(int a,int b) { // Function gcd for use in Chinese Remainder 
                       // Theorem
    if(a==0)
    return b;
    if(b==0)
    return a;
    if(a>b)
    return(gcd(a%b,b)); // Greatest Common Divisor (a mod(b), b)
    if(b>a)
    return(gcd(b%a,a)); // Greatest Common Divisor (b mod(a), a)
    }
    
/*----------------End of Greatest Common Divisor------------------*/

/*-----------------------Inverse Function-------------------------*/    
    
int inverse(int a,int b) {// Function inverse for use in CRT
                          // here a-->modulus,b-->element 
    int gcd,x=0,y=1,k=a;
    int u=1, v=0, m, n, q, r;
    gcd = b;
    while(a!=0){ // a is NOT equal to 0
           q=gcd/a; // q<-gcd/a
           r=gcd%a; // r<-gcd mod a
           m=x-u*q; // m<-x-(u*q)
           n=y-v*q; // n<-y-(v*q)
           gcd=a; // gcd<-a
           a=r; // a<-r
           x=u; // x<-u
           y=v; // y<-u
           u=m; // u<-m
           v=n; // v<-n
           }
           while(y<0){
                 y=k+y;
           }return y; // Give back value of y
}

/*---------------------End of Inverse function---------------------*/

/*--------------------Chinese Remainder Theorem--------------------*/

int ChineseTheorem(vector<int> x, vector<int> Z){ 

int k = x.size(); // k is the size of vector x
int m[k],a[k],i,n=1; // Initialising array's m and a of size k i.e 
                              // equivalent to the size of vector x 
                              // and integers i and n. Assigning n 
                              // to value 1.

for(i=0;i<k;i++){ // i iterates from 0 to (vector size x)-1
                 a[i] = Z[i]; // Assigning array a to vector Z
                 m[i] = x[i]; // Assigning array m to vector x 
       if(i>0){

                if(gcd(m[i-1],m[i])!=1){ // If the Greatest Common
                //Divisor of (m[i-1],m[i]) is NOT equal to 1
                 
       return 1;
                   }
                   }
                   n=n*m[i]; // Every iterative value of array m is
                   // multiplied by n then assigned to n
                   }

       int sol=0,B=1
       for(i=0;i<k;i++){
                         
       B=a[i]*(n/m[i])*inverse(m[i],n/m[i]); // Integer B is 
       // equivalent to array a multiplied by (n divided by 
       //array m) multiplied by the inverse of (array m and n
       //divided by array m), for which i iterates from 0 to 
       //vector size x
                         
                         sol=sol+B; // sol = sol add the value of B
                         }sol=sol%n; // sol = sol mod n
return sol;
}

/*----------------End of Chinese Remainder Theorem-----------------*/

/*-------------------Square and Multiply algorithm-----------------*/
       
int s_and_m(int alpha, int A, int n){
    
    int b=1;
    
    while(A>0) // While A>0 do:
    {
              if ((A-1)%2==0) // If A=1{mod2}
              {
                              b=b*alpha; //b=b*alpha
                              b=b%n; // b=(b*alpha)modn
              }
              alpha=alpha*alpha; // alpha=alpha^2
              alpha=alpha%n; // alpha=alpha^2(modn)
              A=int(A/2); // A=[A/2]
    }
    return b; // Return b
    
}

/*---------------End of Square and Multiply algorithm--------------*/

/*--------------------Prime Factorisation--------------------------*/

ph prime_fact(int n) {// Function prime factorisation of structure ph

int i = 2;
int count;
vector<int> q, c;
 
while (n > 1 && i <= n) { // n has to be both greater then 1 AND less 
                          // than and equal to i. && Boolean operator 
                          // AND, hence will only work if both 
                          // conditions on left and right hand sides 
                          //are satisfied
  
  if (n % i == 0){ // If n mod i is NOT equal to 0
        
        q.push_back(i); // Adding i values to vector q
        count = 1;
        n = n / i; // n = n divided by i
        while (n % i == 0) { // n mod i is NOT equal to 0
              count = count + 1;
              n = n / i;
              }
        
        c.push_back(count); // Adding count values to vector c
        }
  i = i + 1;
  }
  ph pH = {q,c}; // Storing vectors q and c in pH
  return pH; // Give back pH
}

/*-------------------End of Prime Factorisation-------------------*/

/*--------------------Pohlig-Hellman algorithm--------------------*/

int PHellman(int a, int b, int n){
    
    vector<int> g, l, alp, A, B;
    int z = 0, q = 0, e = 0, delta, gamma, alpha, beta, r;

    int p=n+1;
    ph x=prime_fact(n); // Calling function prime factorisation 
                        // and factorising for prime factors 
                        // of the value of order n
   
    for(int k = 0; k<x.a.size();k++){ // k goes from 0 to value of 
                                      //(prime facotorisation - 1)
    
    q = x.a[k]; // q = values of primes factors a[k]
    e= x.b[k]; // e = exponential values of prime factors b[k]
    
    B.push_back(int(pow((double)x.a[k], x.b[k]))); 
    // Calculating q^e and adding to vector B
    
    l.push_back(0); // l_[-1]=0
    gamma=1;
   
    for(int j =0; j<e;j++){ // j goes from 0 to 
                            // (maximum exponent value - 1)
   
    alpha=s_and_m(a, n/q, p); // Square and multiply method for 
                              // (a^(n/q)) then equating to alpha

    gamma=gamma*(s_and_m(a, (l[j]*((int)(pow((double) q, j-1)))), p));

    // Square and multiply method for gamma*a^((l_[j-1])*(q^[j-1])) 
    // then mod p and assigning to gamma

    gamma=gamma%p; // Gamma = gamma mod(p)
    
    for(int i=0;i<=x.a[k]-1;i++){ // i goes from 0 to q-1
   
    z=s_and_m(a, ((n*i)/x.a[k]), p);
    // Square and multiply method for a^((n*i)/q) then mod p
    // and assigning to z
   
    g.push_back(z); // Adding z value to vector g
}

    beta=mult_inv(gamma, p); // Multiplicative inverse of gamma 
                             // then mod p and assigning to beta
    beta=beta*b; 
    while(beta<0){
    beta=beta+p;
}
    beta = beta%p; // beta mod(p)
    
    beta=s_and_m(beta, (n/(int(pow((double)x.a[k], j+1)))),p); 
    // Square and multiply for beta^(n/q^(j+1)) then mod p.
    // Assigning value to beta

    for(int y=0; y<g.size(); y++){ // y goes from 0 to 
                                   // (size of vector g) - 1

    if(beta==g[y]){ // Comparing values of beta and y^th 
                    // value in vector g
    l.push_back(y); // Adding y values to vector l
   
    g.clear(); // Clearing vector g
    break;
}
}
}
int t =0;
    for(int q=1;q<l.size();q++){// q goes from 1 to (size of l) - 1
        t = t + (l[q]*((int)pow((double) x.a[k], q-1)));
        // t + (l[q]*(prime factors^(q-1))) then assign to t
        }
        
        A.push_back(t); // Adding t values to the vector A
l.clear(); // Clearing vector l
}

int m = ChineseTheorem(B, A); // Calling the function Chinese Remainder 
                              // Theorem to solve pair of congruences 
                              // A and B. Equate to integer m
return m; // Give back value of m
}

/*-----------------End of Pohlig-Hellman algorithm-----------------*/

/************************End of Functions***************************/

/*--------------------------Main Function---------------------------*/

int main(){
    
    int alpha, beta ,n;
    
     double time, timedif; // Double is used here to show small values

    time = (double) clock(); // Get the intial time
    time = time/CLOCKS_PER_SEC;  // Time in seconds 
    
    cout<<"\n Divyesh B Chudasama"
          "\n Copyright (c) 2012";
          
     cout<<"\n \n Implementation of the Pohlig Hellman algorithm for" 
           "\n computing the unique integer x such that" 
           "\n x = log_{alpha}beta for the Discrete Logarithm" 
           "\n Problem in GF(p), with cyclic group G, order n," 
           "\n generator alpha and group element beta. ";
          
    cout<<"\n \n Please enter a value for 'alpha': ";
    cin>>alpha;
    cout<<"\n Please enter a value for 'beta': ";
    cin>>beta;
    cout<<"\n Please enter a value for 'n': ";
    cin>>n;
   
   int r = PHellman(alpha, beta, n); // Calling Pohlig Hellman
   
   if(r==1)
            
       cout<<"\n There is no unique solution to this problem.\n\n";
   
   else if(r > 1)
    
    cout<<endl<<"\n The discrete logarithm x is: "<<r<<endl<<endl;
    
    timedif = ( ((double) clock()) / CLOCKS_PER_SEC) - time; 
    // Calling clock() function from start of program, subtracting 
    // its return value, then to obtain the final processor time in 
    // seconds, divide the value returned by clock() by 
    // CLOCK_PER_SEC
    
    cout<<"\n The processor time elapsed is: "<<timedif<<" seconds"
    <<endl<<endl;
    
    keep_window_open();
       
}

/*----------------------End of Main Function----------------------*/


\end{verbatim}



\newpage

\section{Algorithms for $\mathbb{F}_{p^n}$}

\subsection{Brute-Force Search}

\begin{verbatim}

/*-----------------------ex_search_2n.cpp---------------------------

Implementation of the Exhaustive Search/Brute Force method for
computing the unique integer x such beta=alpha^x for the Discrete 
Logarithm Problem in the finite field GF(2^n), where n is the value 
of the field exponent, alpha and beta are Galois Field Elements and 
prim_poly is the primitive polynomial of the field.

Code written by Divyesh B Chudasama on 14/08/2012.
Copyright (c) 2012

-------------------------ex_search_2n.cpp--------------------------*/

/*---------------------Exhaustive Search Method---------------------*/

//#include "stdafx.h" // Only include for VS 2010
#include <stdio.h>
#include <time.h>
#include "std_lib_facilities.h"
#include "GaloisFieldElement.h"

using namespace galois;

// Initialising primitive polynomial
unsigned int prim_poly[4] = {1, 0, 1, 1}; 

// Creating Galois Field, where the integer value has to be changed 
//according to the power
GaloisField gf(3, prim_poly);			 

GaloisFieldElement alpha(&gf, 2); 
//Galois Field Element alpha...change value accordingly 

GaloisFieldElement beta(&gf, 4); 
// Galois Field Element beta...change value accordingly

unsigned int o = (2^3)-1; 
// Exponent power corresponds to value assigned above when 
//initialising Galois Field.

int ex_search(GaloisFieldElement alpha, GaloisFieldElement beta, 
unsigned int o){ // Function Exhaustive Search

vector<GaloisFieldElement> B1; // List

GaloisFieldElement b(&gf, 1);

unsigned int x;

for(x=0; x<o; x++){

        B1.push_back(b); // Adding entries to list B1
        b=(b*alpha);

        }

for(unsigned int y=0; y<B1.size(); y++){ //

    if(B1[y]==beta) // Comparing list value to find a match with beta

        return y;
}

}

/*------------------End of Exhaustive Search Method----------------*/

/*---------------------------Main Function-------------------------*/

int main(){

int ans;

	double time, timedif; // Double is used here to show small values

    time = (double) clock(); // Get the initial time
    time = time/CLOCKS_PER_SEC;  // Time in seconds 
    
    cout<<"\n Divyesh B Chudasama"
          "\n Copyright (c) 2012";
	
    cout<<"\n \n Implementation of the Exhaustive Search/Brute-Force" 
		          "\n method for computing the unique integer x for the" 
          "\n Discrete Logarithm Problem in the finite field" 
          "\n GF(2^n), where n is the value of the field exponent" 
          "\n alpha and beta are Galois Field Elements and prim_poly 
          "\n is the primitive polynomial of the field. ";

    ans = ex_search(alpha, beta, 7); // Calling Exhaustive Search

    cout<<endl<<"\n \n The discrete logarithm x is: "<<ans<<endl<<endl;

	    timedif = ( ((double) clock()) / CLOCKS_PER_SEC) - time; 
    // Calling clock() function from start of program, subtracting 
    // its return value, then to obtain the final processor time 
    // in seconds, divide the value returned by clock() 
    // by CLOCK_PER_SEC
    
    cout<<"\n The processor time elapsed is: "<<timedif<<" seconds"
    <<endl<<endl;
  
	keep_window_open();

    return 0;
} 

/*----------------------End of Main Function----------------------*/

\end{verbatim}





\newpage

\subsection{Shanks' ``Baby-Step Giant-Step" Method}

\begin{verbatim}

/*---------------------------BSGS_2n.cpp------------------------

Implementation of Shanks' Baby-Step Giant Step Method for computing 
the unique integer x such that beta=alpha^x for the Discrete 
Logarithm Problem, in the finite field GF(2^n), where n is the value 
of the field exponent, alpha and beta are Galois Field Elements and 
prim_poly is the primitive polynomial of the field.

Code written by Divyesh B Chudasama on 25/08/2012.
Copyright (c) 2012

---------------------------BSGS_2n.cpp-------------------------*/

/*--------------------Variable Declarations--------------------*/

#include "stdafx.h"
#include <stdio.h>
#include "std_lib_facilities.h"
#include <iostream>
#include <math.h>
#include <list>
#include <time.h>
#include "GaloisFieldElement.h"

using namespace galois;

// Initialising primitive polynomial
unsigned int prim_poly[11] = {1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1}; 


GaloisField gf(10, prim_poly); 
// Creating Galois Field, where the integer value represents 
// the exponent n, i.e. 2^n. This value has to be changed 
// according to the power

GaloisFieldElement alpha(&gf, 2); 
// Galois Field Element alpha is fixed at value 2

GaloisFieldElement beta(&gf, 4); 
// Galois Field element beta...change value accordingly

/**************************Functions***************************/

/*---------------Multiplicative inverse in Z[n]---------------*/

struct  euclidean { // Creating a structure called euclidean
        
        GaloisFieldElement a; // First element in struct 
        GaloisFieldElement b; // Second element in struct
        GaloisFieldElement c; // Third element in struct
        
};

euclidean extended_euclidean(GaloisFieldElement g, 
GaloisFieldElement h) 
// Function extended_euclidean that will return type euclidean

{
    // Using the extended Euclidean algorithm to find integers x 
    // such and y such that ax+ny = d, where d=gcd(g,h)

    GaloisFieldElement d,q,r;
    
    //Step 1.  
    if(h==0){ 
    d=g; // d<-g
    GaloisFieldElement x(&gf, 1); // x<-1
    GaloisFieldElement y(&gf, 0); // y<-0

	euclidean result= {d,x,y}; // In the struct euclidean, elements 1,2 
      			      			             // and 3 are d,x and y respectively
    
    return result; // return result
}
    
    //Step 2.
	GaloisFieldElement x(&gf, 1); // x<-1
    GaloisFieldElement y(&gf, 0); // y<-0
    GaloisFieldElement x2(&gf, 1);// x2<-1
    GaloisFieldElement x1(&gf, 0); // x1<-0
    GaloisFieldElement y2(&gf, 0); // y2<-0
    GaloisFieldElement y1(&gf, 1); // y1<-1
   
    
    //Step 3.
    while (h>0) { // While h is NOT equal to 0 do the following:
          
          q=g/h; // q<-a/n
          r=g-(q*h); // r<-a-(q*n)
          x=x2-(q*x1); // x<-(x2-(q*x1))
          y=y2-(q*y1); // y<-y2-(q*y1)
          g=h; // a<-n
          h=r; // n<-r
          x2=x1; // x2<-x1
          x1=x; // x1<-x
          y2=y1; // y2<-y1
          y1=y; // y1<-y
    }
    
    //Step 4.
    d=g; // d<-g
    x=x2; // x<-x2
    y=y2; // y<-y2
    
    euclidean result={d,x,y}; // In the struct euclidean, elements 1,
					                             // 2 and 3 are d,x and y respectively
    
    return result; // return result
    
}   // This ends the extended Euclidean's algorithm

GaloisFieldElement mult_inv(GaloisFieldElement alpha, 
GaloisFieldElement n){
        
    // Making a new structure
    euclidean result_new = extended_euclidean(alpha,n); 
    //Calling the function extended_euclidean and 
    //assigning it as type euclidean
	
	if(!(result_new.a>1)) // If d (the first element in the struct)
                      // is greater 1 then a^(-1) mod n does
                      // not exist 

		return result_new.b; // Return x (the second element in the struct)

	else

		return result_new.a;

}   

/*-------------End of Multiplicative inverse in Z[n]------------*/

/*----------------Square and Multiply algorithm-----------------*/

GaloisFieldElement s_and_m(GaloisFieldElement alpha, int A){
    
    GaloisFieldElement b(&gf, 1);

    while(A>0) // While A>0 do:
    {
              if ((A-1)==0) // If A-1=0
              {
                              b=b*alpha; //b=b*alpha                
              }
              alpha=alpha*alpha; // alpha=alpha^2
           
              A=A/2; // A=[A/2]
    }
    return b; // Return b
    
}

/*-----------------End of Square and Multiply-------------------*/ 

/*-------------------Big-Step Giant-Step function--------------*/

int bsgs(GaloisFieldElement alpha, GaloisFieldElement beta, 
unsigned int o){ 

    unsigned int m;
    unsigned int j;
	    double f;

	GaloisFieldElement s(&gf, 1); // s is fixed to 1, 
 	// GaloisFieldElement for conveniency
   
	 GaloisFieldElement p = ((alpha^10) - s) + s; 
	// p = ((2^n)-1) + 1 = (2^n), the value of the
// power is to be changed according to n

    unsigned int i;
    unsigned int x;
    
//Step 1.
f = pow(2.0, 10.0) - 1; // For conveniency values of type double 
		                        //have been used the second input is to 
 				                      //be changed based on the value of n

m=int(sqrt(f))+1; 
//  Setting variable m to the square root of o then add 1


//Step 2.
vector<GaloisFieldElement> B1; 
// B1 is a list of entries of values of size m

vector<GaloisFieldElement> B2; 
// Second list for sorting, this is the same as B1

/*---------Baby Step: B=(j, (alpha^j)modp) for 0<=j<m----------*/

//double a;
//a = double(alpha);
for(j=0;j<m;j++)
{				
			
    B1.push_back((alpha^j)); // Adds a new element at each
    // iteration to list B1, where the second element from each 
    // pair is (alpha^j). 

    B2.push_back((alpha^j)); // Adding elements to list B2
              
                 }

sort(B2.begin(), B2.end()); // Sorting the second list 

//Step 3.
GaloisFieldElement c;

c = mult_inv(alpha,p); 
// Assigning integer c to multiplicative inverse of 
// (alpha^-1)modp


GaloisFieldElement e;

e = s_and_m(c,m); // Using square and multiply method to 
				                  //calculate (alpha^-m)

/*---------------------End of Baby Step----------------------*/

/*------Giant Steps: gamma=(beta)(alpha^(-m*i))modp, 2)gamma^i 
where i=1,2,3..... and then comparing the values with the BabyStep 
results to find a common value---------*/ 

//Step 4.
GaloisFieldElement gamma;

bool endwhile=true; 
int z;
i=0;
while(endwhile){
              
gamma=s_and_m(e,i); // square and multiply for values (e^i)modp
              gamma=gamma*beta; // gamma = gamma*beta
              
              for(int l=0; l<m; l++){
                      
              if(B2[l]==gamma){ // Comparing values from B2 to gamma
                            endwhile=false; 
                            z=i; 
                            
              for (int delta=0; delta<m; delta++){
                  
if (B2[l]==B1[delta]){ // Comparing lists B2 and B1 to find 
                       // the common component in both
j=delta;

                  }
                            }
              }
              }
              gamma=0;
              i++;
              }
              //return z;
              
              x=(z*m)+j;  // x=(z*m)+j    
              
                         return x;
              
                         }                        

/*----------------------End of Giant Step---------------------*/

/*------------End of Baby-Step Giant-Step Function------------*/

/*********************End of Functions*************************/

/*-----------------------Main Function------------------------*/

int main(){

    double time, timedif; 
    // Double is used here to show small values

    time = (double) clock(); // Get the intial time
    time = time/CLOCKS_PER_SEC;  // Time in seconds 
    
    cout<<"\n Divyesh B Chudasama"
          "\n Copyright (c) 2012";
          
    cout<<"\n \n Implementation of Shanks' Baby-Step Giant-Step" 
		          "\n Method for computing the unique integer x such" 
          "\n that beta = alpha^x, for the Discrete Logarithm" 
          "\n Problem in the finite field GF(2^n), where n is" 
		          "\n the value of the field exponent, alpha and beta are" 
          "\n Galois Field Elements and prim_poly is the primitive" 
          "\n polynomial of the field. ";

    int x=bsgs(alpha,beta,1023); // Calling Baby-Step Giant-Step
							   // the last input is to be changed based on (2^n)-1

    cout<<endl<<"\n The discrete logarithm x is: "<<x<<endl<<endl;
    
    timedif = ( ((double) clock()) / CLOCKS_PER_SEC) - time; 
    // Calling clock() function from start of program, 
    // subtracting its return value, then to obtain the final 
    // processor time in seconds, divide the value returned 
    // by clock() by CLOCK_PER_SEC
    
    cout<<"\n The processor time elapsed is: "<<timedif<<" seconds"
    <<endl<<endl;
    
    keep_window_open();
    
    return 0;
}       
    
/*---------------------End of Main Function---------------------*/    

\end{verbatim}





\subsection{Pollard's $\rho$ algorithm for logarithms}

\begin{verbatim}

/*--------------------pollard_rho.cpp---------------------------

Implementation of Pollard's Rho Method for computing the unique 
integer x such that beta=alpha^x for the Discrete Logarithm 
Problem, in the finite field GF(2^n), where n is the value of the 
field exponent, alpha and beta are Galois Field Elements and 
prim_poly is the primitive polynomial of the field.

Code written by Divyesh B Chudasama on 26/08/2012.
Copyright (c) 2012

-------------------pollard_rho.cpp----------------------------*/

#include "stdafx.h"
#include <stdio.h>
#include <time.h>
#include "std_lib_facilities.h"
#include "GaloisFieldElement.h"

using namespace galois;

unsigned int prim_poly[7] = {1, 0, 0, 0, 0, 1, 1}; 
// Initialising primitive polynomial

GaloisField gf(6, prim_poly); 
// Creating Galois Field, where the integer value 
// represents the exponent n, i.e. 2^n. This value
// has to be changed according to the power

GaloisFieldElement alpha(&gf, 2); 
// Galois Field Element alpha is fixed at value 2

GaloisFieldElement beta(&gf, 4); 
// Galois Field element beta...change value accordingly

unsigned int O = int(pow(2.0, 6.0))-1; 
// Exponent power corresponds to value assigned above
// when initialising Galois Field.

/*************************Functions****************************/

/*--------------Set functions for S1, S2 and S3---------------*/

GaloisFieldElement f(GaloisFieldElement x){// Function f(x_i) 
//for sequence of group elements x_(i+1) where x=(x_i)
    
    if(x==0){ // If x_i is an element of S2
                x=(x*x);// x_(i+1)=((x_i)^2)
                }
                
                else if(x==1){ // If x_i is an element of S3
                     x=(alpha*x); // x_(i+1)=(alpha*(x_i))
                     }
                     
                else if(x==2){ // If x_i is an element of S1
                     x=(beta*x); // x_(i+1)=(beta*(x_i))
                     }
                     return x;
                     }

GaloisFieldElement g(GaloisFieldElement x, GaloisFieldElement a){ 
// Function g(x_i,a_i) for sequence of integers a_(i+1)
// where x=(x_i) and a=(a_i)/a_(i+1)
    
	GaloisFieldElement c(&gf, 1); // c=1, for use with x==1 condition
	GaloisFieldElement f(&gf, 2); // f=2, for use with x==0 condition

    if(x==0){ // If x_i is an element of S2
               a=(f*a); // a_(i+1)=(2*(a_i))
               }
               
               else if(x==1){ // If x_i is an element of S3
                    a=(a+c); // a_(i+1)=(a_i)+1
                    }
                    
               else if(x==2){ // If x_i is an element of S1
                    a=a; // a_(i+1)=a_i
                    } 
                    return a;      
                    }
                    
GaloisFieldElement h(GaloisFieldElement x, GaloisFieldElement b){ 
// Function h(x_i,b_i) for sequence of integers b_(i+1)
// where x=(x_i) and b=(b_i)/b_(b+1)
    
	GaloisFieldElement e(&gf, 1); // e=1, for use with x==2 condition
	GaloisFieldElement q(&gf, 2); // q=2, for use with x==0 condition

    if(x==0){ // If x_i is an element of S2
               b=(q*b); // b_(i+1)=(2*(b_i))
               }
               
               else if(x==1){ // If x_i is an element of S3
                    b=b; // b_(i+1)=(b_i)
                    }
                    
               else if(x==2){ // If x_i is an element of S1
                    b=(b+e); // b_(i+1)=(b_i)+1
                    }
                    return b;
                    }
                                   
/*-----------End of Set functions for S1, S2 and S3---------*/

/*-------------------Pollard's Rho function-----------------*/

GaloisFieldElement pollard_rho(GaloisFieldElement alpha, 
GaloisFieldElement beta, unsigned int O){ 
// Pollard's rho method function
    
    unsigned int i;
    
    vector<GaloisFieldElement> x; // Vector list x
    vector<GaloisFieldElement> a; // Vector list a
    vector<GaloisFieldElement> b; // Vector list b
    
	GaloisFieldElement w(&gf, 1); // w=1, w is equivalent to x_0
	GaloisFieldElement u(&gf, 0); // u=0, u is equivalent to a_0
	GaloisFieldElement p(&gf, 0); // p=0, p is equivalent to b_0

    x.push_back(w); // Adding entry x_0=1 to the vector list x
    a.push_back(u); // Adding entry a_0=0 to the vector list a
    b.push_back(p); // Adding entry b_0=0 to the vector list b
    
    GaloisFieldElement X;
    GaloisFieldElement A;
    GaloisFieldElement B;
    GaloisFieldElement r;
    GaloisFieldElement c;
    GaloisFieldElement d;
    GaloisFieldElement e;
    
	GaloisFieldElement z(&gf, 0); // z=0
    
	GaloisFieldElement t;
	GaloisFieldElement T(&gf, 1); // T=1
	
	t = (alpha^6) - T; // t = (2^n) - 1. The exponent will change based 
				    // on the value of n. Alpha, and T have been
				    // used for efficieny and convenience.

    for(i=1; i<O; i++){
    // Computing the values x_i, a_i and b_i using the quantities 
    // of x_(i-1), a_(i-1) and b(i-1) computed previously from 
    // functions f, g and h         
             
             c=f(x[i-1]); // c=f(x_(i-1))
             
             x.push_back(c); // Each iterative value of c is added 
                             // to vector list x
             
             d=(g(x[i-1], a[i-1])); // d=g(x_(i-1),a_(i-1))

             a.push_back(d); // Each iterative value of d is added 
                             // to vector list a
             
             e=(h(x[i-1], b[i-1])); // e=h(x_(i-1),b(i-1))

             b.push_back(e); // Each iterative value of e is 
                            // added to vector list b

             }
             
    for(i=1; i<O; i++){
    // Now computing x_(2i), a_(2i) and b_(2i)
            
             if(x[i]==x[2*i]){
            
             X=f(f(x[(2*i)-2])); // X=x_(2i)
             
             A=(g(f(x[(2*i)-2]), g(x[(2*i)-2], a[(2*i)-2]))); 
	             // A=a_(2i)
        
             B=(h(f(x[(2*i)-2]), h(x[(2*i)-2], b[(2*i)-2]))); 
             // B=b_(2i)
             
             break;
             }
             }
    for(i=1; i<O; i++){     
       if( x[i] == X ){ // If x_i = x_(2i)
                   
                r=(b[i]-B); // r=((b_i)-b_(2i))
                
       if(r==0){ // If r=0
            cout<<"\n \n `Pollard's rho method failed to find" 
		                  "\n unique integer x as r=0!"

                  "\n No Discrete Logarithm x exists for the" 
                  "\n primitive polynomial!'"<<endl;
            return r;
            break; // Terminate algorithm with failure
            }

            else{
                  
     z=(a[i]-A)/(B-b[i]); // z=(((a_i)-a_(2i))/(b_(2i)-b_i))
              
                 if(z<0){ // If z is -ve
                         z=(t+z); // then ((2^n)-1)+z
                         }
                         }
                 return z;
                 break;
                 }
                 
}
}

/*-----------------End of Pollard's Rho function----------------*/

/**********************End of Functions**************************/

/*------------------------Main function-------------------------*/

int main(){
    
    double time, timedif; // Double is used here to show small values

    time = (double) clock(); // Get the intial time
    time = time/CLOCKS_PER_SEC;  // Time in seconds 
    
    cout<<"\n Divyesh B Chudasama"
          "\n Copyright (c) 2012";
    
    cout<<"\n \n Implementation of Pollard's Rho Method for" 
          "\n computing the unique integer x such that" 
          "\n beta = alpha^x, for the Discrete Logarithm" 
          "\n Problem in the finite field GF(2^n), where n is" 
		          "\n the value of the field exponent, alpha and beta" 
          "\n are Galois Field Elements and prim_poly is the 
          " \n primitive polynomial of the field. ";
       
    GaloisFieldElement y;

	    y = pollard_rho(alpha, beta, 63); //Calling Pollard Rho
							    // the last input is to be changed based on (2^n)-1

    cout<<endl<<"\n The discrete logarithm x is: "<<y<<endl<<endl;
    
    timedif = ( ((double) clock()) / CLOCKS_PER_SEC) - time; 
    // Calling clock() function from start of program, 
    // subtracting its return value, then to obtain the final 
    // processor time in seconds, divide the value returned 
    //by clock() by CLOCK_PER_SEC
    
    cout<<"\n The processor time elapsed is: "<<timedif<<" seconds"
    <<endl<<endl;
    
    keep_window_open();
    
    return 0;
}       

/*-------------------End of Main function--------------------*/


\end{verbatim}

\end{document}
